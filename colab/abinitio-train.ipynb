{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriele16/abinitio-train/blob/main/colab/abinitio-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFpAi8g9XmUU"
      },
      "source": [
        "# Train an E(3)NN Interatomic Potential from ab initio data using NequIP or Allegro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyduv5hWIJYP"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/mir-group/allegro/blob/main/logo.png?raw=true\" width=\"30%\">\n",
        "<img src=\"https://github.com/mir-group/nequip/blob/main/logo.png?raw=true\" width=\"30%\">\n",
        "<center/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2shNisM863Wy"
      },
      "source": [
        "### Open in colab and change the runtime to use the GPU if you have not done so already\n",
        "\n",
        "### Install dependencies, these include pytorch, nequip, allegro and other common packages\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HboutJMISv2t",
        "outputId": "076b39c6-06ef-4042-b567-698fb7d3c1b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! rm -rf abinitio-train\n",
        "! git clone  https://github.com/gabriele16/abinitio-train.git\n",
        "! pip install -r requirements.txt\n",
        "!git clone --depth 1 https://github.com/mir-group/allegro.git\n",
        "!pip install allegro/"
      ],
      "metadata": {
        "id": "hmmS-5nxkySM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fix colab imports\n",
        "import site\n",
        "site.main()\n",
        "\n",
        "# set to allow anonymous WandB\n",
        "import os\n",
        "os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n"
      ],
      "metadata": {
        "id": "egxttm2gUsw7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Pytorch and whether it works correctly on the GPU"
      ],
      "metadata": {
        "id": "MZNRk6K8NO-R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uZpOvFtImsy2",
        "outputId": "b30ebe9c-d199-467d-fbf3-3326b7c725eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************\n",
            "torch version:  1.12.1+cu102\n",
            "*****************************\n",
            "cuda is available:  True\n",
            "*****************************\n",
            "cuda version:\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "*****************************\n",
            "check which GPU is being used:\n",
            "Mon May 15 09:15:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "*****************************\n",
            "/usr/local/cuda/bin/nvcc\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"*****************************\")\n",
        "print(\"torch version: \", torch.__version__)\n",
        "print(\"*****************************\")\n",
        "print(\"cuda is available: \", torch.cuda.is_available())\n",
        "print(\"*****************************\")\n",
        "print(\"cuda version:\")\n",
        "!nvcc --version\n",
        "print(\"*****************************\")\n",
        "print(\"check which GPU is being used:\")\n",
        "!nvidia-smi\n",
        "print(\"*****************************\")\n",
        "!which nvcc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrjXfT6L3S51"
      },
      "source": [
        "### Import PyTorch, numpy etc.\n",
        "### Set-up the directory containing the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J51CA0Bod1Jv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n",
        "from ase.io import read, write\n",
        "\n",
        "import warnings\n",
        "import os\n",
        "data_dir = \"/content/abinitio-train/datasets\"\n",
        "\n",
        "np.random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(0)\n",
        "else:\n",
        "  torch.manual_seed(0)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HDmxkn3z8_m"
      },
      "source": [
        "### Workflow:\n",
        "* Train: using a data set, train the neural network\n",
        "* Evaluate: evaluate the error on total energies and forces using unseen data\n",
        "* Deploy: convert the Python-based model into a stand-alone potential file for fast execution\n",
        "* Run: run Molecular Dynamics in CP2K "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62aEgq6QYFIn"
      },
      "source": [
        "### Train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KuOIippfVfd"
      },
      "source": [
        "Here, we extract some ab initio data set for bulk water or water in contact with graphene"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd abinitio-train/datasets/ && tar -xzvf wat_bil_gra_aimd.tar.gz\n",
        "! cd abinitio-train/datasets/ && tar -xzvf wat_gra_bil_film.tar.gz\n",
        "! cd abinitio-train/datasets/refined_water_gra && for i in *.tar.gz; do tar -xzvf $i; done"
      ],
      "metadata": {
        "id": "CN4y9qQAljpO",
        "outputId": "52a6eb63-86bd-4e52-abd6-d9c83f8ec6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wat_bil_gra_aimd/\n",
            "wat_bil_gra_aimd/wat_pos_frc.extxyz\n",
            "wat_bil_gra_aimd/celldata.dat\n",
            "wat_gra_bil_film/\n",
            "wat_gra_bil_film/wat_pos_frc.extxyz\n",
            "wat_gra_bil_film/last_conf.xyz\n",
            "wat_gra_bil_film/celldata.dat\n",
            "wat_bil_gra_25/\n",
            "wat_bil_gra_25/wat_pos_frc.extxyz\n",
            "wat_bil_gra_25/celldata.dat\n",
            "wat_bil_gra_25/last_conf.xyz\n",
            "wat_bil_gra_30/\n",
            "wat_bil_gra_30/wat_pos_frc.extxyz\n",
            "wat_bil_gra_30/celldata.dat\n",
            "wat_bil_gra_30/last_conf.xyz\n",
            "wat_bil_gra_35/\n",
            "wat_bil_gra_35/wat_pos_frc.extxyz\n",
            "wat_bil_gra_35/celldata.dat\n",
            "wat_bil_gra_35/last_conf.xyz\n",
            "wat_bil_gra_40/\n",
            "wat_bil_gra_40/wat_pos_frc.extxyz\n",
            "wat_bil_gra_40/celldata.dat\n",
            "wat_bil_gra_40/last_conf.xyz\n",
            "wat_bil_gra_45/\n",
            "wat_bil_gra_45/wat_pos_frc.extxyz\n",
            "wat_bil_gra_45/celldata.dat\n",
            "wat_bil_gra_45/last_conf.xyz\n",
            "wat_bil_gra_60/\n",
            "wat_bil_gra_60/wat_pos_frc.extxyz\n",
            "wat_bil_gra_60/celldata.dat\n",
            "wat_bil_gra_60/last_conf.xyz\n",
            "wat_bil_gra_BULK/\n",
            "wat_bil_gra_BULK/wat_pos_frc.extxyz\n",
            "wat_bil_gra_BULK/celldata.dat\n",
            "wat_bil_gra_BULK/last_conf.xyz\n",
            "wat_bil_gra_FILM/\n",
            "wat_bil_gra_FILM/wat_pos_frc.extxyz\n",
            "wat_bil_gra_FILM/celldata.dat\n",
            "wat_bil_gra_FILM/last_conf.xyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd abinitio-train/datasets/ && tar -xzvf wat_film_gra.tar.gz"
      ],
      "metadata": {
        "id": "_8iEFXaFnND-",
        "outputId": "6928125c-17ec-4ba9-e054-7253319fd541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wat_film_gra/./\n",
            "wat_film_gra/./wat_pos_frc.extxyz\n",
            "wat_film_gra/./celldata.dat\n",
            "wat_film_gra/./last_conf.xyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Below we explicitly write the input to train the model with NequIP/Allegro"
      ],
      "metadata": {
        "id": "PBPmf2CEgP1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allegro_input = \"\"\"\n",
        "# general\n",
        "root: results/water-gra-film\n",
        "run_name: water-gra-film\n",
        "seed: 42\n",
        "dataset_seed: 42\n",
        "append: true\n",
        "# To use float64 with cp2k, need to implement it, for now use float32\n",
        "default_dtype: float64\n",
        "\n",
        "# -- network --\n",
        "model_builders:\n",
        " - allegro.model.Allegro\n",
        " # the typical model builders from `nequip` can still be used:\n",
        " - PerSpeciesRescale\n",
        " - ForceOutput\n",
        " - RescaleEnergyEtc\n",
        "\n",
        "# cutoffs\n",
        "r_max: 5.0\n",
        "avg_num_neighbors: auto\n",
        "\n",
        "# radial basis\n",
        "# Try to use a small cutoff and a large polynomial cutoff p\n",
        "# use p=48 in the Li3PO4 case in the paper since the cutoff is quite small\n",
        "# see https://github.com/mir-group/allegro/discussions/20\n",
        "BesselBasis_trainable: true \n",
        "### Use normalize_basis: true, see https://github.com/mir-group/allegro/discussions/20\n",
        "normalize_basis: true\n",
        "PolynomialCutoff_p: 48   \n",
        "\n",
        "# symmetry\n",
        "l_max: 2\n",
        "parity: o3_full   \n",
        "\n",
        "# Allegro layers:\n",
        "num_layers: 2\n",
        "env_embed_multiplicity: 8\n",
        "embed_initial_edge: true\n",
        "\n",
        "two_body_latent_mlp_latent_dimensions: [32, 64, 128]\n",
        "two_body_latent_mlp_nonlinearity: silu\n",
        "two_body_latent_mlp_initialization: uniform\n",
        "\n",
        "latent_mlp_latent_dimensions: [128]\n",
        "latent_mlp_nonlinearity: silu\n",
        "latent_mlp_initialization: uniform\n",
        "latent_resnet: true\n",
        "\n",
        "env_embed_mlp_latent_dimensions: []\n",
        "env_embed_mlp_nonlinearity: null\n",
        "env_embed_mlp_initialization: uniform\n",
        "\n",
        "# - end allegro layers -\n",
        "\n",
        "# Final MLP to go from Allegro latent space to edge energies:\n",
        "edge_eng_mlp_latent_dimensions: [32]\n",
        "edge_eng_mlp_nonlinearity: null\n",
        "edge_eng_mlp_initialization: uniform\n",
        "\n",
        "include_keys:\n",
        "  - user_label\n",
        "key_mapping:\n",
        "  user_label: label0\n",
        "\n",
        "# -- data --\n",
        "dataset: ase                                                                   \n",
        "#dataset_file_name: /content/abinitio-train/datasets/wat_gra_bil_film/wat_pos_frc.extxyz                     # path to data set file\n",
        "#dataset_file_name: /content/abinitio-train/datasets/refined_water_gra/wat_bil_gra_FILM/wat_pos_frc.extxyz                     # path to data set file\n",
        "dataset_file_name: /content/abinitio-train/datasets/wat_film_gra/wat_pos_frc.extxyz                     # path to data set file\n",
        "\n",
        "ase_args:\n",
        "  format: extxyz\n",
        "\n",
        "# A mapping of chemical species to type indexes is necessary if the dataset is provided with atomic numbers instead of type indexes.\n",
        "#chemical_symbol_to_type:\n",
        "chemical_symbols:\n",
        "  - C\n",
        "  - H\n",
        "  - O\n",
        "\n",
        "# logging\n",
        "wandb: false\n",
        "#wandb_project: allegro-water-tutorial\n",
        "verbose: info\n",
        "log_batch_freq: 10\n",
        "\n",
        "# training\n",
        "n_train: 500\n",
        "n_val: 50\n",
        "batch_size: 1\n",
        "max_epochs: 100\n",
        "learning_rate: 0.004\n",
        "train_val_split: random\n",
        "shuffle: true\n",
        "metrics_key: validation_loss\n",
        "\n",
        "# use an exponential moving average of the weights\n",
        "use_ema: true\n",
        "ema_decay: 0.99\n",
        "ema_use_num_updates: true\n",
        "\n",
        "# loss function\n",
        "loss_coeffs:\n",
        "  forces: 1.\n",
        "  total_energy:\n",
        "    - 1.\n",
        "    - PerAtomMSELoss\n",
        "\n",
        "# optimizer\n",
        "optimizer_name: Adam\n",
        "optimizer_params:\n",
        "  amsgrad: false\n",
        "  betas: !!python/tuple\n",
        "  - 0.9\n",
        "  - 0.999\n",
        "  eps: 1.0e-08\n",
        "  weight_decay: 0.\n",
        "\n",
        "metrics_components:\n",
        "  - - forces                               # key \n",
        "    - mae                                  # \"rmse\" or \"mae\"\n",
        "  - - forces\n",
        "    - rmse\n",
        "  - - total_energy\n",
        "    - mae    \n",
        "  - - total_energy\n",
        "    - mae\n",
        "    - PerAtom: True                        # if true, energy is normalized by the number of atoms\n",
        "\n",
        "# lr scheduler, drop lr if no improvement for 50 epochs\n",
        "lr_scheduler_name: ReduceLROnPlateau\n",
        "lr_scheduler_patience: 25\n",
        "lr_scheduler_factor: 0.5\n",
        "\n",
        "early_stopping_lower_bounds:\n",
        "  LR: 1.0e-5\n",
        "\n",
        "early_stopping_patiences:\n",
        "  validation_loss: 25\n",
        "\"\"\"\n",
        "\n",
        "with open(\"allegro/configs/allegro-water-gra.yaml\", \"w\") as f:\n",
        "    f.write(allegro_input)"
      ],
      "metadata": {
        "id": "Meo8tyV0W_FS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nequip_input = \"\"\"\n",
        "\n",
        "# IMPORTANT: READ THIS\n",
        "\n",
        "# This is a full yaml file with all nequip options.\n",
        "# It is primarily intented to serve as documentation/reference for all options\n",
        "# For a simpler yaml file containing all necessary features to get you started, we strongly recommend to start with configs/example.yaml\n",
        "\n",
        "# Two folders will be used during the training: 'root'/process and 'root'/'run_name'\n",
        "# run_name contains logfiles and saved models\n",
        "# process contains processed data sets\n",
        "# if 'root'/'run_name' exists, 'root'/'run_name'_'year'-'month'-'day'-'hour'-'min'-'s' will be used instead.\n",
        "root: results/water-gra-film\n",
        "run_name: water-gra-film\n",
        "seed: 123 # model seed\n",
        "dataset_seed: 456 # data set seed\n",
        "append: true # set true if a restarted run should append to the previous log file\n",
        "default_dtype: float64 # type of float to use, e.g. float32 and float64\n",
        "allow_tf32: false # whether to use TensorFloat32 if it is available\n",
        "# device:  cuda                                                                   # which device to use. Default: automatically detected cuda or \"cpu\"\n",
        "\n",
        "# network\n",
        "r_max: 5.0 # cutoff radius in length units, here Angstrom, this is an important hyperparamter to scan\n",
        "num_layers: 3 # number of interaction blocks, we find 3-5 to work best\n",
        "\n",
        "l_max: 1 # the maximum irrep order (rotation order) for the network's features, l=1 is a good default, l=2 is more accurate but slower\n",
        "parity: true # whether to include features with odd mirror parityy; often turning parity off gives equally good results but faster networks, so do consider this\n",
        "num_features: 32 # the multiplicity of the features, 32 is a good default for accurate network, if you want to be more accurate, go larger, if you want to be faster, go lower\n",
        "\n",
        "# alternatively, the irreps of the features in various parts of the network can be specified directly:\n",
        "# the following options use e3nn irreps notation\n",
        "# either these four options, or the above three options, should be provided--- they cannot be mixed.\n",
        "# chemical_embedding_irreps_out: 32x0e                                              # irreps for the chemical embedding of species\n",
        "# feature_irreps_hidden: 32x0o + 32x0e + 32x1o + 32x1e                              # irreps used for hidden features, here we go up to lmax=1, with even and odd parities; for more accurate but slower networks, use l=2 or higher, smaller number of features is faster\n",
        "# irreps_edge_sh: 0e + 1o                                                           # irreps of the spherical harmonics used for edges. If a single integer, indicates the full SH up to L_max=that_integer\n",
        "# conv_to_output_hidden_irreps_out: 16x0e                                           # irreps used in hidden layer of output block\n",
        "\n",
        "nonlinearity_type: gate # may be 'gate' or 'norm', 'gate' is recommended\n",
        "resnet:\n",
        "  false # set true to make interaction block a resnet-style update\n",
        "  # the resnet update will only be applied when the input and output irreps of the layer are the same\n",
        "\n",
        "# scalar nonlinearities to use — available options are silu, ssp (shifted softplus), tanh, and abs.\n",
        "# Different nonlinearities are specified for e (even) and o (odd) parity;\n",
        "# note that only tanh and abs are correct for o (odd parity).\n",
        "# silu typically works best for even\n",
        "nonlinearity_scalars:\n",
        "  e: silu\n",
        "  o: tanh\n",
        "\n",
        "nonlinearity_gates:\n",
        "  e: silu\n",
        "  o: tanh\n",
        "\n",
        "# radial network basis\n",
        "num_basis: 8 # number of basis functions used in the radial basis, 8 usually works best\n",
        "BesselBasis_trainable: true # set true to train the bessel weights\n",
        "PolynomialCutoff_p: 48 # p-exponent used in polynomial cutoff function, smaller p corresponds to stronger decay with distance\n",
        "\n",
        "# radial network\n",
        "invariant_layers: 2 # number of radial layers, usually 1-3 works best, smaller is faster\n",
        "invariant_neurons: 64 # number of hidden neurons in radial function, smaller is faster\n",
        "avg_num_neighbors: auto # number of neighbors to divide by, null => no normalization, auto computes it based on dataset\n",
        "use_sc: true # use self-connection or not, usually gives big improvement\n",
        "\n",
        "# to specify different parameters for each convolutional layer, try examples below\n",
        "# layer1_use_sc: true                                                             # use \"layer{i}_\" prefix to specify parameters for only one of the layer,\n",
        "# priority for different definitions:\n",
        "#   invariant_neurons < InteractionBlock_invariant_neurons < layer{i}_invariant_neurons\n",
        "\n",
        "# data set\n",
        "# there are two options to specify a dataset, npz or ase\n",
        "# npz works with npz files, ase can ready any format that ase.io.read can read\n",
        "# in most cases working with the ase option and an extxyz file is by far the simplest way to do it and we strongly recommend using this\n",
        "# simply provide a single extxyz file that contains the structures together with energies and forces (generated with ase.io.write(atoms, format='extxyz', append=True))\n",
        "\n",
        "include_keys:\n",
        "  - user_label\n",
        "key_mapping:\n",
        "  user_label: label0\n",
        "\n",
        "# alternatively, you can read directly from a VASP OUTCAR file (this will only read that single OUTCAR)\n",
        "# # for VASP OUTCAR, the yaml input should be\n",
        "# dataset: ase\n",
        "# dataset_file_name: OUTCAR\n",
        "# ase_args:\n",
        "#   format: vasp-out\n",
        "# important VASP note: the ase vasp parser stores the potential energy to \"free_energy\" instead of \"energy\".\n",
        "# Here, the key_mapping maps the external name (key) to the NequIP default name (value)\n",
        "# key_mapping:\n",
        "#   free_energy: total_energy\n",
        "\n",
        "# npz example\n",
        "# the keys used need to be stated at least once in key_mapping, npz_fixed_field_keys or include_keys\n",
        "# key_mapping is used to map the key in the npz file to the NequIP default values (see data/_key.py)\n",
        "# all arrays are expected to have the shape of (nframe, natom, ?) except the fixed fields\n",
        "# note that if your data set uses pbc, you need to also pass an array that maps to the nequip \"pbc\" key\n",
        "# dataset: npz                                                                       # type of data set, can be npz or ase\n",
        "# dataset_url: http://quantum-machine.org/gdml/data/npz/toluene_ccsd_t.zip           # url to download the npz. optional\n",
        "# dataset_file_name: ./benchmark_data/toluene_ccsd_t-train.npz                       # path to data set file\n",
        "# key_mapping:\n",
        "#   z: atomic_numbers                                                                # atomic species, integers\n",
        "#   E: total_energy                                                                  # total potential eneriges to train to\n",
        "#   F: forces                                                                        # atomic forces to train to\n",
        "#   R: pos                                                                           # raw atomic positions\n",
        "# npz_fixed_field_keys:                                                              # fields that are repeated across different examples\n",
        "#   - atomic_numbers\n",
        "\n",
        "# A list of chemical species found in the data. The NequIP atom types will be named after the chemical symbols and ordered by atomic number in ascending order.\n",
        "# (In this case, NequIP's internal atom type 0 will be named H and type 1 will be named C.)\n",
        "# Atoms in the input will be assigned NequIP atom types according to their atomic numbers.\n",
        "chemical_symbols:\n",
        "  - C\n",
        "  - H\n",
        "  - O\n",
        "\n",
        "# Alternatively, you may explicitly specify which chemical species in the input will map to NequIP atom type 0, which to atom type 1, and so on.\n",
        "# Other than providing an explicit order for the NequIP atom types, this option behaves the same as `chemical_symbols`\n",
        "#chemical_symbol_to_type:\n",
        "#  C: 0\n",
        "#  H: 1\n",
        "#  O: 2\n",
        "\n",
        "# Alternatively, if the dataset has type indices, you may give the names for the types in order:\n",
        "# (this also sets the number of types)\n",
        "# type_names:\n",
        "#   - my_type\n",
        "#   - atom\n",
        "#   - thing\n",
        "\n",
        "# As an alternative option to npz, you can also pass data ase ASE Atoms-objects\n",
        "# This can often be easier to work with, simply make sure the ASE Atoms object\n",
        "# has a calculator for which atoms.get_potential_energy() and atoms.get_forces() are defined\n",
        "dataset: ase\n",
        "#dataset_file_name: ./abinitio-train/datasets/wat_gra_bil_film/wat_pos_frc.extxyz # need to be a format accepted by ase.io.read\n",
        "#dataset_file_name: /content/abinitio-train/datasets/refined_water_gra/wat_bil_gra_FILM/wat_pos_frc.extxyz                     # path to data set file\n",
        "dataset_file_name: /content/abinitio-train/datasets/wat_film_gra/wat_pos_frc.extxyz                     # path to data set file\n",
        "\n",
        "ase_args: # any arguments needed by ase.io.read\n",
        "  format: extxyz\n",
        "\n",
        "# If you want to use a different dataset for validation, you can specify\n",
        "# the same types of options using a `validation_` prefix:\n",
        "# validation_dataset: ase\n",
        "# validation_dataset_file_name: xxx.xyz                                            # need to be a format accepted by ase.io.read\n",
        "\n",
        "# logging\n",
        "#wandb: true # we recommend using wandb for logging\n",
        "#wandb_project: water-example # project name used in wandb\n",
        "#wandb_watch: false\n",
        "\n",
        "# see https://docs.wandb.ai/ref/python/watch\n",
        "# wandb_watch_kwargs:\n",
        "#   log: all\n",
        "#   log_freq: 1\n",
        "#   log_graph: true\n",
        "\n",
        "verbose: info # the same as python logging, e.g. warning, info, debug, error. case insensitive\n",
        "log_batch_freq: 1 # batch frequency, how often to print training errors withinin the same epoch\n",
        "log_epoch_freq: 1 # epoch frequency, how often to print\n",
        "save_checkpoint_freq: -1 # frequency to save the intermediate checkpoint. no saving of intermediate checkpoints when the value is not positive.\n",
        "save_ema_checkpoint_freq: -1 # frequency to save the intermediate ema checkpoint. no saving of intermediate checkpoints when the value is not positive.\n",
        "\n",
        "# training\n",
        "n_train: 100 # number of training data\n",
        "n_val: 10 # number of validation data\n",
        "learning_rate: 0.005 # learning rate, we found values between 0.01 and 0.005 to work best - this is often one of the most important hyperparameters to tune\n",
        "batch_size: 1 # batch size, we found it important to keep this small for most applications including forces (1-5); for energy-only training, higher batch sizes work better\n",
        "validation_batch_size: 1 # batch size for evaluating the model during validation. This does not affect the training results, but using the highest value possible (<=n_val) without running out of memory will speed up your training.\n",
        "max_epochs: 200 # stop training after _ number of epochs, we set a very large number here, it won't take this long in practice and we will use early stopping instead\n",
        "train_val_split: random # can be random or sequential. if sequential, first n_train elements are training, next n_val are val, else random, usually random is the right choice\n",
        "shuffle: true # If true, the data loader will shuffle the data, usually a good idea\n",
        "metrics_key: validation_loss # metrics used for scheduling and saving best model. Options: `set`_`quantity`, set can be either \"train\" or \"validation, \"quantity\" can be loss or anything that appears in the validation batch step header, such as f_mae, f_rmse, e_mae, e_rmse\n",
        "use_ema: true # if true, use exponential moving average on weights for val/test, usually helps a lot with training, in particular for energy errors\n",
        "ema_decay: 0.99 # ema weight, typically set to 0.99 or 0.999\n",
        "ema_use_num_updates: true # whether to use number of updates when computing averages\n",
        "report_init_validation: true # if True, report the validation error for just initialized model\n",
        "\n",
        "# early stopping based on metrics values.\n",
        "# LR, wall and any keys printed in the log file can be used.\n",
        "# The key can start with Training or validation. If not defined, the validation value will be used.\n",
        "early_stopping_patiences: # stop early if a metric value stopped decreasing for n epochs\n",
        "  validation_loss: 50\n",
        "\n",
        "early_stopping_delta: # If delta is defined, a decrease smaller than delta will not be considered as a decrease\n",
        "  validation_loss: 0.005\n",
        "\n",
        "early_stopping_cumulative_delta: false # If True, the minimum value recorded will not be updated when the decrease is smaller than delta\n",
        "\n",
        "early_stopping_lower_bounds: # stop early if a metric value is lower than the bound\n",
        "  LR: 1.0e-5\n",
        "\n",
        "early_stopping_upper_bounds: # stop early if a metric value is higher than the bound\n",
        "  cumulative_wall: 1.0e+100\n",
        "\n",
        "# loss function\n",
        "loss_coeffs: # different weights to use in a weighted loss functions\n",
        "  forces: 1 # if using PerAtomMSELoss, a default weight of 1:1 on each should work well\n",
        "  total_energy:\n",
        "    - 1\n",
        "    - PerAtomMSELoss\n",
        "\n",
        "# # default loss function is MSELoss, the name has to be exactly the same as those in torch.nn.\n",
        "# the only supprted targets are forces and total_energy\n",
        "\n",
        "# here are some example of more ways to declare different types of loss functions, depending on your application:\n",
        "# loss_coeffs:\n",
        "#   total_energy: MSELoss\n",
        "#\n",
        "# loss_coeffs:\n",
        "#   total_energy:\n",
        "#   - 3.0\n",
        "#   - MSELoss\n",
        "#\n",
        "# loss_coeffs:\n",
        "#   total_energy:\n",
        "#   - 1.0\n",
        "#   - PerAtomMSELoss\n",
        "#\n",
        "# loss_coeffs:\n",
        "#   forces:\n",
        "#   - 1.0\n",
        "#   - PerSpeciesL1Loss\n",
        "#\n",
        "# loss_coeffs: total_energy\n",
        "#\n",
        "# loss_coeffs:\n",
        "#   total_energy:\n",
        "#   - 3.0\n",
        "#   - L1Loss\n",
        "#   forces: 1.0\n",
        "\n",
        "# output metrics\n",
        "metrics_components:\n",
        "  - - forces # key\n",
        "    - mae # \"rmse\" or \"mae\"\n",
        "  - - forces\n",
        "    - rmse\n",
        "  - - forces\n",
        "    - mae\n",
        "    - PerSpecies: True # if true, per species contribution is counted separately\n",
        "      report_per_component: False # if true, statistics on each component (i.e. fx, fy, fz) will be counted separately\n",
        "  - - forces\n",
        "    - rmse\n",
        "    - PerSpecies: True\n",
        "      report_per_component: False\n",
        "  - - total_energy\n",
        "    - mae\n",
        "  - - total_energy\n",
        "    - mae\n",
        "    - PerAtom: True # if true, energy is normalized by the number of atoms\n",
        "\n",
        "# optimizer, may be any optimizer defined in torch.optim\n",
        "# the name `optimizer_name`is case sensitive\n",
        "optimizer_name: Adam # default optimizer is Adam\n",
        "optimizer_amsgrad: false\n",
        "optimizer_betas: !!python/tuple\n",
        "  - 0.9\n",
        "  - 0.999\n",
        "optimizer_eps: 1.0e-08\n",
        "optimizer_weight_decay: 0\n",
        "\n",
        "# gradient clipping using torch.nn.utils.clip_grad_norm_\n",
        "# see https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_\n",
        "# setting to inf or null disables it\n",
        "max_gradient_norm: null\n",
        "\n",
        "# lr scheduler, currently only supports the two options listed below, if you need more please file an issue\n",
        "# first: on-plateau, reduce lr by factory of lr_scheduler_factor if metrics_key hasn't improved for lr_scheduler_patience epoch\n",
        "lr_scheduler_name: ReduceLROnPlateau\n",
        "lr_scheduler_patience: 100\n",
        "lr_scheduler_factor: 0.5\n",
        "\n",
        "# second, cosine annealing with warm restart\n",
        "# lr_scheduler_name: CosineAnnealingWarmRestarts\n",
        "# lr_scheduler_T_0: 10000\n",
        "# lr_scheduler_T_mult: 2\n",
        "# lr_scheduler_eta_min: 0\n",
        "# lr_scheduler_last_epoch: -1\n",
        "\n",
        "# we provide a series of options to shift and scale the data\n",
        "# these are for advanced use and usually the defaults work very well\n",
        "# the default is to scale the energies and forces by scaling them by the force standard deviation and to shift the energy by its mean\n",
        "# in certain cases, it can be useful to have a trainable shift/scale and to also have species-dependent shifts/scales for each atom\n",
        "\n",
        "per_species_rescale_scales_trainable: false\n",
        "# whether the scales are trainable. Defaults to False. Optional\n",
        "per_species_rescale_shifts_trainable: false\n",
        "# whether the shifts are trainable. Defaults to False. Optional\n",
        "per_species_rescale_shifts: dataset_per_atom_total_energy_mean\n",
        "# initial atomic energy shift for each species. default to the mean of per atom energy. Optional\n",
        "# the value can be a constant float value, an array for each species, or a string\n",
        "# string option include:\n",
        "# *  \"dataset_per_atom_total_energy_mean\", which computes the per atom average\n",
        "# *  \"dataset_per_species_total_energy_mean\", which automatically compute the per atom energy mean using a GP model\n",
        "per_species_rescale_scales: dataset_forces_rms\n",
        "# initial atomic energy scale for each species. Optional.\n",
        "# the value can be a constant float value, an array for each species, or a string\n",
        "# string option include:\n",
        "# *  \"dataset_per_atom_total_energy_std\", which computes the per atom energy std\n",
        "# *  \"dataset_per_species_total_energy_std\", which uses the GP model uncertainty\n",
        "# *  \"dataset_per_species_forces_rms\", which compute the force rms for each species\n",
        "# If not provided, defaults to dataset_per_species_force_rms or dataset_per_atom_total_energy_std, depending on whether forces are being trained.\n",
        "# per_species_rescale_kwargs:\n",
        "#   total_energy:\n",
        "#     alpha: 0.1\n",
        "#     max_iteration: 20\n",
        "#     stride: 100\n",
        "# keywords for GP decomposition of per specie energy. Optional. Defaults to 0.1\n",
        "# per_species_rescale_arguments_in_dataset_units: True\n",
        "# if explicit numbers are given for the shifts/scales, this parameter must specify whether the given numbers are unitless shifts/scales or are in the units of the dataset. If ``True``, any global rescalings will correctly be applied to the per-species values.\n",
        "\n",
        "# global energy shift and scale\n",
        "# When \"dataset_total_energy_mean\", the mean energy of the dataset. When None, disables the global shift. When a number, used directly.\n",
        "# Warning: if this value is not None, the model is no longer size extensive\n",
        "global_rescale_shift: null\n",
        "\n",
        "# global energy scale. When \"dataset_force_rms\", the RMS of force components in the dataset. When \"dataset_total_energy_std\", the stdev of energies in the dataset. When null, disables the global scale. When a number, used directly.\n",
        "# If not provided, defaults to either dataset_force_rms or dataset_total_energy_std, depending on whether forces are being trained.\n",
        "global_rescale_scale: dataset_forces_rms\n",
        "\n",
        "# whether the shift of the final global energy rescaling should be trainable\n",
        "global_rescale_shift_trainable: false\n",
        "\n",
        "# whether the scale of the final global energy rescaling should be trainable\n",
        "global_rescale_scale_trainable: false\n",
        "# # full block needed for per specie rescale\n",
        "# global_rescale_shift: null\n",
        "# global_rescale_shift_trainable: false\n",
        "# global_rescale_scale: dataset_forces_rms\n",
        "# global_rescale_scale_trainable: false\n",
        "# per_species_rescale_trainable: true\n",
        "# per_species_rescale_shifts: dataset_per_atom_total_energy_mean\n",
        "# per_species_rescale_scales: dataset_per_atom_total_energy_std\n",
        "\n",
        "# # full block needed for global rescale\n",
        "# global_rescale_shift: dataset_total_energy_mean\n",
        "# global_rescale_shift_trainable: false\n",
        "# global_rescale_scale: dataset_forces_rms\n",
        "# global_rescale_scale_trainable: false\n",
        "# per_species_rescale_trainable: false\n",
        "# per_species_rescale_shifts: null\n",
        "# per_species_rescale_scales: null\n",
        "\n",
        "# Options for e3nn's set_optimization_defaults. A dict:\n",
        "# e3nn_optimization_defaults:\n",
        "#   explicit_backward: True\n",
        "\"\"\"\n",
        "\n",
        "!mkdir nequip_train\n",
        "with open(\"nequip_train/water-gra.yaml\", \"w\") as f:\n",
        "    f.write(nequip_input)"
      ],
      "metadata": {
        "id": "TQYNvq6YO0EH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with Allegro or NequIP"
      ],
      "metadata": {
        "id": "33biTiWVq7Zb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ukSnt_QD5avu",
        "outputId": "7d3c04ec-ea03-45a9-fd33-25bc2e0504d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              22 2892.555    0.004      0.00396     0.000262      0.00422       0.0411        0.054         3.98       0.0111\n",
            "! Validation         22 2892.555    0.004      0.00344     7.65e-06      0.00345       0.0382       0.0504         0.66      0.00183\n",
            "Wall time: 2892.555846321\n",
            "! Best model       22    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     23    10       0.0041      0.00372      0.00038       0.0398       0.0524         6.03       0.0167\n",
            "     23    20      0.00366      0.00307      0.00059       0.0361       0.0476         7.51       0.0209\n",
            "     23    30      0.00474       0.0037      0.00104       0.0394       0.0522         9.96       0.0277\n",
            "     23    40      0.00452      0.00435     0.000167       0.0437       0.0567            4       0.0111\n",
            "     23    50      0.00525      0.00482     0.000428        0.046       0.0596          6.4       0.0178\n",
            "     23    60      0.00399      0.00396     3.57e-05       0.0424        0.054         1.85      0.00513\n",
            "     23    70      0.00438      0.00438     3.66e-07       0.0424       0.0568        0.187      0.00052\n",
            "     23    80      0.00391      0.00336     0.000547       0.0375       0.0498         7.23       0.0201\n",
            "     23    90      0.00466      0.00378     0.000882       0.0405       0.0528         9.18       0.0255\n",
            "     23   100      0.00413      0.00413     4.61e-06       0.0423       0.0552        0.664      0.00184\n",
            "     23   110       0.0047      0.00463      7.1e-05       0.0427       0.0584         2.61      0.00724\n",
            "     23   120      0.00318      0.00318     1.61e-07        0.037       0.0484        0.124     0.000345\n",
            "     23   130      0.00372      0.00366     5.79e-05       0.0394        0.052         2.35      0.00653\n",
            "     23   140      0.00376      0.00368     8.16e-05        0.039       0.0521         2.79      0.00776\n",
            "     23   150      0.00407      0.00352     0.000555       0.0392       0.0509         7.29       0.0202\n",
            "     23   160      0.00551      0.00551     4.27e-08       0.0439       0.0638       0.0639     0.000177\n",
            "     23   170      0.00388      0.00385      2.2e-05       0.0406       0.0533         1.45      0.00403\n",
            "     23   180      0.00571      0.00567     3.95e-05       0.0486       0.0647         1.94       0.0054\n",
            "     23   190       0.0036       0.0036     2.81e-06       0.0394       0.0515        0.518      0.00144\n",
            "     23   200      0.00456      0.00431     0.000251        0.043       0.0564         4.89       0.0136\n",
            "     23   210      0.00429      0.00402     0.000276       0.0424       0.0544         5.13       0.0143\n",
            "     23   220      0.00383      0.00382     1.62e-05       0.0401       0.0531         1.24      0.00346\n",
            "     23   230      0.00467       0.0038     0.000864       0.0423        0.053         9.09       0.0252\n",
            "     23   240      0.00388      0.00357     0.000308       0.0393       0.0513         5.42       0.0151\n",
            "     23   250      0.00427      0.00424      3.3e-05       0.0415       0.0559         1.78      0.00494\n",
            "     23   260      0.00379      0.00351     0.000281       0.0396       0.0509         5.18       0.0144\n",
            "     23   270      0.00326      0.00307     0.000192       0.0371       0.0476         4.28       0.0119\n",
            "     23   280      0.00323      0.00321     1.75e-05       0.0384       0.0487         1.29      0.00359\n",
            "     23   290      0.00515      0.00493     0.000227       0.0453       0.0603         4.66       0.0129\n",
            "     23   300      0.00503      0.00495     7.87e-05       0.0445       0.0604         2.74      0.00762\n",
            "     23   310       0.0034      0.00339      5.3e-06       0.0391         0.05        0.712      0.00198\n",
            "     23   320      0.00335      0.00325     0.000104        0.038       0.0489         3.16      0.00877\n",
            "     23   330      0.00396      0.00358     0.000378       0.0391       0.0514         6.01       0.0167\n",
            "     23   340       0.0049      0.00423     0.000671       0.0429       0.0559         8.01       0.0222\n",
            "     23   350      0.00505      0.00424     0.000815       0.0423       0.0559         8.83       0.0245\n",
            "     23   360      0.00344      0.00339     4.63e-05       0.0384         0.05          2.1      0.00584\n",
            "     23   370      0.00344       0.0034      4.2e-05       0.0388       0.0501            2      0.00556\n",
            "     23   380      0.00413      0.00367     0.000454       0.0392        0.052         6.59       0.0183\n",
            "     23   390      0.00335       0.0033     4.74e-05       0.0383       0.0493         2.13      0.00591\n",
            "     23   400      0.00322       0.0031     0.000121       0.0364       0.0478          3.4      0.00944\n",
            "     23   410      0.00426      0.00425     1.01e-05       0.0428        0.056        0.985      0.00274\n",
            "     23   420       0.0036      0.00359     1.35e-05       0.0388       0.0514         1.13      0.00315\n",
            "     23   430      0.00508      0.00364      0.00144       0.0388       0.0518         11.7       0.0326\n",
            "     23   440      0.00449      0.00442     7.45e-05        0.044       0.0571         2.67      0.00741\n",
            "     23   450      0.00392      0.00385     7.29e-05       0.0404       0.0533         2.64      0.00733\n",
            "     23   460      0.00436      0.00435     1.68e-05       0.0403       0.0566         1.27      0.00352\n",
            "     23   470       0.0039      0.00386     4.35e-05       0.0404       0.0533         2.04      0.00566\n",
            "     23   480      0.00419      0.00417     1.97e-05       0.0428       0.0555         1.37      0.00381\n",
            "     23   490      0.00383      0.00381     2.14e-05       0.0401        0.053         1.43      0.00397\n",
            "     23   500      0.00327      0.00325     1.89e-05       0.0375       0.0489         1.34      0.00373\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     23    10       0.0034       0.0034     3.96e-06       0.0387       0.0501        0.469       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              23 3023.131    0.004      0.00398     0.000264      0.00424       0.0412       0.0542         4.04       0.0112\n",
            "! Validation         23 3023.131    0.004      0.00334     7.61e-06      0.00335       0.0377       0.0497        0.675      0.00187\n",
            "Wall time: 3023.1310592259997\n",
            "! Best model       23    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     24    10        0.004        0.004      3.2e-07       0.0419       0.0543        0.175     0.000486\n",
            "     24    20      0.00496      0.00494     1.86e-05       0.0459       0.0604         1.34      0.00371\n",
            "     24    30      0.00415      0.00377      0.00038       0.0402       0.0527         6.03       0.0167\n",
            "     24    40      0.00584       0.0044      0.00144       0.0437        0.057         11.7       0.0326\n",
            "     24    50      0.00448      0.00397     0.000518       0.0413       0.0541         7.04       0.0195\n",
            "     24    60      0.00357      0.00352     4.48e-05       0.0386        0.051         2.07      0.00575\n",
            "     24    70      0.00478      0.00477     1.14e-05       0.0457       0.0593         1.04       0.0029\n",
            "     24    80      0.00334      0.00326     8.27e-05       0.0377        0.049         2.81      0.00781\n",
            "     24    90      0.00479      0.00474     5.34e-05       0.0438       0.0591         2.26      0.00628\n",
            "     24   100      0.00454      0.00439     0.000149       0.0427       0.0569         3.77       0.0105\n",
            "     24   110       0.0041      0.00409     3.31e-06       0.0428        0.055        0.563      0.00156\n",
            "     24   120      0.00476      0.00463      0.00013       0.0429       0.0584         3.52      0.00978\n",
            "     24   130      0.00442      0.00383     0.000591       0.0395       0.0532         7.51       0.0209\n",
            "     24   140      0.00443      0.00421     0.000214       0.0436       0.0557         4.52       0.0126\n",
            "     24   150      0.00372      0.00372     3.72e-06       0.0402       0.0524        0.596      0.00166\n",
            "     24   160       0.0039      0.00375     0.000148       0.0396       0.0526         3.76       0.0105\n",
            "     24   170      0.00568       0.0046      0.00108       0.0422       0.0583         10.2       0.0282\n",
            "     24   180      0.00328      0.00327     1.21e-05       0.0373       0.0491         1.07      0.00298\n",
            "     24   190      0.00323       0.0031     0.000132       0.0371       0.0478         3.55      0.00986\n",
            "     24   200      0.00457      0.00358      0.00099       0.0391       0.0514         9.73        0.027\n",
            "     24   210      0.00354      0.00351     3.77e-05       0.0386       0.0508          1.9      0.00527\n",
            "     24   220      0.00381       0.0034     0.000412       0.0387       0.0501         6.28       0.0174\n",
            "     24   230      0.00425      0.00368     0.000567       0.0403       0.0521         7.36       0.0204\n",
            "     24   240      0.00421      0.00406      0.00015       0.0432       0.0547         3.79       0.0105\n",
            "     24   250      0.00353      0.00333     0.000201       0.0381       0.0496         4.39       0.0122\n",
            "     24   260      0.00409      0.00409     5.19e-06        0.041       0.0549        0.704      0.00196\n",
            "     24   270      0.00457      0.00442     0.000147       0.0425       0.0571         3.75       0.0104\n",
            "     24   280       0.0036       0.0033     0.000298       0.0382       0.0494         5.34       0.0148\n",
            "     24   290      0.00328      0.00323     4.28e-05       0.0373       0.0488         2.02      0.00562\n",
            "     24   300      0.00426      0.00419     6.77e-05       0.0429       0.0556         2.54      0.00706\n",
            "     24   310      0.00491      0.00468     0.000226        0.044       0.0588         4.65       0.0129\n",
            "     24   320      0.00446      0.00446      8.8e-07       0.0425       0.0573         0.29     0.000806\n",
            "     24   330      0.00366      0.00339     0.000271       0.0368         0.05         5.09       0.0141\n",
            "     24   340      0.00332       0.0031     0.000221       0.0365       0.0478          4.6       0.0128\n",
            "     24   350      0.00407      0.00377     0.000301       0.0414       0.0528         5.37       0.0149\n",
            "     24   360      0.00498      0.00473     0.000253       0.0464       0.0591         4.92       0.0137\n",
            "     24   370      0.00416      0.00356     0.000593       0.0395       0.0513         7.53       0.0209\n",
            "     24   380      0.00291      0.00284     7.26e-05       0.0357       0.0457         2.63      0.00732\n",
            "     24   390      0.00475      0.00356       0.0012       0.0387       0.0512         10.7       0.0297\n",
            "     24   400      0.00339      0.00299     0.000398        0.036        0.047         6.17       0.0171\n",
            "     24   410      0.00559      0.00557     1.97e-05       0.0481       0.0641         1.37      0.00381\n",
            "     24   420      0.00346      0.00345     7.65e-06       0.0382       0.0505        0.855      0.00238\n",
            "     24   430      0.00352      0.00352      4.2e-06        0.039       0.0509        0.634      0.00176\n",
            "     24   440      0.00405      0.00302      0.00102       0.0363       0.0472          9.9       0.0275\n",
            "     24   450      0.00445      0.00394      0.00051       0.0422       0.0539         6.98       0.0194\n",
            "     24   460      0.00438      0.00286      0.00152       0.0356       0.0459         12.1       0.0335\n",
            "     24   470      0.00322      0.00279     0.000431       0.0354       0.0454         6.42       0.0178\n",
            "     24   480       0.0044      0.00342     0.000979       0.0376       0.0502         9.67       0.0269\n",
            "     24   490       0.0034      0.00324     0.000169       0.0369       0.0488         4.02       0.0112\n",
            "     24   500      0.00454      0.00393     0.000615       0.0414       0.0538         7.67       0.0213\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     24    10      0.00331      0.00331     3.53e-06       0.0381       0.0494        0.401      0.00111\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              24 3154.085    0.004      0.00379     0.000259      0.00405       0.0402       0.0529         4.03       0.0112\n",
            "! Validation         24 3154.085    0.004      0.00325     7.85e-06      0.00326       0.0372        0.049        0.655      0.00182\n",
            "Wall time: 3154.084908396\n",
            "! Best model       24    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     25    10      0.00438      0.00401     0.000375       0.0415       0.0544         5.99       0.0166\n",
            "     25    20      0.00405      0.00385     0.000195       0.0411       0.0533         4.31        0.012\n",
            "     25    30      0.00448      0.00433     0.000149       0.0424       0.0565         3.77       0.0105\n",
            "     25    40      0.00429      0.00427     1.79e-05        0.042       0.0561         1.31      0.00363\n",
            "     25    50      0.00387      0.00374     0.000133       0.0401       0.0525         3.57      0.00991\n",
            "     25    60      0.00331       0.0033     1.28e-05       0.0382       0.0493         1.11      0.00307\n",
            "     25    70      0.00373      0.00373     6.31e-06       0.0403       0.0524        0.777      0.00216\n",
            "     25    80      0.00432      0.00423     9.49e-05       0.0427       0.0558         3.01      0.00836\n",
            "     25    90      0.00363      0.00318     0.000456       0.0369       0.0484          6.6       0.0183\n",
            "     25   100      0.00449       0.0041     0.000393       0.0409        0.055         6.13        0.017\n",
            "     25   110      0.00354      0.00353     3.42e-06       0.0398       0.0511        0.571      0.00159\n",
            "     25   120      0.00388      0.00379     9.25e-05        0.039       0.0529         2.97      0.00826\n",
            "     25   130      0.00363      0.00362     2.29e-06       0.0396       0.0517        0.468       0.0013\n",
            "     25   140      0.00448      0.00415     0.000326       0.0412       0.0553         5.58       0.0155\n",
            "     25   150      0.00384      0.00379     5.13e-05       0.0393       0.0529         2.21      0.00615\n",
            "     25   160      0.00488      0.00461     0.000271       0.0445       0.0583         5.09       0.0141\n",
            "     25   170      0.00406      0.00405     4.54e-06        0.041       0.0547        0.659      0.00183\n",
            "     25   180      0.00432      0.00385     0.000475       0.0404       0.0533         6.74       0.0187\n",
            "     25   190      0.00353      0.00353     3.35e-06       0.0395        0.051        0.566      0.00157\n",
            "     25   200      0.00311       0.0031      7.1e-06       0.0369       0.0478        0.824      0.00229\n",
            "     25   210      0.00375      0.00351     0.000232       0.0374       0.0509         4.71       0.0131\n",
            "     25   220      0.00404      0.00389     0.000145       0.0406       0.0536         3.73       0.0104\n",
            "     25   230      0.00352      0.00342     0.000103        0.037       0.0502         3.14      0.00872\n",
            "     25   240      0.00404      0.00404     8.52e-07       0.0415       0.0546        0.285     0.000793\n",
            "     25   250      0.00366      0.00365      2.1e-06       0.0401       0.0519        0.448      0.00124\n",
            "     25   260      0.00323      0.00299     0.000234       0.0366        0.047         4.72       0.0131\n",
            "     25   270      0.00403      0.00385     0.000182       0.0399       0.0533         4.17       0.0116\n",
            "     25   280      0.00388      0.00388     3.75e-06       0.0411       0.0535        0.599      0.00166\n",
            "     25   290      0.00305      0.00305     2.17e-07       0.0363       0.0474        0.144       0.0004\n",
            "     25   300      0.00441      0.00426     0.000156       0.0418        0.056         3.86       0.0107\n",
            "     25   310      0.00452      0.00363     0.000888       0.0393       0.0517         9.21       0.0256\n",
            "     25   320      0.00448      0.00419      0.00029       0.0425       0.0556         5.26       0.0146\n",
            "     25   330      0.00338       0.0033     8.45e-05        0.038       0.0493         2.84       0.0079\n",
            "     25   340      0.00385      0.00378     7.56e-05       0.0398       0.0528         2.69      0.00747\n",
            "     25   350      0.00331      0.00326      4.9e-05       0.0387        0.049         2.16      0.00601\n",
            "     25   360      0.00329      0.00329     1.34e-06       0.0368       0.0493        0.358     0.000996\n",
            "     25   370      0.00521      0.00521     1.53e-07       0.0454        0.062        0.121     0.000336\n",
            "     25   380      0.00367      0.00355     0.000117         0.04       0.0512         3.35       0.0093\n",
            "     25   390      0.00383       0.0038     3.01e-05       0.0397        0.053          1.7      0.00471\n",
            "     25   400      0.00441      0.00411     0.000297       0.0418        0.055         5.33       0.0148\n",
            "     25   410      0.00348       0.0032     0.000279       0.0367       0.0486         5.17       0.0144\n",
            "     25   420      0.00407      0.00363      0.00044         0.04       0.0517         6.48        0.018\n",
            "     25   430      0.00337      0.00306      0.00031       0.0367       0.0475         5.44       0.0151\n",
            "     25   440      0.00381      0.00341     0.000391       0.0386       0.0502         6.11        0.017\n",
            "     25   450       0.0038      0.00379     4.43e-06         0.04       0.0529        0.651      0.00181\n",
            "     25   460      0.00337      0.00336     1.56e-05       0.0382       0.0497         1.22       0.0034\n",
            "     25   470      0.00516      0.00382      0.00134       0.0415       0.0531         11.3       0.0314\n",
            "     25   480      0.00474      0.00439     0.000354       0.0449       0.0569         5.82       0.0162\n",
            "     25   490      0.00424      0.00424     6.85e-07       0.0415       0.0559        0.256     0.000711\n",
            "     25   500       0.0032      0.00305      0.00015        0.036       0.0474         3.78       0.0105\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     25    10      0.00324      0.00324      3.7e-06       0.0377       0.0489        0.414      0.00115\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              25 3284.656    0.004      0.00367     0.000191      0.00386       0.0396       0.0521         3.32      0.00922\n",
            "! Validation         25 3284.656    0.004      0.00316     7.59e-06      0.00317       0.0367       0.0483        0.656      0.00182\n",
            "Wall time: 3284.656011563\n",
            "! Best model       25    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     26    10      0.00468      0.00466     1.77e-05       0.0453       0.0586          1.3      0.00361\n",
            "     26    20      0.00351      0.00346     4.54e-05       0.0388       0.0505         2.08      0.00578\n",
            "     26    30      0.00415      0.00391      0.00024       0.0417       0.0537         4.79       0.0133\n",
            "     26    40      0.00389      0.00385     4.58e-05       0.0398       0.0533         2.09      0.00581\n",
            "     26    50      0.00374      0.00371     2.94e-05       0.0403       0.0523         1.68      0.00466\n",
            "     26    60      0.00334      0.00272     0.000623       0.0335       0.0448         7.72       0.0214\n",
            "     26    70      0.00438       0.0042     0.000179       0.0399       0.0557         4.13       0.0115\n",
            "     26    80      0.00449      0.00443     5.76e-05       0.0432       0.0572         2.35      0.00652\n",
            "     26    90      0.00426      0.00419     6.59e-05        0.038       0.0556         2.51      0.00697\n",
            "     26   100      0.00386      0.00379     6.91e-05       0.0397       0.0529         2.57      0.00714\n",
            "     26   110      0.00425      0.00422     2.86e-05       0.0429       0.0558         1.65      0.00459\n",
            "     26   120        0.006      0.00559     0.000408       0.0489       0.0642         6.24       0.0173\n",
            "     26   130      0.00296      0.00295     7.27e-06       0.0358       0.0467        0.833      0.00232\n",
            "     26   140      0.00453      0.00414     0.000391       0.0425       0.0552         6.11        0.017\n",
            "     26   150      0.00295      0.00282      0.00013        0.035       0.0456         3.53      0.00981\n",
            "     26   160      0.00515      0.00473     0.000414       0.0447       0.0591         6.29       0.0175\n",
            "     26   170      0.00375      0.00375     7.96e-11       0.0385       0.0526      0.00276     7.66e-06\n",
            "     26   180      0.00533      0.00427      0.00106       0.0423       0.0561         10.1       0.0279\n",
            "     26   190       0.0041      0.00383     0.000264       0.0407       0.0532         5.02       0.0139\n",
            "     26   200      0.00416      0.00416     2.09e-06       0.0432       0.0554        0.447      0.00124\n",
            "     26   210      0.00405      0.00402      2.7e-05       0.0412       0.0545         1.61      0.00447\n",
            "     26   220      0.00334      0.00291      0.00043       0.0357       0.0464         6.41       0.0178\n",
            "     26   230      0.00358      0.00348     9.05e-05       0.0383       0.0507         2.94      0.00817\n",
            "     26   240      0.00366      0.00327     0.000386       0.0376       0.0491         6.08       0.0169\n",
            "     26   250      0.00365      0.00363     1.86e-05       0.0393       0.0517         1.33      0.00371\n",
            "     26   260      0.00533      0.00495      0.00038       0.0434       0.0604         6.03       0.0167\n",
            "     26   270      0.00272      0.00269     3.15e-05       0.0341       0.0446         1.74      0.00482\n",
            "     26   280      0.00335      0.00334     8.42e-06        0.038       0.0496        0.897      0.00249\n",
            "     26   290      0.00424      0.00377     0.000476       0.0397       0.0527         6.74       0.0187\n",
            "     26   300      0.00328      0.00327     4.24e-06       0.0377       0.0491        0.637      0.00177\n",
            "     26   310      0.00266      0.00266     1.27e-06       0.0339       0.0443        0.349     0.000968\n",
            "     26   320      0.00408        0.004     8.21e-05       0.0414       0.0543          2.8      0.00778\n",
            "     26   330      0.00366       0.0034     0.000266       0.0388       0.0501         5.04        0.014\n",
            "     26   340      0.00328      0.00309     0.000186       0.0368       0.0477         4.22       0.0117\n",
            "     26   350      0.00335      0.00316      0.00019       0.0368       0.0483         4.26       0.0118\n",
            "     26   360       0.0051      0.00444     0.000667       0.0438       0.0572         7.98       0.0222\n",
            "     26   370      0.00402      0.00395     7.13e-05       0.0415        0.054         2.61      0.00725\n",
            "     26   380      0.00493      0.00483     0.000108       0.0459       0.0597         3.21      0.00892\n",
            "     26   390      0.00443      0.00412     0.000304       0.0414       0.0551         5.39        0.015\n",
            "     26   400       0.0049       0.0044     0.000496       0.0427        0.057         6.89       0.0191\n",
            "     26   410      0.00533      0.00413       0.0012       0.0415       0.0552         10.7       0.0298\n",
            "     26   420      0.00335      0.00329      5.5e-05       0.0379       0.0493         2.29      0.00637\n",
            "     26   430      0.00615      0.00356       0.0026       0.0393       0.0512         15.8       0.0438\n",
            "     26   440      0.00383      0.00359     0.000237       0.0393       0.0515         4.76       0.0132\n",
            "     26   450      0.00345      0.00332     0.000127       0.0383       0.0495         3.49      0.00969\n",
            "     26   460      0.00345      0.00326     0.000187       0.0381        0.049         4.23       0.0118\n",
            "     26   470      0.00373      0.00373     1.56e-07       0.0399       0.0525        0.122      0.00034\n",
            "     26   480       0.0034      0.00331     8.51e-05       0.0384       0.0494         2.85      0.00792\n",
            "     26   490      0.00355      0.00353     2.08e-05       0.0387        0.051         1.41      0.00392\n",
            "     26   500      0.00432      0.00394     0.000377       0.0413       0.0539            6       0.0167\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     26    10      0.00316      0.00315     3.96e-06       0.0372       0.0482         0.46      0.00128\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              26 3415.108    0.004      0.00369     0.000248      0.00393       0.0397       0.0521         3.96        0.011\n",
            "! Validation         26 3415.108    0.004      0.00309     7.51e-06       0.0031       0.0363       0.0478        0.666      0.00185\n",
            "Wall time: 3415.108247888\n",
            "! Best model       26    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     27    10      0.00296      0.00278     0.000185       0.0351       0.0453          4.2       0.0117\n",
            "     27    20      0.00371      0.00361     9.84e-05       0.0389       0.0516         3.07      0.00852\n",
            "     27    30      0.00317      0.00313      3.5e-05       0.0366       0.0481         1.83      0.00508\n",
            "     27    40      0.00328      0.00327     7.91e-06       0.0383       0.0491         0.87      0.00242\n",
            "     27    50      0.00333      0.00332     1.29e-05       0.0374       0.0495         1.11      0.00308\n",
            "     27    60      0.00305      0.00305     2.81e-06       0.0363       0.0474        0.518      0.00144\n",
            "     27    70       0.0036      0.00348      0.00012       0.0395       0.0507         3.39       0.0094\n",
            "     27    80      0.00373      0.00346     0.000274        0.038       0.0505         5.12       0.0142\n",
            "     27    90      0.00351      0.00343     7.85e-05       0.0379       0.0503         2.74      0.00761\n",
            "     27   100       0.0044      0.00348     0.000922       0.0393       0.0506         9.39       0.0261\n",
            "     27   110      0.00325      0.00325     8.03e-06       0.0381       0.0489        0.876      0.00243\n",
            "     27   120      0.00295      0.00281     0.000143       0.0356       0.0455          3.7       0.0103\n",
            "     27   130       0.0045      0.00403     0.000475       0.0411       0.0545         6.74       0.0187\n",
            "     27   140      0.00319      0.00319     1.26e-12       0.0373       0.0485     0.000348     9.66e-07\n",
            "     27   150      0.00379       0.0037     9.18e-05       0.0392       0.0522         2.96      0.00823\n",
            "     27   160      0.00379      0.00372     6.49e-05       0.0405       0.0524         2.49      0.00692\n",
            "     27   170       0.0038      0.00378     1.75e-05       0.0407       0.0528         1.29      0.00359\n",
            "     27   180      0.00372      0.00371      8.5e-06       0.0409       0.0523        0.901       0.0025\n",
            "     27   190      0.00421      0.00313      0.00108       0.0368        0.048         10.2       0.0283\n",
            "     27   200      0.00353      0.00353     9.93e-07       0.0381        0.051        0.308     0.000856\n",
            "     27   210      0.00294      0.00294     5.44e-06       0.0359       0.0465        0.721        0.002\n",
            "     27   220      0.00307      0.00298     8.66e-05        0.036       0.0469         2.88      0.00799\n",
            "     27   230      0.00304      0.00304     1.69e-06       0.0365       0.0474        0.402      0.00112\n",
            "     27   240      0.00509      0.00509     2.54e-06       0.0454       0.0613        0.492      0.00137\n",
            "     27   250      0.00424      0.00372     0.000518       0.0392       0.0524         7.04       0.0196\n",
            "     27   260      0.00314      0.00314     8.98e-06       0.0372       0.0481        0.926      0.00257\n",
            "     27   270      0.00503      0.00486     0.000169       0.0461       0.0599         4.02       0.0112\n",
            "     27   280      0.00337      0.00301      0.00036       0.0361       0.0471         5.87       0.0163\n",
            "     27   290      0.00441      0.00359     0.000821        0.039       0.0515         8.86       0.0246\n",
            "     27   300      0.00486      0.00412     0.000736       0.0431       0.0551         8.39       0.0233\n",
            "     27   310      0.00324      0.00319     5.71e-05       0.0366       0.0485         2.34      0.00649\n",
            "     27   320       0.0047      0.00386     0.000847        0.038       0.0533            9        0.025\n",
            "     27   330      0.00337      0.00336     1.41e-05       0.0375       0.0498         1.16      0.00322\n",
            "     27   340      0.00321       0.0032     1.11e-05       0.0361       0.0486         1.03      0.00286\n",
            "     27   350      0.00282      0.00254     0.000288       0.0331       0.0432         5.24       0.0146\n",
            "     27   360      0.00439      0.00427     0.000112        0.043       0.0561         3.28      0.00911\n",
            "     27   370      0.00341      0.00336     4.58e-05       0.0389       0.0498         2.09      0.00581\n",
            "     27   380        0.003      0.00278     0.000223       0.0349       0.0453         4.62       0.0128\n",
            "     27   390       0.0028       0.0028     8.51e-07       0.0351       0.0454        0.285     0.000792\n",
            "     27   400      0.00395       0.0039     5.43e-05       0.0405       0.0536         2.28      0.00633\n",
            "     27   410      0.00351      0.00351      1.5e-06       0.0383       0.0509        0.379      0.00105\n",
            "     27   420      0.00638      0.00562      0.00076       0.0467       0.0644         8.52       0.0237\n",
            "     27   430      0.00319      0.00318     5.75e-06       0.0378       0.0484        0.741      0.00206\n",
            "     27   440       0.0033      0.00325     5.09e-05       0.0374       0.0489         2.21      0.00613\n",
            "     27   450      0.00256      0.00256     8.24e-07       0.0336       0.0435        0.281      0.00078\n",
            "     27   460      0.00397      0.00352     0.000458       0.0393       0.0509         6.62       0.0184\n",
            "     27   470      0.00374      0.00353     0.000206       0.0397       0.0511         4.43       0.0123\n",
            "     27   480      0.00276      0.00266      9.6e-05       0.0339       0.0443         3.03      0.00842\n",
            "     27   490       0.0031       0.0029     0.000199       0.0347       0.0463         4.36       0.0121\n",
            "     27   500      0.00429      0.00348     0.000819        0.039       0.0506         8.85       0.0246\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     27    10      0.00309      0.00309     3.81e-06       0.0368       0.0477        0.452      0.00126\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              27 3545.757    0.004      0.00347     0.000193      0.00366       0.0385       0.0506         3.42       0.0095\n",
            "! Validation         27 3545.757    0.004      0.00302     7.63e-06      0.00302       0.0358       0.0472        0.669      0.00186\n",
            "Wall time: 3545.757582653\n",
            "! Best model       27    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     28    10      0.00269      0.00251     0.000175       0.0329        0.043         4.09       0.0114\n",
            "     28    20      0.00352      0.00309     0.000435        0.037       0.0477         6.45       0.0179\n",
            "     28    30      0.00412      0.00389     0.000233       0.0398       0.0536         4.71       0.0131\n",
            "     28    40      0.00287      0.00279     8.28e-05       0.0348       0.0454         2.81      0.00781\n",
            "     28    50      0.00374       0.0037     4.64e-05       0.0373       0.0522         2.11      0.00585\n",
            "     28    60      0.00306      0.00275     0.000309       0.0351       0.0451         5.44       0.0151\n",
            "     28    70      0.00372       0.0037     2.21e-05       0.0395       0.0522         1.45      0.00404\n",
            "     28    80      0.00423      0.00326     0.000972        0.038       0.0491         9.64       0.0268\n",
            "     28    90      0.00356      0.00354     1.48e-05       0.0391       0.0511         1.19       0.0033\n",
            "     28   100      0.00332      0.00325     7.39e-05       0.0377       0.0489         2.66      0.00738\n",
            "     28   110      0.00332      0.00308     0.000234       0.0365       0.0477         4.73       0.0131\n",
            "     28   120      0.00261       0.0026     1.45e-05       0.0332       0.0438         1.18      0.00327\n",
            "     28   130      0.00282      0.00278     4.56e-05       0.0343       0.0453         2.09       0.0058\n",
            "     28   140       0.0028      0.00276     3.69e-05       0.0344       0.0451         1.88      0.00522\n",
            "     28   150      0.00357      0.00356     6.95e-06       0.0395       0.0512        0.815      0.00226\n",
            "     28   160      0.00469      0.00468     7.28e-06       0.0446       0.0588        0.834      0.00232\n",
            "     28   170      0.00331      0.00331     9.12e-07       0.0381       0.0494        0.295      0.00082\n",
            "     28   180       0.0035      0.00278     0.000724       0.0352       0.0453         8.32       0.0231\n",
            "     28   190      0.00357      0.00336     0.000206       0.0379       0.0498         4.44       0.0123\n",
            "     28   200      0.00347      0.00334     0.000129       0.0368       0.0496         3.51      0.00975\n",
            "     28   210      0.00322      0.00321     4.13e-06       0.0369       0.0487        0.628      0.00175\n",
            "     28   220      0.00358      0.00356     1.24e-05       0.0395       0.0513         1.09      0.00302\n",
            "     28   230      0.00439      0.00376     0.000636       0.0397       0.0526          7.8       0.0217\n",
            "     28   240      0.00346      0.00345      1.5e-05        0.038       0.0504          1.2      0.00332\n",
            "     28   250      0.00334       0.0031     0.000243       0.0366       0.0478         4.82       0.0134\n",
            "     28   260      0.00405      0.00334     0.000711       0.0381       0.0496         8.24       0.0229\n",
            "     28   270      0.00474      0.00464     9.67e-05       0.0444       0.0585         3.04      0.00845\n",
            "     28   280      0.00312      0.00312     8.37e-07       0.0356       0.0479        0.283     0.000786\n",
            "     28   290      0.00506      0.00444      0.00062       0.0432       0.0572          7.7       0.0214\n",
            "     28   300      0.00297      0.00283      0.00014       0.0355       0.0457         3.65       0.0101\n",
            "     28   310      0.00417      0.00414     2.94e-05       0.0432       0.0552         1.68      0.00465\n",
            "     28   320      0.00256      0.00255     7.44e-06        0.034       0.0434        0.843      0.00234\n",
            "     28   330      0.00384      0.00297     0.000874       0.0355       0.0468         9.14       0.0254\n",
            "     28   340      0.00413      0.00316     0.000966       0.0383       0.0483         9.61       0.0267\n",
            "     28   350      0.00414      0.00379     0.000344       0.0388       0.0529         5.74       0.0159\n",
            "     28   360      0.00291       0.0029     1.28e-05       0.0353       0.0462          1.1      0.00307\n",
            "     28   370      0.00412      0.00361     0.000508       0.0395       0.0516         6.97       0.0193\n",
            "     28   380      0.00471      0.00458     0.000123       0.0454       0.0582         3.43      0.00952\n",
            "     28   390      0.00312      0.00305     7.26e-05       0.0361       0.0474         2.63      0.00732\n",
            "     28   400      0.00315       0.0031     4.99e-05       0.0369       0.0478         2.18      0.00607\n",
            "     28   410      0.00309      0.00307     2.11e-05       0.0368       0.0476         1.42      0.00395\n",
            "     28   420      0.00339      0.00339     7.23e-07       0.0378         0.05        0.263      0.00073\n",
            "     28   430      0.00376       0.0032     0.000562       0.0371       0.0485         7.33       0.0204\n",
            "     28   440      0.00347      0.00309      0.00038       0.0357       0.0478         6.03       0.0167\n",
            "     28   450      0.00337      0.00329     7.26e-05       0.0373       0.0493         2.63      0.00732\n",
            "     28   460       0.0035      0.00348     2.16e-05       0.0389       0.0506         1.44      0.00399\n",
            "     28   470      0.00338      0.00338      8.2e-06       0.0375       0.0499        0.886      0.00246\n",
            "     28   480      0.00364      0.00351     0.000136       0.0392       0.0509         3.61         0.01\n",
            "     28   490      0.00401      0.00395     5.67e-05       0.0395        0.054         2.33      0.00646\n",
            "     28   500      0.00331      0.00311       0.0002       0.0366       0.0479         4.37       0.0121\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     28    10      0.00302      0.00301     3.59e-06       0.0364       0.0471        0.411      0.00114\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              28 3676.216    0.004      0.00338     0.000206      0.00358        0.038       0.0499          3.6         0.01\n",
            "! Validation         28 3676.216    0.004      0.00294     7.96e-06      0.00295       0.0354       0.0466        0.657      0.00182\n",
            "Wall time: 3676.216746139\n",
            "! Best model       28    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     29    10      0.00417      0.00399     0.000179       0.0401       0.0542         4.14       0.0115\n",
            "     29    20      0.00293      0.00285     8.19e-05       0.0352       0.0458          2.8      0.00777\n",
            "     29    30       0.0025      0.00246     4.69e-05       0.0334       0.0426         2.12      0.00588\n",
            "     29    40      0.00372      0.00353      0.00019       0.0396       0.0511         4.26       0.0118\n",
            "     29    50      0.00322       0.0029     0.000321        0.036       0.0462         5.54       0.0154\n",
            "     29    60      0.00401      0.00374     0.000268       0.0398       0.0525         5.06       0.0141\n",
            "     29    70      0.00306      0.00297     9.29e-05       0.0358       0.0468         2.98      0.00828\n",
            "     29    80      0.00302      0.00294     7.81e-05        0.036       0.0466         2.73      0.00759\n",
            "     29    90      0.00365      0.00365     4.17e-09       0.0395       0.0519         0.02     5.54e-05\n",
            "     29   100      0.00392       0.0039      1.6e-05       0.0395       0.0537         1.24      0.00343\n",
            "     29   110      0.00384      0.00383     1.77e-05       0.0403       0.0531          1.3      0.00362\n",
            "     29   120      0.00335      0.00335     1.51e-07       0.0376       0.0497         0.12     0.000334\n",
            "     29   130      0.00297       0.0027      0.00027       0.0352       0.0446         5.08       0.0141\n",
            "     29   140      0.00327      0.00321     5.86e-05       0.0373       0.0487         2.37      0.00657\n",
            "     29   150      0.00326      0.00305     0.000209       0.0362       0.0474         4.47       0.0124\n",
            "     29   160      0.00348      0.00343     5.22e-05       0.0385       0.0503         2.23       0.0062\n",
            "     29   170      0.00316      0.00316     2.43e-06       0.0373       0.0483        0.482      0.00134\n",
            "     29   180      0.00484      0.00454     0.000296       0.0437       0.0579         5.31       0.0148\n",
            "     29   190      0.00378      0.00331     0.000468       0.0376       0.0494         6.69       0.0186\n",
            "     29   200      0.00306      0.00306     9.07e-07       0.0365       0.0475        0.294     0.000818\n",
            "     29   210      0.00353       0.0034     0.000124       0.0388       0.0501         3.44      0.00957\n",
            "     29   220      0.00373      0.00373     4.07e-08       0.0404       0.0525       0.0624     0.000173\n",
            "     29   230      0.00363      0.00358     5.01e-05       0.0395       0.0514         2.19      0.00608\n",
            "     29   240      0.00366      0.00351     0.000149       0.0391       0.0509         3.77       0.0105\n",
            "     29   250      0.00278      0.00271     7.53e-05       0.0334       0.0447         2.68      0.00745\n",
            "     29   260      0.00324      0.00324     4.66e-06       0.0379       0.0489        0.668      0.00185\n",
            "     29   270      0.00319      0.00305      0.00014       0.0362       0.0474         3.65       0.0101\n",
            "     29   280      0.00441      0.00418     0.000232       0.0422       0.0555         4.71       0.0131\n",
            "     29   290      0.00385      0.00383     2.41e-05       0.0401       0.0532         1.52      0.00421\n",
            "     29   300      0.00356      0.00312     0.000439       0.0369        0.048         6.48        0.018\n",
            "     29   310      0.00282      0.00281     6.96e-06       0.0344       0.0456        0.815      0.00227\n",
            "     29   320      0.00395      0.00386     8.47e-05         0.04       0.0534         2.85       0.0079\n",
            "     29   330      0.00406      0.00376     0.000308         0.04       0.0526         5.42       0.0151\n",
            "     29   340      0.00311      0.00292     0.000191       0.0357       0.0464         4.27       0.0119\n",
            "     29   350      0.00449      0.00427     0.000228       0.0426       0.0561         4.66        0.013\n",
            "     29   360      0.00414      0.00406     8.35e-05       0.0416       0.0547         2.83      0.00785\n",
            "     29   370      0.00256      0.00256     1.06e-08       0.0332       0.0434       0.0318     8.84e-05\n",
            "     29   380      0.00409      0.00402     7.34e-05       0.0417       0.0544         2.65      0.00736\n",
            "     29   390      0.00525      0.00515     0.000103       0.0455       0.0616         3.15      0.00874\n",
            "     29   400      0.00298      0.00249     0.000485       0.0326       0.0429         6.81       0.0189\n",
            "     29   410      0.00295      0.00292     3.22e-05        0.036       0.0464         1.75      0.00487\n",
            "     29   420      0.00384      0.00365      0.00019       0.0387       0.0519         4.26       0.0118\n",
            "     29   430      0.00403      0.00386     0.000167       0.0415       0.0534         3.99       0.0111\n",
            "     29   440      0.00287      0.00286     4.14e-06       0.0353        0.046        0.629      0.00175\n",
            "     29   450      0.00369      0.00354     0.000153       0.0394       0.0511         3.82       0.0106\n",
            "     29   460       0.0031      0.00309     8.35e-06       0.0364       0.0478        0.894      0.00248\n",
            "     29   470      0.00381      0.00381      8.6e-07       0.0399        0.053        0.287     0.000796\n",
            "     29   480      0.00397      0.00307     0.000902       0.0358       0.0476         9.29       0.0258\n",
            "     29   490      0.00281       0.0028     6.29e-06       0.0348       0.0455        0.775      0.00215\n",
            "     29   500      0.00284      0.00258     0.000261        0.034       0.0436            5       0.0139\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     29    10      0.00295      0.00294     3.68e-06        0.036       0.0466        0.411      0.00114\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              29 3806.776    0.004      0.00336     0.000168      0.00352       0.0378       0.0497         3.29      0.00914\n",
            "! Validation         29 3806.776    0.004      0.00288     8.01e-06      0.00289        0.035       0.0461        0.662      0.00184\n",
            "Wall time: 3806.7766733339995\n",
            "! Best model       29    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     30    10      0.00313      0.00307        6e-05       0.0361       0.0476         2.39      0.00665\n",
            "     30    20      0.00325      0.00325     6.63e-07       0.0382       0.0489        0.252     0.000699\n",
            "     30    30       0.0038      0.00308     0.000719       0.0371       0.0477         8.29        0.023\n",
            "     30    40      0.00318      0.00304      0.00014       0.0364       0.0474         3.66       0.0102\n",
            "     30    50      0.00435      0.00328      0.00107       0.0373       0.0492         10.1       0.0281\n",
            "     30    60      0.00379      0.00358     0.000217       0.0393       0.0514         4.56       0.0127\n",
            "     30    70      0.00287      0.00282     5.28e-05        0.035       0.0456         2.25      0.00624\n",
            "     30    80      0.00351      0.00351     2.12e-07        0.035       0.0509        0.142     0.000396\n",
            "     30    90      0.00333      0.00329     3.69e-05       0.0381       0.0493         1.88      0.00522\n",
            "     30   100       0.0031      0.00306     3.73e-05       0.0364       0.0475         1.89      0.00525\n",
            "     30   110      0.00347      0.00335     0.000118       0.0365       0.0497         3.35      0.00931\n",
            "     30   120      0.00271       0.0027      1.5e-05       0.0345       0.0446          1.2      0.00332\n",
            "     30   130      0.00282      0.00262     0.000201       0.0334       0.0439         4.38       0.0122\n",
            "     30   140      0.00344      0.00336     7.38e-05       0.0381       0.0498         2.66      0.00738\n",
            "     30   150      0.00319      0.00319     6.36e-06       0.0377       0.0485         0.78      0.00217\n",
            "     30   160      0.00282      0.00272     9.61e-05       0.0347       0.0448         3.03      0.00842\n",
            "     30   170      0.00339      0.00338     9.93e-06       0.0383         0.05        0.974      0.00271\n",
            "     30   180      0.00403      0.00336     0.000673       0.0375       0.0498         8.02       0.0223\n",
            "     30   190      0.00473      0.00473     4.63e-06       0.0441        0.059        0.665      0.00185\n",
            "     30   200      0.00397      0.00396     1.15e-05       0.0413        0.054         1.05      0.00292\n",
            "     30   210      0.00298      0.00287     0.000108       0.0351        0.046         3.22      0.00893\n",
            "     30   220      0.00365      0.00364     7.82e-06       0.0392       0.0518        0.864       0.0024\n",
            "     30   230      0.00276       0.0027     5.54e-05       0.0341       0.0446          2.3      0.00639\n",
            "     30   240      0.00375      0.00356     0.000192       0.0399       0.0512         4.28       0.0119\n",
            "     30   250      0.00484      0.00474     0.000102       0.0455       0.0591         3.13      0.00868\n",
            "     30   260      0.00316      0.00312     3.43e-05       0.0373        0.048         1.81      0.00503\n",
            "     30   270      0.00424      0.00401     0.000228       0.0405       0.0544         4.67        0.013\n",
            "     30   280       0.0044      0.00331      0.00109       0.0369       0.0494         10.2       0.0284\n",
            "     30   290      0.00426      0.00364     0.000624        0.039       0.0518         7.72       0.0214\n",
            "     30   300      0.00311      0.00309     2.25e-05       0.0359       0.0477         1.47      0.00407\n",
            "     30   310      0.00374      0.00363      0.00011       0.0394       0.0517         3.25      0.00902\n",
            "     30   320      0.00317      0.00278     0.000397       0.0344       0.0453         6.16       0.0171\n",
            "     30   330      0.00306      0.00304     2.28e-05       0.0362       0.0473         1.48       0.0041\n",
            "     30   340      0.00359      0.00304     0.000551       0.0358       0.0474         7.26       0.0202\n",
            "     30   350       0.0032      0.00318      2.6e-05       0.0382       0.0484         1.58      0.00438\n",
            "     30   360      0.00351      0.00351     3.27e-06       0.0389       0.0509        0.559      0.00155\n",
            "     30   370      0.00257      0.00256     3.24e-06       0.0331       0.0435        0.556      0.00154\n",
            "     30   380      0.00347      0.00347     1.46e-07       0.0385       0.0506        0.118     0.000328\n",
            "     30   390      0.00352      0.00337     0.000158        0.039       0.0498         3.88       0.0108\n",
            "     30   400      0.00317      0.00306     0.000107       0.0357       0.0475         3.19      0.00887\n",
            "     30   410      0.00376      0.00376     1.33e-08       0.0392       0.0526       0.0356     9.89e-05\n",
            "     30   420      0.00404      0.00401     3.26e-05       0.0416       0.0544         1.76       0.0049\n",
            "     30   430      0.00285      0.00276     9.22e-05       0.0351       0.0451         2.97      0.00825\n",
            "     30   440        0.003        0.003     1.41e-06       0.0356        0.047        0.367      0.00102\n",
            "     30   450      0.00294      0.00287     6.73e-05       0.0359        0.046         2.54      0.00705\n",
            "     30   460      0.00418      0.00406     0.000125       0.0422       0.0547         3.45      0.00959\n",
            "     30   470      0.00377      0.00364     0.000134       0.0394       0.0518         3.58      0.00995\n",
            "     30   480      0.00415        0.004     0.000152       0.0409       0.0543         3.82       0.0106\n",
            "     30   490      0.00291      0.00291     5.68e-07       0.0354       0.0463        0.233     0.000647\n",
            "     30   500      0.00556      0.00545     0.000108       0.0474       0.0634         3.21      0.00891\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     30    10      0.00289      0.00288     4.07e-06       0.0356       0.0461        0.471      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              30 3937.186    0.004      0.00332     0.000151      0.00347       0.0376       0.0495            3      0.00832\n",
            "! Validation         30 3937.186    0.004      0.00282     7.61e-06      0.00283       0.0347       0.0456         0.67      0.00186\n",
            "Wall time: 3937.1868660809996\n",
            "! Best model       30    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     31    10      0.00367      0.00356     0.000108       0.0378       0.0513         3.21      0.00891\n",
            "     31    20      0.00267      0.00263     3.98e-05       0.0338        0.044         1.95      0.00541\n",
            "     31    30      0.00331      0.00315     0.000162       0.0372       0.0482         3.93       0.0109\n",
            "     31    40      0.00352      0.00344      7.2e-05       0.0378       0.0504         2.62      0.00729\n",
            "     31    50      0.00301      0.00301     3.53e-06       0.0355       0.0471        0.581      0.00161\n",
            "     31    60      0.00397      0.00354     0.000429       0.0385       0.0511          6.4       0.0178\n",
            "     31    70      0.00561       0.0042      0.00141       0.0429       0.0556         11.6       0.0323\n",
            "     31    80       0.0037      0.00368     2.16e-05       0.0395       0.0521         1.44      0.00399\n",
            "     31    90       0.0041      0.00384     0.000259       0.0407       0.0532         4.97       0.0138\n",
            "     31   100      0.00355       0.0032     0.000344       0.0376       0.0486         5.74       0.0159\n",
            "     31   110      0.00328      0.00319     9.35e-05       0.0371       0.0485         2.99      0.00831\n",
            "     31   120      0.00354      0.00343     0.000103        0.039       0.0503         3.13       0.0087\n",
            "     31   130       0.0038      0.00366     0.000149       0.0399       0.0519         3.77       0.0105\n",
            "     31   140      0.00344      0.00279     0.000644        0.035       0.0454         7.85       0.0218\n",
            "     31   150      0.00343      0.00342     1.23e-05        0.039       0.0502         1.08      0.00301\n",
            "     31   160       0.0061      0.00585     0.000245       0.0482       0.0657         4.84       0.0135\n",
            "     31   170      0.00438      0.00438     4.43e-06       0.0436       0.0568         0.65      0.00181\n",
            "     31   180      0.00355      0.00349      6.2e-05       0.0386       0.0507         2.43      0.00676\n",
            "     31   190      0.00316      0.00307     9.69e-05        0.036       0.0476         3.04      0.00845\n",
            "     31   200      0.00424      0.00421      2.7e-05       0.0428       0.0557         1.61      0.00447\n",
            "     31   210      0.00395      0.00389     5.78e-05       0.0413       0.0536         2.35      0.00653\n",
            "     31   220      0.00398      0.00353     0.000447       0.0378       0.0511         6.54       0.0182\n",
            "     31   230       0.0029      0.00268     0.000219       0.0342       0.0445         4.57       0.0127\n",
            "     31   240      0.00353       0.0035     2.98e-05       0.0381       0.0508         1.69      0.00469\n",
            "     31   250      0.00356      0.00313     0.000431       0.0368       0.0481         6.42       0.0178\n",
            "     31   260      0.00342      0.00303     0.000386       0.0365       0.0473         6.07       0.0169\n",
            "     31   270      0.00351      0.00346     5.62e-05       0.0365       0.0505         2.32      0.00644\n",
            "     31   280      0.00366      0.00366     2.83e-06       0.0389       0.0519         0.52      0.00145\n",
            "     31   290      0.00305      0.00304     5.17e-06       0.0373       0.0474        0.703      0.00195\n",
            "     31   300      0.00243      0.00243     8.28e-09       0.0326       0.0423       0.0281     7.81e-05\n",
            "     31   310      0.00266      0.00254     0.000111       0.0334       0.0433         3.25      0.00903\n",
            "     31   320      0.00292      0.00292     1.81e-06       0.0358       0.0464        0.416      0.00116\n",
            "     31   330        0.003       0.0029     9.87e-05       0.0351       0.0463         3.07      0.00853\n",
            "     31   340      0.00253      0.00251     1.58e-05       0.0331        0.043         1.23      0.00341\n",
            "     31   350      0.00287       0.0028     6.86e-05       0.0333       0.0455         2.56      0.00711\n",
            "     31   360       0.0035      0.00312     0.000371       0.0366        0.048         5.95       0.0165\n",
            "     31   370      0.00351      0.00351     3.17e-06       0.0369       0.0509         0.55      0.00153\n",
            "     31   380      0.00388      0.00379      9.3e-05       0.0405       0.0529         2.98      0.00828\n",
            "     31   390      0.00365      0.00358     6.92e-05       0.0393       0.0514         2.57      0.00714\n",
            "     31   400      0.00292      0.00291     2.06e-06        0.035       0.0464        0.444      0.00123\n",
            "     31   410      0.00286      0.00274     0.000128       0.0339       0.0449          3.5      0.00971\n",
            "     31   420      0.00312      0.00258     0.000542       0.0338       0.0436          7.2         0.02\n",
            "     31   430      0.00394      0.00389     4.81e-05       0.0405       0.0536         2.15      0.00596\n",
            "     31   440      0.00292      0.00282       0.0001       0.0352       0.0456          3.1       0.0086\n",
            "     31   450      0.00253      0.00252     8.29e-06        0.033       0.0431         0.89      0.00247\n",
            "     31   460      0.00383      0.00376     6.17e-05       0.0404       0.0527         2.43      0.00675\n",
            "     31   470      0.00306      0.00301     4.15e-05       0.0363       0.0471         1.99      0.00553\n",
            "     31   480        0.003      0.00282     0.000176       0.0352       0.0456          4.1       0.0114\n",
            "     31   490      0.00394      0.00394     7.91e-06       0.0414       0.0539         0.87      0.00242\n",
            "     31   500      0.00327      0.00303     0.000242        0.036       0.0472         4.81       0.0134\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     31    10      0.00284      0.00284     3.99e-06       0.0353       0.0458        0.452      0.00125\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              31 4068.382    0.004      0.00325      0.00015       0.0034       0.0372       0.0489            3      0.00834\n",
            "! Validation         31 4068.382    0.004      0.00277     7.62e-06      0.00278       0.0343       0.0452        0.665      0.00185\n",
            "Wall time: 4068.3824961359996\n",
            "! Best model       31    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     32    10      0.00362      0.00358     3.89e-05       0.0391       0.0514         1.93      0.00535\n",
            "     32    20      0.00415      0.00404     0.000118       0.0407       0.0546         3.36      0.00934\n",
            "     32    30      0.00293      0.00292     8.27e-06       0.0343       0.0464        0.889      0.00247\n",
            "     32    40      0.00316      0.00314     1.98e-05       0.0366       0.0481         1.38      0.00382\n",
            "     32    50      0.00398      0.00388     9.76e-05       0.0413       0.0535         3.05      0.00849\n",
            "     32    60      0.00324      0.00308     0.000163       0.0359       0.0476         3.95        0.011\n",
            "     32    70      0.00233      0.00223     0.000105       0.0316       0.0405         3.16      0.00878\n",
            "     32    80       0.0034      0.00333     6.97e-05       0.0376       0.0495         2.58      0.00717\n",
            "     32    90      0.00259      0.00251      7.6e-05       0.0324       0.0431          2.7      0.00749\n",
            "     32   100      0.00365      0.00361     4.17e-05       0.0392       0.0516            2      0.00555\n",
            "     32   110      0.00329      0.00329     2.75e-07       0.0368       0.0492        0.162      0.00045\n",
            "     32   120      0.00241      0.00235     5.43e-05       0.0325       0.0417         2.28      0.00633\n",
            "     32   130      0.00454      0.00394     0.000607       0.0416       0.0539         7.62       0.0212\n",
            "     32   140      0.00318      0.00295     0.000233       0.0359       0.0466         4.72       0.0131\n",
            "     32   150      0.00331      0.00282      0.00049       0.0348       0.0456         6.84        0.019\n",
            "     32   160      0.00286      0.00269     0.000167       0.0327       0.0445            4       0.0111\n",
            "     32   170      0.00367      0.00365     1.91e-05       0.0396       0.0519         1.35      0.00376\n",
            "     32   180       0.0029      0.00287     2.82e-05        0.036        0.046         1.64      0.00456\n",
            "     32   190      0.00339       0.0029      0.00049        0.035       0.0462         6.84        0.019\n",
            "     32   200      0.00323      0.00319     3.65e-05       0.0363       0.0485         1.87      0.00519\n",
            "     32   210      0.00284       0.0028     3.99e-05       0.0343       0.0454         1.95      0.00542\n",
            "     32   220      0.00235      0.00235     8.07e-09        0.032       0.0417       0.0278     7.72e-05\n",
            "     32   230      0.00242      0.00229     0.000136        0.032       0.0411         3.61         0.01\n",
            "     32   240      0.00307      0.00307     1.78e-07       0.0368       0.0476         0.13     0.000362\n",
            "     32   250      0.00408      0.00392      0.00016       0.0411       0.0538         3.91       0.0108\n",
            "     32   260      0.00343      0.00339     3.85e-05       0.0383         0.05         1.92      0.00533\n",
            "     32   270       0.0033      0.00329     7.85e-06       0.0377       0.0493        0.866      0.00241\n",
            "     32   280      0.00285      0.00281     4.19e-05       0.0355       0.0455            2      0.00556\n",
            "     32   290       0.0029      0.00284     5.66e-05       0.0349       0.0458         2.33      0.00646\n",
            "     32   300        0.003      0.00285     0.000142       0.0355       0.0459         3.69       0.0102\n",
            "     32   310      0.00361      0.00301     0.000597       0.0362       0.0471         7.55        0.021\n",
            "     32   320      0.00372      0.00351     0.000209       0.0391       0.0509         4.47       0.0124\n",
            "     32   330      0.00433      0.00433     5.84e-07       0.0428       0.0565        0.236     0.000656\n",
            "     32   340      0.00282      0.00281     9.18e-06       0.0352       0.0455        0.937       0.0026\n",
            "     32   350      0.00313      0.00306     6.37e-05       0.0365       0.0475         2.47      0.00686\n",
            "     32   360      0.00374      0.00337     0.000373       0.0377       0.0498         5.97       0.0166\n",
            "     32   370      0.00307      0.00307     5.22e-07       0.0364       0.0476        0.223      0.00062\n",
            "     32   380      0.00353      0.00345     7.94e-05       0.0384       0.0504         2.76      0.00765\n",
            "     32   390      0.00458      0.00379     0.000785       0.0409       0.0529         8.66       0.0241\n",
            "     32   400      0.00317       0.0031     6.47e-05       0.0367       0.0478         2.49      0.00691\n",
            "     32   410      0.00314      0.00282     0.000321       0.0356       0.0456         5.54       0.0154\n",
            "     32   420      0.00241       0.0024     1.75e-06       0.0329       0.0421        0.409      0.00114\n",
            "     32   430      0.00331      0.00317     0.000143       0.0362       0.0483          3.7       0.0103\n",
            "     32   440      0.00352      0.00321     0.000306       0.0378       0.0487         5.41        0.015\n",
            "     32   450      0.00338        0.003     0.000383       0.0366        0.047         6.05       0.0168\n",
            "     32   460      0.00418      0.00393     0.000251       0.0417       0.0539          4.9       0.0136\n",
            "     32   470      0.00355      0.00349     5.97e-05       0.0396       0.0507         2.39      0.00664\n",
            "     32   480      0.00342      0.00342     2.98e-06       0.0379       0.0502        0.534      0.00148\n",
            "     32   490      0.00357      0.00338     0.000193       0.0385       0.0499         4.29       0.0119\n",
            "     32   500      0.00335      0.00326     8.35e-05       0.0376       0.0491         2.83      0.00785\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     32    10      0.00279      0.00278      4.3e-06       0.0349       0.0453        0.488      0.00136\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              32 4199.754    0.004      0.00318     0.000165      0.00335       0.0368       0.0485         3.18      0.00883\n",
            "! Validation         32 4199.754    0.004      0.00272     7.55e-06      0.00272        0.034       0.0448         0.67      0.00186\n",
            "Wall time: 4199.754146273\n",
            "! Best model       32    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     33    10      0.00457      0.00438     0.000191        0.042       0.0568         4.28       0.0119\n",
            "     33    20      0.00423      0.00416     6.89e-05       0.0428       0.0554         2.57      0.00713\n",
            "     33    30      0.00412      0.00385     0.000266       0.0413       0.0533         5.05        0.014\n",
            "     33    40      0.00291      0.00288     3.74e-05       0.0356       0.0461         1.89      0.00525\n",
            "     33    50      0.00408      0.00316     0.000917       0.0377       0.0483         9.36        0.026\n",
            "     33    60      0.00399      0.00393     6.29e-05       0.0404       0.0538         2.45      0.00681\n",
            "     33    70      0.00311      0.00271     0.000405       0.0346       0.0447         6.22       0.0173\n",
            "     33    80      0.00264      0.00262     2.24e-05       0.0333        0.044         1.46      0.00407\n",
            "     33    90      0.00323      0.00306     0.000163       0.0357       0.0475         3.95        0.011\n",
            "     33   100      0.00277      0.00277     9.71e-08       0.0349       0.0452       0.0963     0.000268\n",
            "     33   110      0.00385      0.00347     0.000378       0.0398       0.0506         6.01       0.0167\n",
            "     33   120      0.00355      0.00332     0.000235       0.0381       0.0495         4.74       0.0132\n",
            "     33   130      0.00491      0.00386      0.00105       0.0407       0.0534           10       0.0278\n",
            "     33   140      0.00314      0.00312     1.25e-05       0.0373        0.048          1.1      0.00304\n",
            "     33   150      0.00344      0.00299     0.000449        0.036        0.047         6.55       0.0182\n",
            "     33   160      0.00346      0.00337     9.06e-05       0.0385       0.0498         2.94      0.00818\n",
            "     33   170      0.00378      0.00346     0.000323       0.0389       0.0505         5.55       0.0154\n",
            "     33   180      0.00288      0.00287     8.46e-06        0.035        0.046        0.899       0.0025\n",
            "     33   190        0.003      0.00299     1.08e-05       0.0362        0.047         1.02      0.00282\n",
            "     33   200      0.00306      0.00296     9.98e-05       0.0355       0.0468         3.09      0.00858\n",
            "     33   210      0.00341      0.00341     4.84e-06       0.0392       0.0501         0.68      0.00189\n",
            "     33   220      0.00263      0.00261     1.35e-05       0.0339       0.0439         1.13      0.00315\n",
            "     33   230       0.0039      0.00358      0.00032       0.0388       0.0514         5.53       0.0154\n",
            "     33   240      0.00405      0.00379     0.000259       0.0403       0.0529         4.98       0.0138\n",
            "     33   250      0.00256      0.00254     1.55e-05       0.0334       0.0433         1.22      0.00338\n",
            "     33   260       0.0032      0.00312     7.28e-05       0.0376        0.048         2.64      0.00733\n",
            "     33   270      0.00387      0.00371     0.000161       0.0393       0.0523         3.92       0.0109\n",
            "     33   280      0.00452       0.0045     1.92e-05       0.0423       0.0576         1.35      0.00376\n",
            "     33   290      0.00305      0.00299     6.53e-05       0.0367        0.047          2.5      0.00694\n",
            "     33   300      0.00327      0.00324     2.89e-05       0.0378       0.0489         1.66      0.00462\n",
            "     33   310      0.00282      0.00282     2.16e-09        0.035       0.0456       0.0144     3.99e-05\n",
            "     33   320      0.00343      0.00339     3.51e-05        0.038         0.05         1.83      0.00509\n",
            "     33   330      0.00277      0.00277     1.86e-06       0.0344       0.0452        0.422      0.00117\n",
            "     33   340      0.00309      0.00298     0.000112       0.0363       0.0469         3.27      0.00908\n",
            "     33   350      0.00282      0.00272     9.65e-05       0.0345       0.0448         3.04      0.00843\n",
            "     33   360      0.00295      0.00291     3.59e-05       0.0356       0.0464         1.85      0.00515\n",
            "     33   370      0.00379      0.00303     0.000765       0.0368       0.0473         8.55       0.0238\n",
            "     33   380      0.00376       0.0034     0.000355       0.0364       0.0501         5.83       0.0162\n",
            "     33   390      0.00257      0.00252     5.41e-05       0.0336       0.0431         2.27      0.00632\n",
            "     33   400      0.00297      0.00286      0.00011       0.0353       0.0459         3.24      0.00899\n",
            "     33   410       0.0048      0.00461     0.000185       0.0451       0.0583         4.21       0.0117\n",
            "     33   420      0.00305      0.00266      0.00039       0.0345       0.0443         6.11        0.017\n",
            "     33   430      0.00391      0.00365     0.000259       0.0394       0.0519         4.98       0.0138\n",
            "     33   440      0.00371      0.00362     8.75e-05       0.0379       0.0517         2.89      0.00803\n",
            "     33   450      0.00371       0.0037     1.21e-05       0.0395       0.0522         1.07      0.00298\n",
            "     33   460      0.00326      0.00326     4.81e-07       0.0348       0.0491        0.214     0.000595\n",
            "     33   470      0.00278      0.00278     2.41e-08       0.0348       0.0453        0.048     0.000133\n",
            "     33   480      0.00267      0.00247     0.000198        0.032       0.0427         4.35       0.0121\n",
            "     33   490      0.00287      0.00285     2.19e-05       0.0347       0.0459         1.45      0.00402\n",
            "     33   500      0.00239      0.00238     9.48e-06       0.0321       0.0419        0.952      0.00264\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     33    10      0.00275      0.00275     4.17e-06       0.0346        0.045        0.467       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              33 4331.309    0.004      0.00318     0.000177      0.00336       0.0369       0.0484         3.33      0.00926\n",
            "! Validation         33 4331.309    0.004      0.00268     7.52e-06      0.00269       0.0338       0.0444        0.663      0.00184\n",
            "Wall time: 4331.3095883529995\n",
            "! Best model       33    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     34    10      0.00309       0.0028     0.000283       0.0351       0.0455          5.2       0.0144\n",
            "     34    20      0.00311      0.00291     0.000202       0.0357       0.0463         4.39       0.0122\n",
            "     34    30      0.00227      0.00217       0.0001       0.0311         0.04          3.1      0.00861\n",
            "     34    40      0.00331      0.00326     4.98e-05       0.0372        0.049         2.18      0.00606\n",
            "     34    50      0.00425      0.00407     0.000178       0.0427       0.0548         4.13       0.0115\n",
            "     34    60      0.00393      0.00372     0.000208       0.0411       0.0524         4.46       0.0124\n",
            "     34    70      0.00238      0.00236      1.9e-05       0.0323       0.0417         1.35      0.00375\n",
            "     34    80      0.00344      0.00334     9.87e-05       0.0347       0.0496         3.07      0.00853\n",
            "     34    90      0.00265      0.00265     5.67e-07       0.0338       0.0442        0.233     0.000647\n",
            "     34   100      0.00399       0.0036     0.000383       0.0397       0.0516         6.05       0.0168\n",
            "     34   110      0.00393      0.00349      0.00044       0.0395       0.0507         6.49        0.018\n",
            "     34   120      0.00327      0.00319     8.22e-05       0.0384       0.0485          2.8      0.00779\n",
            "     34   130      0.00312      0.00311     2.57e-06        0.036       0.0479        0.496      0.00138\n",
            "     34   140      0.00323      0.00317     5.87e-05       0.0373       0.0484         2.37      0.00658\n",
            "     34   150      0.00333      0.00308     0.000257       0.0367       0.0476         4.96       0.0138\n",
            "     34   160      0.00364      0.00362     2.23e-05       0.0395       0.0517         1.46      0.00405\n",
            "     34   170      0.00258      0.00255     2.66e-05       0.0335       0.0434         1.59      0.00443\n",
            "     34   180      0.00249      0.00244     4.83e-05       0.0334       0.0424         2.15      0.00597\n",
            "     34   190      0.00327      0.00326     6.61e-06       0.0381        0.049        0.795      0.00221\n",
            "     34   200      0.00381      0.00375     5.51e-05       0.0401       0.0526          2.3      0.00638\n",
            "     34   210      0.00337      0.00325     0.000119        0.037        0.049         3.37      0.00935\n",
            "     34   220      0.00323      0.00318     4.74e-05       0.0361       0.0485         2.13      0.00591\n",
            "     34   230      0.00344      0.00344      4.8e-08       0.0385       0.0504       0.0677     0.000188\n",
            "     34   240      0.00313      0.00308     4.86e-05       0.0363       0.0477         2.16      0.00599\n",
            "     34   250      0.00248       0.0024     8.64e-05        0.032        0.042         2.87      0.00798\n",
            "     34   260      0.00344      0.00321     0.000227       0.0374       0.0487         4.66       0.0129\n",
            "     34   270      0.00311      0.00287     0.000247       0.0347        0.046         4.86       0.0135\n",
            "     34   280      0.00302        0.003     2.04e-05       0.0363       0.0471          1.4      0.00388\n",
            "     34   290      0.00383      0.00327     0.000558       0.0383       0.0491          7.3       0.0203\n",
            "     34   300      0.00364      0.00343     0.000216       0.0384       0.0503         4.55       0.0126\n",
            "     34   310      0.00265      0.00264     1.15e-05       0.0327       0.0441         1.05      0.00291\n",
            "     34   320      0.00308      0.00307     1.47e-05       0.0363       0.0476         1.19      0.00329\n",
            "     34   330      0.00359      0.00346     0.000138       0.0395       0.0505         3.63       0.0101\n",
            "     34   340      0.00375      0.00347     0.000281        0.039       0.0506         5.18       0.0144\n",
            "     34   350      0.00312      0.00298     0.000137        0.035       0.0469         3.62       0.0101\n",
            "     34   360      0.00321      0.00297     0.000242       0.0359       0.0468         4.81       0.0134\n",
            "     34   370      0.00315      0.00289     0.000255       0.0353       0.0462         4.94       0.0137\n",
            "     34   380      0.00367      0.00342     0.000252       0.0383       0.0502          4.9       0.0136\n",
            "     34   390      0.00277      0.00268     8.81e-05       0.0348       0.0445          2.9      0.00806\n",
            "     34   400      0.00255      0.00243     0.000123       0.0326       0.0423         3.43      0.00952\n",
            "     34   410      0.00396      0.00393     2.75e-05        0.041       0.0539         1.62       0.0045\n",
            "     34   420      0.00413       0.0039     0.000223       0.0418       0.0537         4.62       0.0128\n",
            "     34   430       0.0041      0.00382     0.000281       0.0413       0.0531         5.18       0.0144\n",
            "     34   440      0.00291      0.00272     0.000188       0.0346       0.0448         4.23       0.0118\n",
            "     34   450      0.00374      0.00374     7.45e-07       0.0391       0.0525        0.267     0.000741\n",
            "     34   460       0.0047      0.00468     1.39e-05       0.0435       0.0588         1.15       0.0032\n",
            "     34   470       0.0034      0.00339     1.07e-05       0.0376         0.05         1.01      0.00281\n",
            "     34   480      0.00319      0.00317     2.03e-05       0.0366       0.0484         1.39      0.00387\n",
            "     34   490      0.00349      0.00342     6.71e-05       0.0382       0.0503         2.53      0.00704\n",
            "     34   500      0.00258      0.00232     0.000268       0.0321       0.0413         5.06       0.0141\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     34    10       0.0027       0.0027     4.11e-06       0.0343       0.0446        0.458      0.00127\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              34 4462.563    0.004      0.00315     0.000114      0.00327       0.0367       0.0482         2.69      0.00747\n",
            "! Validation         34 4462.563    0.004      0.00263     7.58e-06      0.00264       0.0335       0.0441        0.662      0.00184\n",
            "Wall time: 4462.563101748\n",
            "! Best model       34    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     35    10      0.00335       0.0031     0.000248        0.036       0.0478         4.87       0.0135\n",
            "     35    20      0.00343      0.00293     0.000499       0.0357       0.0465          6.9       0.0192\n",
            "     35    30       0.0029      0.00283     6.37e-05       0.0341       0.0457         2.47      0.00686\n",
            "     35    40      0.00225      0.00219     5.14e-05       0.0312       0.0402         2.22      0.00616\n",
            "     35    50      0.00271       0.0027     5.34e-06       0.0346       0.0447        0.715      0.00198\n",
            "     35    60      0.00261      0.00216     0.000446        0.031       0.0399         6.53       0.0181\n",
            "     35    70      0.00292      0.00256     0.000366       0.0332       0.0434         5.92       0.0164\n",
            "     35    80      0.00281      0.00264     0.000173       0.0339       0.0441         4.06       0.0113\n",
            "     35    90      0.00346      0.00332     0.000144       0.0374       0.0495          3.7       0.0103\n",
            "     35   100      0.00371      0.00224      0.00148       0.0308       0.0406         11.9        0.033\n",
            "     35   110      0.00393       0.0027      0.00123       0.0342       0.0446         10.9       0.0302\n",
            "     35   120      0.00404      0.00344     0.000598       0.0386       0.0504         7.56        0.021\n",
            "     35   130      0.00247      0.00246     8.98e-06       0.0324       0.0426        0.927      0.00257\n",
            "     35   140      0.00263      0.00263     3.18e-06       0.0342       0.0441        0.551      0.00153\n",
            "     35   150      0.00311      0.00309     1.98e-05       0.0374       0.0477         1.38      0.00382\n",
            "     35   160      0.00341      0.00318     0.000224       0.0376       0.0485         4.62       0.0128\n",
            "     35   170      0.00243      0.00235     7.89e-05       0.0326       0.0416         2.75      0.00763\n",
            "     35   180      0.00434      0.00424     0.000101       0.0414       0.0559          3.1      0.00862\n",
            "     35   190      0.00267      0.00267     3.96e-07       0.0339       0.0444        0.194      0.00054\n",
            "     35   200      0.00285      0.00271      0.00014       0.0343       0.0447         3.65       0.0101\n",
            "     35   210      0.00309      0.00309     5.21e-06       0.0354       0.0477        0.706      0.00196\n",
            "     35   220      0.00265      0.00265     3.98e-06       0.0332       0.0442        0.617      0.00171\n",
            "     35   230      0.00302      0.00292     0.000102       0.0347       0.0464         3.13      0.00869\n",
            "     35   240      0.00362      0.00352     0.000105       0.0392       0.0509         3.17      0.00881\n",
            "     35   250      0.00327      0.00321     6.76e-05       0.0374       0.0486         2.54      0.00706\n",
            "     35   260      0.00422      0.00417     5.13e-05       0.0434       0.0555         2.21      0.00615\n",
            "     35   270       0.0024      0.00233      6.6e-05       0.0323       0.0415         2.51      0.00698\n",
            "     35   280      0.00464      0.00464     4.93e-07       0.0424       0.0585        0.217     0.000603\n",
            "     35   290      0.00269      0.00263     6.72e-05       0.0335        0.044         2.54      0.00704\n",
            "     35   300      0.00407        0.004     7.16e-05       0.0412       0.0543         2.62      0.00727\n",
            "     35   310      0.00328       0.0028     0.000482       0.0351       0.0454         6.79       0.0189\n",
            "     35   320      0.00225      0.00225     2.63e-06       0.0321       0.0407        0.501      0.00139\n",
            "     35   330      0.00315      0.00314     1.02e-05       0.0375       0.0481        0.988      0.00274\n",
            "     35   340      0.00371      0.00365     6.37e-05       0.0398       0.0519         2.47      0.00685\n",
            "     35   350      0.00264      0.00263     8.04e-06       0.0349       0.0441        0.877      0.00244\n",
            "     35   360       0.0035      0.00286     0.000646       0.0352       0.0459         7.86       0.0218\n",
            "     35   370      0.00362      0.00353     8.99e-05       0.0394        0.051         2.93      0.00814\n",
            "     35   380      0.00362      0.00335      0.00028       0.0377       0.0497         5.17       0.0144\n",
            "     35   390      0.00433      0.00432     4.47e-06       0.0433       0.0565        0.654      0.00182\n",
            "     35   400      0.00287      0.00222     0.000641       0.0315       0.0405         7.83       0.0217\n",
            "     35   410      0.00349      0.00271     0.000777        0.034       0.0447         8.62       0.0239\n",
            "     35   420      0.00237      0.00236     8.96e-06       0.0319       0.0418        0.925      0.00257\n",
            "     35   430      0.00402      0.00384     0.000184       0.0404       0.0532         4.19       0.0116\n",
            "     35   440      0.00328      0.00302     0.000264       0.0362       0.0472         5.02       0.0139\n",
            "     35   450      0.00257      0.00257      5.2e-06       0.0329       0.0435        0.705      0.00196\n",
            "     35   460       0.0025       0.0025     4.54e-06       0.0331       0.0429        0.659      0.00183\n",
            "     35   470      0.00251      0.00251     2.37e-07       0.0332        0.043         0.15     0.000418\n",
            "     35   480      0.00391      0.00386      5.3e-05        0.039       0.0533         2.25      0.00625\n",
            "     35   490      0.00386       0.0038     6.09e-05       0.0384        0.053         2.41       0.0067\n",
            "     35   500      0.00295       0.0029     5.54e-05       0.0354       0.0462          2.3      0.00639\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     35    10      0.00267      0.00266     4.49e-06       0.0341       0.0443        0.511      0.00142\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              35 4593.659    0.004      0.00302     0.000201      0.00322       0.0359       0.0472         3.61         0.01\n",
            "! Validation         35 4593.659    0.004      0.00259      7.6e-06       0.0026       0.0332       0.0437        0.676      0.00188\n",
            "Wall time: 4593.659524766\n",
            "! Best model       35    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     36    10      0.00326      0.00318      7.8e-05       0.0363       0.0484         2.73      0.00759\n",
            "     36    20       0.0025      0.00244     5.72e-05       0.0331       0.0424         2.34       0.0065\n",
            "     36    30       0.0026      0.00256     3.95e-05       0.0334       0.0435         1.94       0.0054\n",
            "     36    40      0.00346      0.00344     1.31e-05       0.0381       0.0504         1.12      0.00311\n",
            "     36    50      0.00248      0.00244     4.54e-05       0.0318       0.0424         2.08      0.00579\n",
            "     36    60      0.00266      0.00266      2.7e-07       0.0343       0.0443        0.161     0.000446\n",
            "     36    70      0.00285      0.00285     3.85e-07       0.0344       0.0459        0.192     0.000533\n",
            "     36    80      0.00307      0.00301      6.3e-05       0.0366       0.0471         2.45      0.00682\n",
            "     36    90      0.00346      0.00332     0.000141       0.0381       0.0495         3.68       0.0102\n",
            "     36   100      0.00386      0.00375     0.000105       0.0409       0.0526         3.17      0.00882\n",
            "     36   110      0.00377      0.00367     0.000102       0.0398        0.052         3.12      0.00867\n",
            "     36   120      0.00235      0.00234     3.89e-06       0.0322       0.0416        0.609      0.00169\n",
            "     36   130      0.00431      0.00419      0.00012       0.0426       0.0556         3.39      0.00941\n",
            "     36   140      0.00301      0.00292      8.9e-05       0.0353       0.0464         2.92       0.0081\n",
            "     36   150      0.00288      0.00288     3.06e-06       0.0352       0.0461        0.541       0.0015\n",
            "     36   160      0.00398      0.00398     3.94e-06       0.0401       0.0542        0.614       0.0017\n",
            "     36   170      0.00239      0.00225     0.000148       0.0314       0.0407         3.76       0.0104\n",
            "     36   180      0.00331        0.003     0.000317        0.036        0.047         5.51       0.0153\n",
            "     36   190      0.00323      0.00306     0.000166       0.0366       0.0475         3.98       0.0111\n",
            "     36   200      0.00275      0.00273     1.97e-05       0.0338       0.0449         1.37      0.00381\n",
            "     36   210      0.00346      0.00346     3.71e-06       0.0382       0.0505        0.595      0.00165\n",
            "     36   220      0.00296      0.00292     3.76e-05       0.0355       0.0464          1.9      0.00527\n",
            "     36   230      0.00345      0.00338     7.17e-05       0.0384       0.0499         2.62      0.00727\n",
            "     36   240      0.00316      0.00313     2.75e-05       0.0358        0.048         1.62      0.00451\n",
            "     36   250      0.00254      0.00253     2.02e-06       0.0331       0.0432        0.439      0.00122\n",
            "     36   260      0.00267      0.00267     3.85e-06       0.0343       0.0444        0.607      0.00168\n",
            "     36   270      0.00295      0.00284     0.000113       0.0354       0.0458         3.28      0.00912\n",
            "     36   280      0.00297      0.00277       0.0002       0.0347       0.0452         4.37       0.0121\n",
            "     36   290      0.00263      0.00262     1.49e-05       0.0342       0.0439         1.19      0.00332\n",
            "     36   300      0.00243      0.00232     0.000103       0.0315       0.0414         3.14      0.00873\n",
            "     36   310      0.00351      0.00345     5.38e-05       0.0389       0.0505         2.27       0.0063\n",
            "     36   320      0.00266      0.00259     6.39e-05       0.0331       0.0437         2.47      0.00686\n",
            "     36   330      0.00322      0.00322      4.9e-07       0.0368       0.0487        0.217     0.000601\n",
            "     36   340      0.00318      0.00298       0.0002       0.0359       0.0469         4.37       0.0121\n",
            "     36   350      0.00222      0.00222     1.19e-07       0.0313       0.0404        0.106     0.000296\n",
            "     36   360      0.00478      0.00475     2.82e-05       0.0448       0.0592         1.64      0.00456\n",
            "     36   370      0.00235      0.00235     1.95e-08       0.0324       0.0416       0.0431      0.00012\n",
            "     36   380      0.00328      0.00322     6.33e-05       0.0375       0.0487         2.46      0.00684\n",
            "     36   390      0.00283      0.00264      0.00019       0.0336       0.0441         4.26       0.0118\n",
            "     36   400      0.00326      0.00306     0.000202       0.0369       0.0475          4.4       0.0122\n",
            "     36   410      0.00245      0.00241     3.76e-05       0.0333       0.0422          1.9      0.00527\n",
            "     36   420       0.0039      0.00376     0.000143       0.0393       0.0526          3.7       0.0103\n",
            "     36   430      0.00324      0.00321     2.92e-05       0.0375       0.0486         1.67      0.00464\n",
            "     36   440      0.00291       0.0029      6.9e-06        0.036       0.0463        0.812      0.00226\n",
            "     36   450      0.00388      0.00387     3.77e-06        0.041       0.0534          0.6      0.00167\n",
            "     36   460       0.0027      0.00223     0.000473       0.0314       0.0406         6.72       0.0187\n",
            "     36   470      0.00272      0.00248     0.000239        0.033       0.0428         4.78       0.0133\n",
            "     36   480      0.00347      0.00329      0.00018       0.0377       0.0493         4.15       0.0115\n",
            "     36   490      0.00308      0.00304      4.2e-05       0.0366       0.0474            2      0.00556\n",
            "     36   500      0.00297      0.00279     0.000176       0.0349       0.0454          4.1       0.0114\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     36    10      0.00263      0.00263     4.43e-06       0.0338        0.044        0.508      0.00141\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              36 4725.042    0.004      0.00298      0.00011      0.00309       0.0356       0.0469         2.59       0.0072\n",
            "! Validation         36 4725.042    0.004      0.00255     7.66e-06      0.00256       0.0329       0.0433        0.678      0.00188\n",
            "Wall time: 4725.042881708\n",
            "! Best model       36    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     37    10      0.00263      0.00255     7.71e-05       0.0333       0.0434         2.71      0.00754\n",
            "     37    20      0.00358      0.00342     0.000154       0.0383       0.0502         3.84       0.0107\n",
            "     37    30      0.00584      0.00513     0.000715       0.0463       0.0615         8.27        0.023\n",
            "     37    40      0.00335      0.00314     0.000212       0.0371       0.0481          4.5       0.0125\n",
            "     37    50      0.00459      0.00393     0.000665        0.038       0.0538         7.98       0.0222\n",
            "     37    60      0.00324      0.00304     0.000208       0.0362       0.0473         4.46       0.0124\n",
            "     37    70      0.00323      0.00307     0.000159       0.0368       0.0476          3.9       0.0108\n",
            "     37    80      0.00334      0.00328     6.29e-05       0.0379       0.0492         2.45      0.00681\n",
            "     37    90       0.0037       0.0037     3.79e-07       0.0393       0.0522         0.19     0.000529\n",
            "     37   100      0.00246      0.00246     1.54e-06       0.0328       0.0426        0.383      0.00106\n",
            "     37   110      0.00282       0.0028     1.42e-05       0.0346       0.0455         1.16      0.00323\n",
            "     37   120      0.00271      0.00269     1.33e-05       0.0343       0.0446         1.13      0.00313\n",
            "     37   130      0.00345      0.00345        7e-08       0.0386       0.0504       0.0818     0.000227\n",
            "     37   140      0.00264      0.00263     1.72e-05       0.0337        0.044         1.28      0.00356\n",
            "     37   150      0.00344       0.0025     0.000934        0.033        0.043         9.45       0.0263\n",
            "     37   160      0.00275       0.0026     0.000157       0.0333       0.0438         3.87       0.0108\n",
            "     37   170       0.0031      0.00305     4.94e-05       0.0356       0.0474         2.17      0.00604\n",
            "     37   180      0.00311       0.0031     1.22e-05        0.037       0.0478         1.08        0.003\n",
            "     37   190       0.0036      0.00284     0.000755        0.035       0.0458          8.5       0.0236\n",
            "     37   200      0.00371      0.00369     2.07e-05       0.0397       0.0522         1.41      0.00391\n",
            "     37   210      0.00247      0.00246     8.69e-06       0.0322       0.0426        0.912      0.00253\n",
            "     37   220      0.00293      0.00248     0.000443       0.0333       0.0428         6.51       0.0181\n",
            "     37   230      0.00302      0.00278     0.000236       0.0331       0.0453         4.75       0.0132\n",
            "     37   240      0.00269      0.00269     5.83e-08       0.0343       0.0445       0.0747     0.000207\n",
            "     37   250      0.00235      0.00221     0.000141       0.0314       0.0404         3.67       0.0102\n",
            "     37   260      0.00331      0.00307     0.000242       0.0368       0.0476         4.81       0.0134\n",
            "     37   270      0.00262      0.00259     3.09e-05       0.0343       0.0437         1.72      0.00477\n",
            "     37   280      0.00321      0.00248     0.000736       0.0328       0.0427         8.39       0.0233\n",
            "     37   290      0.00329      0.00291     0.000374       0.0354       0.0463         5.98       0.0166\n",
            "     37   300      0.00227      0.00226     7.06e-06       0.0317       0.0409        0.822      0.00228\n",
            "     37   310      0.00251      0.00236     0.000149        0.032       0.0417         3.77       0.0105\n",
            "     37   320      0.00285      0.00284      1.9e-06       0.0355       0.0458        0.426      0.00118\n",
            "     37   330      0.00312      0.00294     0.000178       0.0363       0.0466         4.12       0.0115\n",
            "     37   340      0.00363      0.00362     1.55e-05       0.0401       0.0517         1.22      0.00338\n",
            "     37   350      0.00378      0.00355     0.000227       0.0385       0.0512         4.66        0.013\n",
            "     37   360      0.00223      0.00217     5.97e-05       0.0307         0.04         2.39      0.00664\n",
            "     37   370      0.00404      0.00339     0.000643       0.0386         0.05         7.84       0.0218\n",
            "     37   380      0.00287      0.00261     0.000261       0.0331       0.0439         4.99       0.0139\n",
            "     37   390      0.00254      0.00253     1.54e-05       0.0333       0.0432         1.21      0.00337\n",
            "     37   400      0.00402      0.00384     0.000181         0.04       0.0532         4.16       0.0115\n",
            "     37   410      0.00328      0.00321     7.12e-05       0.0347       0.0487         2.61      0.00725\n",
            "     37   420      0.00243      0.00242     1.11e-05       0.0321       0.0423         1.03      0.00286\n",
            "     37   430      0.00241       0.0024     1.34e-05       0.0325        0.042         1.13      0.00315\n",
            "     37   440      0.00218      0.00218     3.74e-07        0.031       0.0401        0.189     0.000525\n",
            "     37   450      0.00246      0.00243     2.15e-05       0.0324       0.0424         1.43      0.00398\n",
            "     37   460      0.00291      0.00285      5.8e-05       0.0348       0.0459         2.35      0.00654\n",
            "     37   470      0.00318      0.00293     0.000254       0.0362       0.0465         4.93       0.0137\n",
            "     37   480      0.00334      0.00327     6.72e-05       0.0374       0.0491         2.53      0.00704\n",
            "     37   490      0.00225      0.00221     4.27e-05        0.031       0.0403         2.02      0.00561\n",
            "     37   500      0.00307      0.00303     3.75e-05       0.0367       0.0473         1.89      0.00526\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     37    10      0.00259      0.00258     4.17e-06       0.0335       0.0437        0.462      0.00128\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              37 4856.136    0.004      0.00292     0.000174       0.0031       0.0353       0.0464         3.31       0.0092\n",
            "! Validation         37 4856.136    0.004      0.00251     7.63e-06      0.00252       0.0326        0.043        0.664      0.00184\n",
            "Wall time: 4856.136071111\n",
            "! Best model       37    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     38    10      0.00357      0.00309     0.000481       0.0372       0.0477         6.78       0.0188\n",
            "     38    20      0.00347      0.00292     0.000545       0.0353       0.0464         7.22         0.02\n",
            "     38    30      0.00305      0.00246     0.000585       0.0321       0.0426         7.48       0.0208\n",
            "     38    40       0.0029      0.00289     8.98e-06       0.0356       0.0462        0.927      0.00257\n",
            "     38    50      0.00291      0.00285     6.51e-05       0.0356       0.0458          2.5      0.00693\n",
            "     38    60      0.00242      0.00242     3.28e-06       0.0323       0.0422         0.56      0.00156\n",
            "     38    70      0.00297      0.00297     8.65e-09       0.0351       0.0468       0.0288     7.99e-05\n",
            "     38    80      0.00295      0.00294      7.6e-06       0.0361       0.0466        0.853      0.00237\n",
            "     38    90      0.00309      0.00301     7.98e-05       0.0363       0.0471         2.76      0.00767\n",
            "     38   100      0.00321      0.00321     7.34e-07       0.0372       0.0487        0.265     0.000736\n",
            "     38   110      0.00267      0.00267      2.3e-07       0.0347       0.0444        0.148     0.000412\n",
            "     38   120      0.00291      0.00268     0.000229       0.0337       0.0445         4.68        0.013\n",
            "     38   130      0.00358      0.00314      0.00044        0.036       0.0481         6.48        0.018\n",
            "     38   140      0.00281      0.00248      0.00033       0.0328       0.0427         5.61       0.0156\n",
            "     38   150      0.00238      0.00238      3.6e-06       0.0311       0.0419        0.586      0.00163\n",
            "     38   160      0.00256      0.00256     3.66e-08       0.0332       0.0435       0.0592     0.000164\n",
            "     38   170      0.00253      0.00243     0.000102       0.0328       0.0424         3.12      0.00866\n",
            "     38   180       0.0025      0.00249     1.03e-05       0.0333       0.0428        0.992      0.00275\n",
            "     38   190      0.00282       0.0028     2.31e-05       0.0346       0.0454         1.48      0.00412\n",
            "     38   200      0.00301      0.00277     0.000238       0.0344       0.0452         4.77       0.0133\n",
            "     38   210      0.00353      0.00324     0.000298       0.0364       0.0488         5.34       0.0148\n",
            "     38   220      0.00301      0.00282     0.000188        0.034       0.0456         4.24       0.0118\n",
            "     38   230      0.00335      0.00328     7.38e-05       0.0372       0.0491         2.66      0.00738\n",
            "     38   240      0.00252       0.0025     2.01e-05       0.0333        0.043         1.38      0.00385\n",
            "     38   250       0.0037      0.00322     0.000486       0.0369       0.0487         6.82       0.0189\n",
            "     38   260      0.00315      0.00239     0.000762       0.0319        0.042         8.54       0.0237\n",
            "     38   270      0.00303      0.00296     7.16e-05        0.036       0.0467         2.62      0.00727\n",
            "     38   280      0.00332      0.00322     9.37e-05       0.0381       0.0488         2.99      0.00831\n",
            "     38   290      0.00312      0.00312     2.57e-06       0.0366       0.0479        0.495      0.00138\n",
            "     38   300       0.0029      0.00287     3.19e-05       0.0346        0.046         1.74      0.00485\n",
            "     38   310      0.00272      0.00266     5.55e-05       0.0344       0.0443          2.3       0.0064\n",
            "     38   320      0.00287      0.00286     1.02e-05        0.034       0.0459        0.986      0.00274\n",
            "     38   330      0.00282      0.00276     6.48e-05       0.0345       0.0451         2.49      0.00692\n",
            "     38   340      0.00271      0.00271     1.35e-06       0.0337       0.0447        0.359     0.000998\n",
            "     38   350       0.0029      0.00288     1.69e-05       0.0355       0.0461         1.27      0.00353\n",
            "     38   360      0.00247      0.00239     7.63e-05       0.0323        0.042          2.7       0.0075\n",
            "     38   370      0.00313       0.0028     0.000332       0.0343       0.0455         5.63       0.0156\n",
            "     38   380      0.00267      0.00267     1.02e-06       0.0345       0.0444        0.312     0.000866\n",
            "     38   390      0.00295      0.00287     7.81e-05       0.0354        0.046         2.73      0.00759\n",
            "     38   400      0.00309      0.00295     0.000136       0.0356       0.0467         3.61         0.01\n",
            "     38   410      0.00267      0.00265     1.38e-05       0.0343       0.0442         1.15      0.00318\n",
            "     38   420      0.00306      0.00273     0.000325       0.0354       0.0449         5.58       0.0155\n",
            "     38   430      0.00244      0.00237     6.66e-05       0.0325       0.0418         2.52      0.00701\n",
            "     38   440      0.00304      0.00301     3.12e-05        0.036       0.0471         1.73       0.0048\n",
            "     38   450      0.00331      0.00298     0.000331        0.036       0.0469         5.63       0.0156\n",
            "     38   460      0.00212      0.00211     1.63e-05       0.0304       0.0394         1.25      0.00347\n",
            "     38   470      0.00321       0.0031     0.000107       0.0368       0.0478          3.2      0.00888\n",
            "     38   480      0.00306      0.00303     3.13e-05       0.0355       0.0472         1.73      0.00481\n",
            "     38   490      0.00245      0.00243     2.66e-05       0.0325       0.0423          1.6      0.00443\n",
            "     38   500      0.00316      0.00315     1.01e-05       0.0366       0.0482        0.983      0.00273\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     38    10      0.00257      0.00257     4.48e-06       0.0334       0.0435         0.51      0.00142\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              38 4987.375    0.004      0.00289     0.000124      0.00301       0.0351       0.0462         2.71      0.00751\n",
            "! Validation         38 4987.375    0.004      0.00248     7.69e-06      0.00249       0.0324       0.0428         0.68      0.00189\n",
            "Wall time: 4987.375671822\n",
            "! Best model       38    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     39    10      0.00402      0.00397     4.24e-05       0.0401       0.0541         2.01      0.00559\n",
            "     39    20      0.00358       0.0033     0.000283       0.0381       0.0493          5.2       0.0144\n",
            "     39    30      0.00246      0.00246     1.66e-09       0.0324       0.0426       0.0126      3.5e-05\n",
            "     39    40      0.00279      0.00277      1.8e-05        0.035       0.0452         1.31      0.00365\n",
            "     39    50       0.0031       0.0031     1.23e-06       0.0362       0.0478        0.342     0.000951\n",
            "     39    60      0.00278      0.00275     2.44e-05       0.0343       0.0451         1.53      0.00425\n",
            "     39    70      0.00253      0.00248     5.73e-05       0.0328       0.0427         2.34       0.0065\n",
            "     39    80      0.00282      0.00281     1.09e-05       0.0345       0.0456         1.02      0.00284\n",
            "     39    90      0.00298      0.00294     3.58e-05        0.036       0.0466         1.85      0.00514\n",
            "     39   100      0.00241      0.00232     8.48e-05       0.0322       0.0414         2.85      0.00791\n",
            "     39   110       0.0035      0.00348     2.31e-05        0.036       0.0507         1.49      0.00413\n",
            "     39   120      0.00253      0.00249     3.49e-05        0.033       0.0429         1.83      0.00507\n",
            "     39   130      0.00266      0.00259     7.84e-05       0.0336       0.0437         2.74       0.0076\n",
            "     39   140      0.00288      0.00286     1.92e-05       0.0353       0.0459         1.35      0.00376\n",
            "     39   150      0.00314      0.00314     3.88e-06       0.0353       0.0481        0.609      0.00169\n",
            "     39   160      0.00344      0.00339     4.17e-05       0.0386         0.05            2      0.00554\n",
            "     39   170      0.00279      0.00274     4.49e-05       0.0339        0.045         2.07      0.00576\n",
            "     39   180      0.00253      0.00232     0.000209       0.0325       0.0413         4.47       0.0124\n",
            "     39   190      0.00402      0.00388     0.000137       0.0393       0.0535         3.62       0.0101\n",
            "     39   200      0.00292      0.00292     1.57e-06       0.0351       0.0464        0.387      0.00108\n",
            "     39   210      0.00332      0.00324     7.44e-05       0.0365       0.0489         2.67      0.00741\n",
            "     39   220       0.0031       0.0031     2.39e-07       0.0366       0.0478        0.151      0.00042\n",
            "     39   230      0.00305      0.00291      0.00013       0.0343       0.0464         3.53      0.00981\n",
            "     39   240      0.00343      0.00333     9.82e-05       0.0378       0.0496         3.06      0.00851\n",
            "     39   250      0.00303      0.00275     0.000278       0.0353        0.045         5.15       0.0143\n",
            "     39   260      0.00358        0.003     0.000585       0.0367        0.047         7.48       0.0208\n",
            "     39   270      0.00329      0.00329     2.47e-06       0.0372       0.0493        0.486      0.00135\n",
            "     39   280      0.00256      0.00249     6.82e-05       0.0328       0.0428         2.55      0.00709\n",
            "     39   290      0.00408      0.00407     9.54e-06       0.0395       0.0548        0.955      0.00265\n",
            "     39   300      0.00282      0.00279     3.44e-05       0.0349       0.0453         1.81      0.00504\n",
            "     39   310      0.00335      0.00329     5.81e-05       0.0376       0.0493         2.36      0.00654\n",
            "     39   320      0.00253      0.00216     0.000368       0.0314       0.0399         5.93       0.0165\n",
            "     39   330      0.00456        0.004     0.000553       0.0406       0.0543         7.27       0.0202\n",
            "     39   340      0.00345      0.00329     0.000161       0.0377       0.0492         3.92       0.0109\n",
            "     39   350      0.00338      0.00308       0.0003       0.0363       0.0476         5.36       0.0149\n",
            "     39   360      0.00482      0.00476     6.46e-05        0.044       0.0592         2.48       0.0069\n",
            "     39   370      0.00249      0.00229     0.000201       0.0312       0.0411         4.39       0.0122\n",
            "     39   380      0.00404      0.00403     1.78e-05       0.0404       0.0545         1.31      0.00363\n",
            "     39   390      0.00347      0.00347     7.03e-07       0.0386       0.0506        0.259      0.00072\n",
            "     39   400      0.00285      0.00285     3.16e-06       0.0334       0.0458        0.549      0.00153\n",
            "     39   410      0.00287      0.00278     9.38e-05       0.0349       0.0453         2.99      0.00832\n",
            "     39   420      0.00273      0.00243     0.000305       0.0322       0.0423          5.4        0.015\n",
            "     39   430      0.00299      0.00298     6.05e-06       0.0358       0.0469         0.76      0.00211\n",
            "     39   440      0.00305      0.00302     3.32e-05       0.0352       0.0472         1.78      0.00495\n",
            "     39   450      0.00299      0.00298     9.89e-06       0.0355       0.0469        0.972       0.0027\n",
            "     39   460      0.00209      0.00204     4.57e-05       0.0297       0.0388         2.09       0.0058\n",
            "     39   470      0.00322        0.003     0.000214       0.0357        0.047         4.53       0.0126\n",
            "     39   480      0.00287       0.0026     0.000272       0.0332       0.0438          5.1       0.0142\n",
            "     39   490      0.00277      0.00253     0.000237        0.033       0.0432         4.76       0.0132\n",
            "     39   500      0.00293      0.00293     9.65e-07       0.0355       0.0465        0.304     0.000844\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     39    10      0.00253      0.00252     4.29e-06       0.0331       0.0432        0.474      0.00132\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              39 5118.602    0.004       0.0029     0.000124      0.00302       0.0352       0.0462          2.8      0.00777\n",
            "! Validation         39 5118.602    0.004      0.00245     7.55e-06      0.00245       0.0322       0.0425        0.661      0.00184\n",
            "Wall time: 5118.60279972\n",
            "! Best model       39    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     40    10       0.0032      0.00315      4.6e-05       0.0364       0.0482          2.1      0.00583\n",
            "     40    20      0.00232      0.00223     9.19e-05       0.0309       0.0406         2.96      0.00823\n",
            "     40    30      0.00303      0.00303     2.44e-07       0.0362       0.0473        0.153     0.000424\n",
            "     40    40      0.00315      0.00314     8.81e-06       0.0362       0.0481        0.918      0.00255\n",
            "     40    50      0.00275      0.00273      2.1e-05       0.0346       0.0449         1.42      0.00394\n",
            "     40    60      0.00365      0.00319     0.000468       0.0367       0.0485         6.69       0.0186\n",
            "     40    70      0.00311      0.00289     0.000216       0.0356       0.0462         4.54       0.0126\n",
            "     40    80      0.00283      0.00283     3.92e-07       0.0352       0.0457        0.194     0.000538\n",
            "     40    90      0.00264      0.00246     0.000179       0.0333       0.0426         4.14       0.0115\n",
            "     40   100       0.0024      0.00239     1.38e-05       0.0319        0.042         1.15      0.00319\n",
            "     40   110      0.00249       0.0024     8.84e-05       0.0321       0.0421         2.91      0.00808\n",
            "     40   120      0.00235      0.00234     1.81e-05        0.032       0.0415         1.31      0.00365\n",
            "     40   130      0.00394      0.00394      3.3e-07       0.0406       0.0539        0.178     0.000493\n",
            "     40   140      0.00217      0.00213      3.7e-05       0.0306       0.0397         1.88      0.00523\n",
            "     40   150      0.00342      0.00271     0.000715       0.0339       0.0447         8.27        0.023\n",
            "     40   160      0.00338      0.00314     0.000237       0.0375       0.0481         4.76       0.0132\n",
            "     40   170      0.00228      0.00228     8.13e-06       0.0308        0.041        0.882      0.00245\n",
            "     40   180      0.00278       0.0025     0.000274       0.0329        0.043         5.11       0.0142\n",
            "     40   190      0.00248      0.00213      0.00035       0.0313       0.0396         5.79       0.0161\n",
            "     40   200       0.0027      0.00269     5.22e-06       0.0333       0.0445        0.706      0.00196\n",
            "     40   210      0.00374      0.00274        0.001       0.0349       0.0449         9.79       0.0272\n",
            "     40   220      0.00293      0.00285     7.93e-05        0.035       0.0459         2.75      0.00765\n",
            "     40   230      0.00293      0.00293     1.39e-06       0.0352       0.0465        0.364      0.00101\n",
            "     40   240      0.00251      0.00229      0.00022       0.0319       0.0411         4.59       0.0127\n",
            "     40   250      0.00237      0.00228     8.67e-05        0.032        0.041         2.88        0.008\n",
            "     40   260      0.00365      0.00344     0.000213       0.0366       0.0503         4.51       0.0125\n",
            "     40   270      0.00313      0.00304     8.43e-05       0.0362       0.0474         2.84      0.00788\n",
            "     40   280      0.00275      0.00271     4.04e-05       0.0343       0.0447         1.97      0.00546\n",
            "     40   290      0.00277      0.00274     2.89e-05       0.0344        0.045         1.66      0.00462\n",
            "     40   300      0.00278      0.00252     0.000255       0.0324       0.0432         4.94       0.0137\n",
            "     40   310      0.00328      0.00316     0.000111       0.0366       0.0483         3.26      0.00905\n",
            "     40   320      0.00213      0.00212     1.04e-05       0.0305       0.0396        0.998      0.00277\n",
            "     40   330      0.00275       0.0025     0.000245       0.0327        0.043         4.84       0.0134\n",
            "     40   340      0.00323      0.00314      8.6e-05       0.0368       0.0481         2.87      0.00797\n",
            "     40   350      0.00336      0.00302     0.000341       0.0358       0.0472         5.71       0.0159\n",
            "     40   360      0.00268      0.00262     6.61e-05        0.034       0.0439         2.51      0.00698\n",
            "     40   370      0.00251      0.00247     4.17e-05       0.0325       0.0427            2      0.00555\n",
            "     40   380      0.00262      0.00251     0.000118       0.0331        0.043         3.35      0.00931\n",
            "     40   390      0.00417      0.00377     0.000394       0.0396       0.0527         6.14        0.017\n",
            "     40   400      0.00309      0.00308     1.71e-06       0.0367       0.0477        0.404      0.00112\n",
            "     40   410      0.00254      0.00248     6.61e-05       0.0327       0.0427         2.51      0.00698\n",
            "     40   420      0.00263      0.00241     0.000218       0.0325       0.0421         4.57       0.0127\n",
            "     40   430       0.0025      0.00224     0.000256       0.0316       0.0407         4.95       0.0137\n",
            "     40   440      0.00234      0.00227     6.92e-05       0.0315       0.0409         2.57      0.00714\n",
            "     40   450      0.00327      0.00322     5.04e-05       0.0372       0.0487         2.19      0.00609\n",
            "     40   460      0.00278      0.00267     0.000106       0.0331       0.0444         3.19      0.00885\n",
            "     40   470       0.0033      0.00314     0.000157       0.0369       0.0481         3.88       0.0108\n",
            "     40   480      0.00271      0.00271     1.62e-07       0.0351       0.0447        0.125     0.000346\n",
            "     40   490      0.00379      0.00358     0.000203       0.0384       0.0514          4.4       0.0122\n",
            "     40   500      0.00346      0.00346     2.11e-10       0.0387       0.0505      0.00449     1.25e-05\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     40    10      0.00251      0.00251     4.38e-06       0.0329        0.043        0.496      0.00138\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              40 5249.990    0.004       0.0028     0.000153      0.00295       0.0345       0.0454         3.13      0.00871\n",
            "! Validation         40 5249.990    0.004      0.00242     7.64e-06      0.00243        0.032       0.0422        0.674      0.00187\n",
            "Wall time: 5249.99036487\n",
            "! Best model       40    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     41    10      0.00342      0.00267     0.000748       0.0343       0.0444         8.45       0.0235\n",
            "     41    20      0.00224      0.00218     5.86e-05       0.0305       0.0401         2.37      0.00657\n",
            "     41    30      0.00266      0.00235     0.000308       0.0312       0.0417         5.43       0.0151\n",
            "     41    40      0.00213      0.00211     1.49e-05       0.0298       0.0395         1.19      0.00331\n",
            "     41    50      0.00279      0.00232     0.000472       0.0318       0.0413         6.71       0.0187\n",
            "     41    60       0.0037       0.0033     0.000409       0.0367       0.0493         6.25       0.0174\n",
            "     41    70      0.00318      0.00306     0.000114       0.0365       0.0475          3.3      0.00916\n",
            "     41    80      0.00334      0.00306     0.000272       0.0361       0.0475          5.1       0.0142\n",
            "     41    90      0.00217      0.00216     5.78e-07       0.0302         0.04        0.235     0.000653\n",
            "     41   100      0.00257      0.00233     0.000239        0.032       0.0415         4.78       0.0133\n",
            "     41   110      0.00303      0.00296     7.18e-05       0.0354       0.0467         2.62      0.00728\n",
            "     41   120       0.0027      0.00267     2.55e-05       0.0343       0.0444         1.56      0.00433\n",
            "     41   130      0.00299      0.00295        4e-05       0.0364       0.0466         1.95      0.00543\n",
            "     41   140      0.00262      0.00262     4.32e-06       0.0333       0.0439        0.643      0.00179\n",
            "     41   150      0.00272      0.00271     1.84e-06       0.0345       0.0447        0.419      0.00116\n",
            "     41   160      0.00223      0.00219      3.9e-05       0.0311       0.0402         1.93      0.00537\n",
            "     41   170      0.00253      0.00253     2.18e-06       0.0327       0.0432        0.457      0.00127\n",
            "     41   180      0.00234      0.00234     2.58e-06       0.0323       0.0415        0.497      0.00138\n",
            "     41   190      0.00323      0.00323     1.51e-06        0.037       0.0488         0.38      0.00105\n",
            "     41   200      0.00348      0.00338     0.000105       0.0388       0.0499         3.17      0.00881\n",
            "     41   210      0.00413      0.00409      4.1e-05       0.0414       0.0549         1.98       0.0055\n",
            "     41   220      0.00317      0.00307     0.000101       0.0367       0.0476          3.1      0.00861\n",
            "     41   230      0.00333      0.00302     0.000304       0.0352       0.0472         5.39        0.015\n",
            "     41   240      0.00268      0.00264     4.31e-05        0.034       0.0441         2.03      0.00564\n",
            "     41   250      0.00346      0.00335     0.000109       0.0375       0.0497         3.23      0.00898\n",
            "     41   260      0.00248      0.00238     9.62e-05       0.0317       0.0419         3.03      0.00842\n",
            "     41   270      0.00314      0.00304     9.82e-05        0.036       0.0473         3.06      0.00851\n",
            "     41   280      0.00299      0.00262     0.000376       0.0332       0.0439            6       0.0167\n",
            "     41   290      0.00232      0.00232     4.41e-06       0.0314       0.0413        0.649       0.0018\n",
            "     41   300       0.0027      0.00235     0.000345       0.0324       0.0417         5.74        0.016\n",
            "     41   310      0.00297      0.00245     0.000525       0.0312       0.0425         7.09       0.0197\n",
            "     41   320      0.00303      0.00294     9.89e-05       0.0353       0.0465         3.07      0.00854\n",
            "     41   330      0.00353      0.00342     0.000116       0.0366       0.0502         3.33      0.00926\n",
            "     41   340      0.00292      0.00292     2.15e-11       0.0359       0.0464      0.00143     3.98e-06\n",
            "     41   350      0.00319      0.00309     0.000102       0.0332       0.0477         3.13      0.00869\n",
            "     41   360      0.00404      0.00312     0.000916       0.0336        0.048         9.36        0.026\n",
            "     41   370      0.00409      0.00405     3.95e-05       0.0386       0.0547         1.94       0.0054\n",
            "     41   380      0.00283      0.00282     1.46e-05       0.0351       0.0456         1.18      0.00328\n",
            "     41   390      0.00295      0.00291      3.3e-05       0.0349       0.0463         1.78      0.00494\n",
            "     41   400      0.00251      0.00241     9.65e-05        0.033       0.0422         3.04      0.00844\n",
            "     41   410      0.00314      0.00299     0.000148       0.0355        0.047         3.76       0.0105\n",
            "     41   420      0.00209      0.00203     5.88e-05       0.0301       0.0387         2.37      0.00659\n",
            "     41   430      0.00317      0.00315     2.13e-05       0.0362       0.0482         1.43      0.00396\n",
            "     41   440      0.00293      0.00265     0.000278       0.0331       0.0442         5.15       0.0143\n",
            "     41   450      0.00248      0.00228     0.000203       0.0317        0.041         4.41       0.0122\n",
            "     41   460      0.00191      0.00188      2.4e-05       0.0289       0.0373         1.51       0.0042\n",
            "     41   470      0.00254      0.00245     8.62e-05       0.0324       0.0425         2.87      0.00797\n",
            "     41   480      0.00325      0.00238     0.000866       0.0326       0.0419          9.1       0.0253\n",
            "     41   490      0.00241      0.00238     2.96e-05       0.0322       0.0419         1.68      0.00467\n",
            "     41   500      0.00247      0.00247     3.03e-07       0.0319       0.0427         0.17     0.000472\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     41    10      0.00249      0.00248     4.42e-06       0.0327       0.0428        0.502       0.0014\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              41 5381.317    0.004      0.00277     0.000137       0.0029       0.0344       0.0452         2.97      0.00826\n",
            "! Validation         41 5381.317    0.004      0.00239     7.61e-06       0.0024       0.0318        0.042        0.672      0.00187\n",
            "Wall time: 5381.317134962\n",
            "! Best model       41    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     42    10      0.00209      0.00208     5.65e-06       0.0297       0.0392        0.735      0.00204\n",
            "     42    20       0.0025      0.00247     2.82e-05       0.0328       0.0427         1.64      0.00456\n",
            "     42    30      0.00298      0.00281     0.000176        0.035       0.0455          4.1       0.0114\n",
            "     42    40      0.00231      0.00231     3.23e-07       0.0318       0.0413        0.176     0.000488\n",
            "     42    50      0.00274      0.00269     4.32e-05       0.0334       0.0446         2.03      0.00565\n",
            "     42    60      0.00256      0.00231     0.000254       0.0312       0.0412         4.93       0.0137\n",
            "     42    70      0.00289      0.00282     7.13e-05       0.0345       0.0456         2.61      0.00725\n",
            "     42    80      0.00246      0.00239     7.39e-05        0.032        0.042         2.66      0.00738\n",
            "     42    90      0.00278      0.00278     1.09e-08       0.0343       0.0453       0.0322     8.95e-05\n",
            "     42   100      0.00385      0.00384     9.88e-06       0.0382       0.0532        0.972       0.0027\n",
            "     42   110      0.00296      0.00296     3.89e-07        0.033       0.0467        0.193     0.000536\n",
            "     42   120      0.00269      0.00265     3.06e-05       0.0333       0.0442         1.71      0.00475\n",
            "     42   130      0.00325      0.00313     0.000124       0.0361        0.048         3.44      0.00957\n",
            "     42   140      0.00297      0.00294     3.02e-05       0.0351       0.0466          1.7      0.00472\n",
            "     42   150      0.00255      0.00248     6.23e-05       0.0336       0.0428         2.44      0.00678\n",
            "     42   160      0.00222      0.00222     4.26e-06       0.0308       0.0404        0.638      0.00177\n",
            "     42   170      0.00224      0.00224     8.99e-07        0.031       0.0407        0.293     0.000814\n",
            "     42   180      0.00218      0.00217     7.88e-06       0.0311         0.04        0.868      0.00241\n",
            "     42   190      0.00255      0.00255     2.05e-06       0.0326       0.0434        0.443      0.00123\n",
            "     42   200       0.0028      0.00234      0.00046       0.0318       0.0415         6.63       0.0184\n",
            "     42   210      0.00446      0.00442     4.03e-05        0.045       0.0571         1.96      0.00545\n",
            "     42   220      0.00333       0.0033     2.98e-05       0.0384       0.0493         1.69      0.00469\n",
            "     42   230      0.00231      0.00226     5.56e-05       0.0315       0.0408         2.31      0.00641\n",
            "     42   240      0.00439      0.00437     2.69e-05       0.0416       0.0568          1.6      0.00445\n",
            "     42   250       0.0028      0.00279     2.35e-06       0.0345       0.0454        0.474      0.00132\n",
            "     42   260      0.00247      0.00238     8.54e-05       0.0325       0.0419         2.86      0.00794\n",
            "     42   270      0.00225      0.00223     1.86e-05       0.0313       0.0405         1.33      0.00371\n",
            "     42   280      0.00266      0.00254     0.000123        0.033       0.0433         3.43      0.00953\n",
            "     42   290      0.00386      0.00303      0.00083       0.0366       0.0472         8.91       0.0247\n",
            "     42   300       0.0031      0.00263     0.000471       0.0334        0.044         6.71       0.0186\n",
            "     42   310      0.00317      0.00317      2.9e-06       0.0372       0.0483        0.527      0.00146\n",
            "     42   320      0.00343       0.0032     0.000232       0.0363       0.0486         4.71       0.0131\n",
            "     42   330      0.00327      0.00282     0.000457       0.0353       0.0456         6.61       0.0184\n",
            "     42   340       0.0023      0.00229     6.22e-06       0.0316       0.0411        0.771      0.00214\n",
            "     42   350      0.00268      0.00262      5.8e-05       0.0326        0.044         2.35      0.00654\n",
            "     42   360      0.00243      0.00237     5.71e-05       0.0326       0.0418         2.34      0.00649\n",
            "     42   370      0.00314      0.00312     2.46e-05       0.0367        0.048         1.53      0.00426\n",
            "     42   380      0.00316      0.00284     0.000328       0.0355       0.0457          5.6       0.0155\n",
            "     42   390      0.00256      0.00251      4.9e-05       0.0324        0.043         2.16      0.00601\n",
            "     42   400      0.00329      0.00298     0.000304       0.0353       0.0469         5.39        0.015\n",
            "     42   410      0.00245      0.00242     2.45e-05       0.0327       0.0423         1.53      0.00425\n",
            "     42   420      0.00368      0.00333     0.000358       0.0368       0.0495         5.85       0.0163\n",
            "     42   430      0.00291      0.00283     7.13e-05        0.036       0.0457         2.61      0.00725\n",
            "     42   440      0.00306       0.0029     0.000159       0.0354       0.0462          3.9       0.0108\n",
            "     42   450      0.00261      0.00261     1.21e-07        0.034       0.0439        0.108     0.000299\n",
            "     42   460      0.00229      0.00229     1.59e-09       0.0307       0.0411       0.0123     3.42e-05\n",
            "     42   470      0.00204      0.00203     4.16e-06       0.0304       0.0387         0.63      0.00175\n",
            "     42   480      0.00228      0.00221     7.78e-05       0.0306       0.0403         2.73      0.00757\n",
            "     42   490      0.00245      0.00244     9.39e-06       0.0327       0.0424        0.947      0.00263\n",
            "     42   500      0.00222      0.00206     0.000155       0.0298        0.039         3.86       0.0107\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     42    10      0.00245      0.00244     4.21e-06       0.0325       0.0424        0.468       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              42 5512.456    0.004       0.0027     0.000127      0.00283       0.0339       0.0446         2.72      0.00757\n",
            "! Validation         42 5512.456    0.004      0.00236     7.62e-06      0.00236       0.0316       0.0417        0.663      0.00184\n",
            "Wall time: 5512.456156836999\n",
            "! Best model       42    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     43    10      0.00335      0.00333     2.31e-05       0.0376       0.0495         1.49      0.00413\n",
            "     43    20      0.00218      0.00211     7.33e-05       0.0304       0.0394         2.65      0.00735\n",
            "     43    30      0.00259      0.00258     1.41e-05       0.0341       0.0436         1.16      0.00322\n",
            "     43    40      0.00223      0.00217      5.4e-05       0.0302         0.04         2.27      0.00631\n",
            "     43    50      0.00272      0.00261      0.00011       0.0326       0.0439         3.25      0.00902\n",
            "     43    60      0.00297      0.00294     2.92e-05       0.0361       0.0466         1.67      0.00464\n",
            "     43    70       0.0035      0.00338      0.00012       0.0378       0.0499         3.39      0.00941\n",
            "     43    80      0.00313      0.00312     8.61e-06       0.0365        0.048        0.907      0.00252\n",
            "     43    90      0.00244      0.00242     1.58e-05       0.0327       0.0423         1.23      0.00341\n",
            "     43   100      0.00226      0.00224     1.88e-05        0.031       0.0407         1.34      0.00372\n",
            "     43   110      0.00272      0.00262     9.56e-05       0.0347        0.044         3.02       0.0084\n",
            "     43   120      0.00252       0.0025     2.03e-05       0.0327       0.0429         1.39      0.00387\n",
            "     43   130      0.00266      0.00257     9.53e-05       0.0329       0.0435         3.02      0.00838\n",
            "     43   140      0.00203      0.00199     3.89e-05       0.0299       0.0383         1.93      0.00536\n",
            "     43   150      0.00227      0.00223     3.24e-05        0.031       0.0406         1.76      0.00489\n",
            "     43   160       0.0032      0.00308     0.000111       0.0354       0.0477         3.25      0.00904\n",
            "     43   170      0.00274      0.00256     0.000173       0.0337       0.0435         4.07       0.0113\n",
            "     43   180      0.00281      0.00248     0.000322       0.0328       0.0428         5.55       0.0154\n",
            "     43   190       0.0033      0.00327     2.34e-05       0.0377       0.0491          1.5      0.00415\n",
            "     43   200      0.00289      0.00289     3.51e-06       0.0358       0.0462        0.579      0.00161\n",
            "     43   210      0.00259      0.00248     0.000109       0.0331       0.0428         3.23      0.00897\n",
            "     43   220      0.00283      0.00283     4.88e-06       0.0348       0.0457        0.683       0.0019\n",
            "     43   230      0.00324      0.00323     1.94e-06       0.0369       0.0488        0.431       0.0012\n",
            "     43   240      0.00334      0.00334     1.88e-06       0.0372       0.0497        0.424      0.00118\n",
            "     43   250      0.00254      0.00243     0.000107       0.0331       0.0423          3.2       0.0089\n",
            "     43   260       0.0028      0.00251     0.000287       0.0327        0.043         5.23       0.0145\n",
            "     43   270      0.00282      0.00238     0.000441       0.0326       0.0419         6.49        0.018\n",
            "     43   280      0.00234      0.00216     0.000185       0.0301       0.0399         4.21       0.0117\n",
            "     43   290      0.00223      0.00216     7.04e-05       0.0308       0.0399         2.59      0.00721\n",
            "     43   300      0.00261      0.00243     0.000177       0.0334       0.0424         4.11       0.0114\n",
            "     43   310      0.00258       0.0025     8.21e-05       0.0328       0.0429          2.8      0.00778\n",
            "     43   320      0.00311      0.00276     0.000353       0.0342       0.0451         5.81       0.0161\n",
            "     43   330      0.00351      0.00319     0.000323       0.0368       0.0485         5.56       0.0154\n",
            "     43   340      0.00274      0.00274     8.08e-06       0.0348       0.0449        0.879      0.00244\n",
            "     43   350      0.00305      0.00253     0.000521       0.0331       0.0432         7.06       0.0196\n",
            "     43   360      0.00302      0.00296     6.11e-05       0.0348       0.0468         2.42      0.00671\n",
            "     43   370      0.00266      0.00258     7.17e-05       0.0335       0.0437         2.62      0.00727\n",
            "     43   380      0.00234      0.00234     1.98e-07       0.0316       0.0416        0.138     0.000382\n",
            "     43   390      0.00238      0.00237     1.49e-05       0.0319       0.0418         1.19      0.00332\n",
            "     43   400      0.00244      0.00239     4.36e-05       0.0317        0.042         2.04      0.00567\n",
            "     43   410      0.00256      0.00254     1.85e-05       0.0331       0.0433         1.33       0.0037\n",
            "     43   420      0.00314      0.00294     0.000198       0.0352       0.0466         4.35       0.0121\n",
            "     43   430      0.00256      0.00221     0.000351       0.0315       0.0403          5.8       0.0161\n",
            "     43   440      0.00313      0.00311     1.85e-05       0.0361       0.0479         1.33      0.00369\n",
            "     43   450      0.00277      0.00276     7.84e-06       0.0346       0.0451        0.866       0.0024\n",
            "     43   460      0.00311      0.00307     3.26e-05       0.0355       0.0476         1.76       0.0049\n",
            "     43   470      0.00479      0.00421      0.00058       0.0423       0.0558         7.44       0.0207\n",
            "     43   480      0.00346      0.00346     4.77e-08       0.0383       0.0505       0.0675     0.000188\n",
            "     43   490      0.00241      0.00225     0.000164       0.0316       0.0407         3.95        0.011\n",
            "     43   500      0.00262       0.0026     1.75e-05       0.0339       0.0438         1.29       0.0036\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     43    10      0.00243      0.00242     4.22e-06       0.0323       0.0423        0.465      0.00129\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              43 5643.816    0.004      0.00273     0.000118      0.00285       0.0341       0.0449         2.72      0.00755\n",
            "! Validation         43 5643.816    0.004      0.00233     7.56e-06      0.00234       0.0314       0.0415        0.658      0.00183\n",
            "Wall time: 5643.817006079\n",
            "! Best model       43    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     44    10      0.00255      0.00251     3.61e-05       0.0332        0.043         1.86      0.00516\n",
            "     44    20      0.00307      0.00275     0.000326       0.0339        0.045         5.58       0.0155\n",
            "     44    30      0.00253      0.00239      0.00014       0.0321        0.042         3.66       0.0102\n",
            "     44    40      0.00282      0.00281     5.67e-06       0.0351       0.0455        0.736      0.00205\n",
            "     44    50      0.00255      0.00236     0.000192       0.0321       0.0417         4.28       0.0119\n",
            "     44    60      0.00223      0.00218     4.83e-05       0.0306       0.0401         2.15      0.00597\n",
            "     44    70      0.00213      0.00212     5.44e-06       0.0298       0.0396        0.721        0.002\n",
            "     44    80      0.00353       0.0035        3e-05       0.0375       0.0508         1.69      0.00471\n",
            "     44    90      0.00302      0.00275     0.000272       0.0346        0.045          5.1       0.0142\n",
            "     44   100      0.00405      0.00403     1.64e-05       0.0413       0.0545         1.25      0.00348\n",
            "     44   110      0.00316      0.00314     2.68e-05       0.0366       0.0481          1.6      0.00444\n",
            "     44   120      0.00372      0.00363     8.59e-05       0.0395       0.0518         2.87      0.00796\n",
            "     44   130       0.0025      0.00249     4.15e-06       0.0326       0.0429         0.63      0.00175\n",
            "     44   140      0.00254      0.00252     2.41e-05       0.0326       0.0431         1.52      0.00422\n",
            "     44   150      0.00272      0.00272     6.16e-07       0.0333       0.0448        0.243     0.000674\n",
            "     44   160      0.00255      0.00251     4.03e-05       0.0325        0.043         1.96      0.00545\n",
            "     44   170      0.00343      0.00312     0.000313       0.0372       0.0479         5.47       0.0152\n",
            "     44   180      0.00313      0.00265     0.000483       0.0345       0.0442          6.8       0.0189\n",
            "     44   190      0.00257      0.00256     1.32e-05       0.0338       0.0434         1.12      0.00312\n",
            "     44   200      0.00256      0.00229     0.000277        0.031       0.0411         5.14       0.0143\n",
            "     44   210      0.00369      0.00232      0.00137       0.0322       0.0414         11.4       0.0318\n",
            "     44   220      0.00288      0.00191     0.000971        0.029       0.0375         9.63       0.0268\n",
            "     44   230      0.00288      0.00281     7.24e-05       0.0342       0.0455         2.63      0.00731\n",
            "     44   240      0.00313      0.00311      1.8e-05       0.0358       0.0479         1.31      0.00365\n",
            "     44   250      0.00285      0.00256     0.000287       0.0332       0.0435         5.24       0.0146\n",
            "     44   260      0.00251       0.0025     1.07e-05       0.0322        0.043         1.01      0.00281\n",
            "     44   270      0.00296      0.00278      0.00018       0.0322       0.0453         4.15       0.0115\n",
            "     44   280      0.00242      0.00229      0.00013       0.0318       0.0411         3.53      0.00979\n",
            "     44   290      0.00251       0.0025     7.86e-06       0.0332       0.0429        0.867      0.00241\n",
            "     44   300      0.00247      0.00231     0.000163       0.0319       0.0413         3.95        0.011\n",
            "     44   310      0.00304      0.00304     3.02e-07       0.0353       0.0474         0.17     0.000472\n",
            "     44   320      0.00256      0.00256     1.01e-07       0.0342       0.0435       0.0984     0.000273\n",
            "     44   330      0.00248      0.00244      3.8e-05       0.0322       0.0424         1.91      0.00529\n",
            "     44   340      0.00408      0.00394     0.000148       0.0407       0.0539         3.76       0.0104\n",
            "     44   350      0.00323      0.00321      2.4e-05       0.0364       0.0486         1.52      0.00421\n",
            "     44   360      0.00259      0.00242     0.000174       0.0324       0.0422         4.08       0.0113\n",
            "     44   370       0.0027      0.00264     5.94e-05       0.0339       0.0441         2.38      0.00662\n",
            "     44   380      0.00286      0.00286     1.91e-07       0.0351       0.0459        0.135     0.000375\n",
            "     44   390      0.00264      0.00264     2.25e-06       0.0339       0.0441        0.464      0.00129\n",
            "     44   400      0.00244      0.00242     1.71e-05       0.0319       0.0422         1.28      0.00355\n",
            "     44   410      0.00253      0.00246     7.31e-05       0.0329       0.0426         2.64      0.00734\n",
            "     44   420      0.00217      0.00216      7.2e-06       0.0308       0.0399         0.83       0.0023\n",
            "     44   430      0.00254      0.00226     0.000276       0.0309       0.0408         5.14       0.0143\n",
            "     44   440      0.00265      0.00234     0.000316        0.032       0.0415         5.49       0.0153\n",
            "     44   450      0.00193       0.0019     2.53e-05       0.0285       0.0375         1.56      0.00432\n",
            "     44   460      0.00301      0.00299      1.6e-05       0.0362        0.047         1.24      0.00343\n",
            "     44   470      0.00288      0.00288     2.99e-06       0.0352       0.0461        0.534      0.00148\n",
            "     44   480      0.00284      0.00282      1.7e-05       0.0344       0.0456         1.28      0.00354\n",
            "     44   490      0.00314      0.00287     0.000267       0.0348        0.046         5.05        0.014\n",
            "     44   500      0.00263      0.00256     7.12e-05       0.0321       0.0435         2.61      0.00725\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     44    10       0.0024       0.0024     4.16e-06       0.0322       0.0421        0.456      0.00127\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              44 5774.943    0.004      0.00267     0.000123      0.00279       0.0337       0.0443          2.7       0.0075\n",
            "! Validation         44 5774.943    0.004      0.00231     7.56e-06      0.00231       0.0312       0.0412        0.653      0.00181\n",
            "Wall time: 5774.943737549\n",
            "! Best model       44    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     45    10      0.00207      0.00205     1.93e-05       0.0298       0.0388         1.36      0.00377\n",
            "     45    20       0.0027       0.0027     1.01e-06       0.0339       0.0446        0.311     0.000864\n",
            "     45    30      0.00267      0.00246     0.000208       0.0326       0.0426         4.46       0.0124\n",
            "     45    40      0.00299      0.00245     0.000538       0.0323       0.0425         7.17       0.0199\n",
            "     45    50      0.00257      0.00253     3.37e-05       0.0337       0.0432          1.8      0.00499\n",
            "     45    60      0.00262       0.0026     2.37e-05       0.0337       0.0438         1.51      0.00418\n",
            "     45    70      0.00277      0.00275     1.14e-05       0.0351       0.0451         1.04       0.0029\n",
            "     45    80      0.00336      0.00322     0.000141       0.0366       0.0487         3.67       0.0102\n",
            "     45    90      0.00242      0.00237        5e-05       0.0323       0.0418         2.19      0.00607\n",
            "     45   100      0.00366      0.00341     0.000246       0.0379       0.0502         4.85       0.0135\n",
            "     45   110      0.00286      0.00281     5.05e-05        0.036       0.0455          2.2       0.0061\n",
            "     45   120      0.00206      0.00205     7.47e-06       0.0303       0.0389        0.845      0.00235\n",
            "     45   130      0.00296      0.00289     6.48e-05       0.0357       0.0462         2.49      0.00692\n",
            "     45   140      0.00213      0.00208     4.88e-05       0.0304       0.0392         2.16        0.006\n",
            "     45   150      0.00269      0.00246     0.000228       0.0325       0.0426         4.67        0.013\n",
            "     45   160      0.00301      0.00289     0.000123       0.0348       0.0462         3.44      0.00954\n",
            "     45   170      0.00222      0.00219     3.22e-05       0.0309       0.0402         1.75      0.00487\n",
            "     45   180      0.00386      0.00384     1.35e-05       0.0391       0.0532         1.14      0.00316\n",
            "     45   190      0.00257      0.00249     8.05e-05       0.0332       0.0428         2.77      0.00771\n",
            "     45   200      0.00338      0.00302     0.000355       0.0354       0.0472         5.83       0.0162\n",
            "     45   210      0.00227       0.0022     6.81e-05       0.0304       0.0403         2.55      0.00709\n",
            "     45   220      0.00245      0.00243     1.99e-05        0.032       0.0423         1.38      0.00383\n",
            "     45   230      0.00259      0.00259     1.72e-08       0.0335       0.0437       0.0405     0.000112\n",
            "     45   240      0.00303      0.00303     2.16e-06        0.036       0.0473        0.455      0.00126\n",
            "     45   250      0.00288      0.00287     8.06e-06       0.0355        0.046        0.878      0.00244\n",
            "     45   260      0.00243      0.00224     0.000193       0.0312       0.0406         4.29       0.0119\n",
            "     45   270      0.00324      0.00321     2.81e-05       0.0364       0.0486         1.64      0.00455\n",
            "     45   280      0.00393      0.00311     0.000821       0.0363       0.0479         8.86       0.0246\n",
            "     45   290      0.00228      0.00224     4.06e-05       0.0313       0.0406         1.97      0.00547\n",
            "     45   300      0.00228      0.00223     4.82e-05        0.031       0.0406         2.15      0.00596\n",
            "     45   310      0.00226      0.00224     2.64e-05       0.0307       0.0406         1.59      0.00441\n",
            "     45   320      0.00342      0.00323      0.00019       0.0369       0.0488         4.26       0.0118\n",
            "     45   330      0.00332       0.0033     1.55e-05       0.0376       0.0493         1.22      0.00338\n",
            "     45   340      0.00284      0.00282     2.14e-05       0.0351       0.0456         1.43      0.00397\n",
            "     45   350      0.00292      0.00282     0.000101       0.0347       0.0456          3.1      0.00862\n",
            "     45   360      0.00304      0.00294     9.83e-05       0.0356       0.0466         3.06      0.00851\n",
            "     45   370      0.00265      0.00248     0.000172       0.0319       0.0427         4.05       0.0113\n",
            "     45   380      0.00252      0.00252     8.41e-07       0.0335       0.0431        0.283     0.000787\n",
            "     45   390       0.0026      0.00217     0.000432        0.031         0.04         6.43       0.0178\n",
            "     45   400      0.00238      0.00233     4.32e-05       0.0323       0.0415         2.03      0.00564\n",
            "     45   410      0.00305      0.00302      2.8e-05       0.0359       0.0472         1.64      0.00454\n",
            "     45   420      0.00439      0.00379     0.000596       0.0408       0.0529         7.55        0.021\n",
            "     45   430      0.00281      0.00255     0.000256       0.0323       0.0434         4.95       0.0137\n",
            "     45   440      0.00225      0.00222     3.17e-05       0.0315       0.0405         1.74      0.00483\n",
            "     45   450       0.0029      0.00277     0.000136        0.035       0.0452          3.6         0.01\n",
            "     45   460      0.00289      0.00289     2.44e-06       0.0353       0.0462        0.483      0.00134\n",
            "     45   470      0.00219      0.00212     7.45e-05         0.03       0.0395         2.67      0.00741\n",
            "     45   480      0.00423      0.00422     1.02e-05       0.0413       0.0558        0.987      0.00274\n",
            "     45   490      0.00266      0.00264     2.39e-05       0.0336       0.0441         1.51       0.0042\n",
            "     45   500      0.00222      0.00221     1.12e-05       0.0307       0.0403         1.03      0.00287\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     45    10      0.00238      0.00238     4.47e-06        0.032       0.0419        0.509      0.00141\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              45 5906.158    0.004      0.00267     0.000126      0.00279       0.0337       0.0443         2.71      0.00754\n",
            "! Validation         45 5906.158    0.004      0.00229     7.61e-06       0.0023       0.0311       0.0411        0.675      0.00188\n",
            "Wall time: 5906.157937471\n",
            "! Best model       45    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     46    10      0.00207      0.00207     1.53e-06       0.0298        0.039        0.383      0.00106\n",
            "     46    20      0.00265      0.00252     0.000128       0.0331       0.0431          3.5      0.00973\n",
            "     46    30      0.00298       0.0029     7.85e-05       0.0359       0.0463         2.74      0.00761\n",
            "     46    40      0.00239      0.00236     3.47e-05       0.0327       0.0417         1.82      0.00506\n",
            "     46    50      0.00271      0.00218     0.000533        0.031       0.0401         7.14       0.0198\n",
            "     46    60      0.00307      0.00287       0.0002       0.0342        0.046         4.37       0.0121\n",
            "     46    70      0.00329      0.00311     0.000176       0.0372       0.0479          4.1       0.0114\n",
            "     46    80      0.00262      0.00251     0.000111       0.0329        0.043         3.26      0.00905\n",
            "     46    90      0.00287      0.00263     0.000234       0.0336       0.0441         4.73       0.0131\n",
            "     46   100      0.00249      0.00239     0.000102       0.0324        0.042         3.13      0.00868\n",
            "     46   110      0.00346      0.00318     0.000283       0.0373       0.0484          5.2       0.0144\n",
            "     46   120       0.0023       0.0023     2.65e-06       0.0315       0.0412        0.504       0.0014\n",
            "     46   130      0.00268      0.00263     4.62e-05        0.034       0.0441          2.1      0.00584\n",
            "     46   140      0.00246      0.00236     9.49e-05       0.0326       0.0417         3.01      0.00837\n",
            "     46   150      0.00255      0.00255     6.93e-07       0.0334       0.0433        0.257     0.000715\n",
            "     46   160       0.0022       0.0022     1.57e-06       0.0304       0.0403        0.388      0.00108\n",
            "     46   170      0.00249      0.00243     6.02e-05       0.0318       0.0423          2.4      0.00666\n",
            "     46   180      0.00261      0.00258     2.59e-05        0.033       0.0436         1.57      0.00437\n",
            "     46   190      0.00263      0.00261     2.37e-05        0.033       0.0439         1.51      0.00418\n",
            "     46   200      0.00222       0.0022     1.91e-05       0.0311       0.0403         1.35      0.00376\n",
            "     46   210      0.00266       0.0024     0.000262       0.0315        0.042            5       0.0139\n",
            "     46   220      0.00222       0.0022     1.19e-05       0.0313       0.0403         1.07      0.00296\n",
            "     46   230       0.0022      0.00217     2.25e-05       0.0307         0.04         1.47      0.00407\n",
            "     46   240      0.00285      0.00283     2.48e-05       0.0345       0.0457         1.54      0.00428\n",
            "     46   250      0.00447      0.00443     3.86e-05       0.0427       0.0571         1.92      0.00534\n",
            "     46   260      0.00306      0.00276     0.000297       0.0342       0.0452         5.32       0.0148\n",
            "     46   270      0.00242      0.00241     9.01e-06       0.0326       0.0422        0.928      0.00258\n",
            "     46   280      0.00197      0.00196     1.51e-06       0.0293       0.0381         0.38      0.00106\n",
            "     46   290      0.00283      0.00273     0.000102       0.0339       0.0449         3.12      0.00868\n",
            "     46   300      0.00279      0.00264     0.000153        0.034       0.0441         3.83       0.0106\n",
            "     46   310      0.00311      0.00306     5.01e-05       0.0345       0.0475         2.19      0.00608\n",
            "     46   320      0.00271      0.00265     6.41e-05       0.0343       0.0442         2.48      0.00688\n",
            "     46   330      0.00236      0.00213     0.000232       0.0308       0.0396         4.71       0.0131\n",
            "     46   340       0.0027      0.00242     0.000272       0.0316       0.0423          5.1       0.0142\n",
            "     46   350      0.00282      0.00275     6.27e-05       0.0342       0.0451         2.45       0.0068\n",
            "     46   360      0.00361      0.00351      9.8e-05       0.0383       0.0509         3.06       0.0085\n",
            "     46   370      0.00266      0.00256     0.000101        0.033       0.0434          3.1      0.00862\n",
            "     46   380      0.00228      0.00207     0.000213       0.0304        0.039         4.52       0.0125\n",
            "     46   390      0.00383      0.00383     1.11e-06       0.0402       0.0532        0.326     0.000906\n",
            "     46   400      0.00258      0.00228     0.000304       0.0318        0.041         5.39        0.015\n",
            "     46   410      0.00226      0.00215      0.00011       0.0302       0.0398         3.25      0.00902\n",
            "     46   420      0.00279      0.00279     4.92e-07       0.0343       0.0454        0.217     0.000602\n",
            "     46   430      0.00199      0.00199     1.34e-07       0.0294       0.0383        0.113     0.000314\n",
            "     46   440      0.00261      0.00256     4.46e-05       0.0331       0.0435         2.07      0.00574\n",
            "     46   450      0.00263      0.00263     4.69e-06       0.0339        0.044         0.67      0.00186\n",
            "     46   460      0.00254      0.00252     1.17e-05        0.033       0.0431         1.06      0.00294\n",
            "     46   470      0.00262      0.00259     3.13e-05       0.0331       0.0437         1.73       0.0048\n",
            "     46   480      0.00245      0.00242      2.4e-05       0.0326       0.0423         1.52      0.00421\n",
            "     46   490      0.00252      0.00248     4.23e-05       0.0329       0.0428         2.01      0.00558\n",
            "     46   500       0.0041      0.00399     0.000107       0.0404       0.0542          3.2      0.00888\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     46    10      0.00237      0.00236     4.02e-06       0.0319       0.0417        0.445      0.00124\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              46 6037.491    0.004      0.00261     7.08e-05      0.00268       0.0333       0.0439          2.1      0.00585\n",
            "! Validation         46 6037.491    0.004      0.00226     7.69e-06      0.00227       0.0309       0.0408        0.653      0.00181\n",
            "Wall time: 6037.491088362\n",
            "! Best model       46    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     47    10      0.00232      0.00227     4.91e-05       0.0315       0.0409         2.17      0.00602\n",
            "     47    20      0.00276      0.00259      0.00017       0.0335       0.0437         4.03       0.0112\n",
            "     47    30      0.00252      0.00248     3.99e-05       0.0325       0.0427         1.95      0.00543\n",
            "     47    40      0.00258      0.00255     2.21e-05       0.0338       0.0434         1.46      0.00404\n",
            "     47    50      0.00322      0.00319     2.57e-05       0.0367       0.0485         1.57      0.00435\n",
            "     47    60      0.00242      0.00231     0.000114       0.0318       0.0413          3.3      0.00918\n",
            "     47    70      0.00417      0.00398     0.000193         0.04       0.0542         4.29       0.0119\n",
            "     47    80      0.00278      0.00278     3.77e-06       0.0346       0.0453        0.601      0.00167\n",
            "     47    90      0.00224      0.00218     6.03e-05       0.0312       0.0401          2.4      0.00667\n",
            "     47   100      0.00302      0.00237     0.000647       0.0322       0.0418         7.86       0.0218\n",
            "     47   110      0.00339       0.0031     0.000292        0.036       0.0478         5.28       0.0147\n",
            "     47   120      0.00229      0.00218     0.000106       0.0308       0.0401         3.18      0.00885\n",
            "     47   130      0.00372        0.003     0.000719       0.0368        0.047         8.29        0.023\n",
            "     47   140      0.00304      0.00275      0.00029        0.035        0.045         5.26       0.0146\n",
            "     47   150      0.00401      0.00399     1.75e-05       0.0389       0.0542         1.29      0.00359\n",
            "     47   160      0.00271      0.00245     0.000263       0.0322       0.0425         5.01       0.0139\n",
            "     47   170       0.0022      0.00217     3.31e-05       0.0306         0.04         1.78      0.00494\n",
            "     47   180      0.00265      0.00264     2.98e-06       0.0332       0.0442        0.534      0.00148\n",
            "     47   190       0.0026      0.00252      7.9e-05        0.033       0.0431         2.75      0.00763\n",
            "     47   200       0.0024      0.00235     5.62e-05       0.0318       0.0416         2.32      0.00644\n",
            "     47   210      0.00283      0.00273     9.74e-05       0.0338       0.0449         3.05      0.00847\n",
            "     47   220      0.00432      0.00408     0.000241        0.041       0.0548          4.8       0.0133\n",
            "     47   230      0.00204      0.00203     3.91e-06       0.0306       0.0387        0.611       0.0017\n",
            "     47   240       0.0025      0.00248     1.48e-05       0.0323       0.0428         1.19       0.0033\n",
            "     47   250       0.0028      0.00277      2.7e-05       0.0342       0.0452         1.61      0.00446\n",
            "     47   260      0.00195      0.00195     8.59e-07       0.0296       0.0379        0.287     0.000796\n",
            "     47   270      0.00261      0.00254     7.06e-05       0.0332       0.0432          2.6      0.00722\n",
            "     47   280      0.00252      0.00251     1.32e-05       0.0323        0.043         1.13      0.00313\n",
            "     47   290      0.00299      0.00294     5.08e-05       0.0352       0.0466          2.2      0.00612\n",
            "     47   300      0.00243      0.00242      1.2e-05       0.0321       0.0423         1.07      0.00298\n",
            "     47   310       0.0025      0.00227     0.000234       0.0317       0.0409         4.73       0.0131\n",
            "     47   320      0.00431      0.00399     0.000317       0.0415       0.0543          5.5       0.0153\n",
            "     47   330      0.00246      0.00242     3.83e-05       0.0326       0.0423         1.91      0.00531\n",
            "     47   340      0.00223      0.00223     1.69e-09       0.0313       0.0406       0.0127     3.53e-05\n",
            "     47   350      0.00325      0.00282     0.000425       0.0353       0.0456         6.37       0.0177\n",
            "     47   360      0.00279       0.0027     9.22e-05       0.0341       0.0446         2.97      0.00825\n",
            "     47   370      0.00401      0.00364     0.000375       0.0385       0.0518         5.98       0.0166\n",
            "     47   380      0.00327      0.00314     0.000134       0.0358       0.0481         3.57      0.00993\n",
            "     47   390      0.00235      0.00235     6.42e-07       0.0317       0.0416        0.248     0.000688\n",
            "     47   400      0.00284      0.00255     0.000291       0.0328       0.0434         5.28       0.0147\n",
            "     47   410      0.00213      0.00213     6.29e-06       0.0306       0.0396        0.775      0.00215\n",
            "     47   420      0.00198      0.00197      1.3e-06       0.0296       0.0382        0.352     0.000978\n",
            "     47   430      0.00342      0.00342     5.39e-06       0.0363       0.0502        0.717      0.00199\n",
            "     47   440      0.00395      0.00395      1.9e-06       0.0413        0.054        0.426      0.00118\n",
            "     47   450      0.00239      0.00236     3.23e-05       0.0305       0.0417         1.76      0.00488\n",
            "     47   460      0.00358      0.00354     4.59e-05       0.0376       0.0511          2.1      0.00582\n",
            "     47   470      0.00404      0.00401     3.12e-05       0.0393       0.0544         1.73      0.00479\n",
            "     47   480      0.00249      0.00244     5.77e-05       0.0325       0.0424         2.35      0.00653\n",
            "     47   490      0.00389       0.0036     0.000291       0.0379       0.0516         5.28       0.0147\n",
            "     47   500      0.00237      0.00237     8.15e-07       0.0322       0.0418        0.279     0.000775\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     47    10      0.00235      0.00234     4.29e-06       0.0318       0.0416        0.471      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              47 6168.554    0.004      0.00263     0.000134      0.00277       0.0335       0.0441         2.91      0.00807\n",
            "! Validation         47 6168.554    0.004      0.00224     7.55e-06      0.00225       0.0308       0.0407        0.662      0.00184\n",
            "Wall time: 6168.554052112\n",
            "! Best model       47    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     48    10      0.00295       0.0029     4.73e-05       0.0352       0.0463         2.13       0.0059\n",
            "     48    20      0.00264      0.00264     1.66e-06       0.0333       0.0442        0.398      0.00111\n",
            "     48    30      0.00289      0.00289     1.45e-06       0.0349       0.0462        0.372      0.00103\n",
            "     48    40       0.0022      0.00215     4.33e-05       0.0306       0.0398         2.04      0.00565\n",
            "     48    50       0.0032      0.00279     0.000406       0.0348       0.0454         6.23       0.0173\n",
            "     48    60      0.00306      0.00277     0.000295       0.0336       0.0452         5.31       0.0148\n",
            "     48    70      0.00309        0.003     9.06e-05       0.0351       0.0471         2.94      0.00817\n",
            "     48    80      0.00227      0.00227     1.06e-06       0.0319       0.0409        0.318     0.000884\n",
            "     48    90      0.00247      0.00237     9.43e-05       0.0321       0.0418            3      0.00834\n",
            "     48   100      0.00264      0.00252     0.000124       0.0331       0.0431         3.44      0.00955\n",
            "     48   110      0.00245      0.00245     1.07e-06       0.0322       0.0425         0.32      0.00089\n",
            "     48   120      0.00289      0.00276     0.000137        0.034       0.0451         3.62       0.0101\n",
            "     48   130      0.00269      0.00225     0.000431       0.0309       0.0408         6.42       0.0178\n",
            "     48   140      0.00434      0.00434     4.19e-08       0.0418       0.0566       0.0633     0.000176\n",
            "     48   150       0.0029       0.0029     9.53e-07       0.0344       0.0463        0.302     0.000839\n",
            "     48   160       0.0022      0.00215     5.06e-05       0.0303       0.0398          2.2      0.00611\n",
            "     48   170       0.0028      0.00279      3.6e-06       0.0345       0.0454        0.587      0.00163\n",
            "     48   180      0.00329      0.00328     1.82e-06       0.0378       0.0492        0.418      0.00116\n",
            "     48   190      0.00267      0.00267     1.78e-07       0.0338       0.0444         0.13     0.000362\n",
            "     48   200      0.00247      0.00244      2.4e-05       0.0327       0.0424         1.52      0.00421\n",
            "     48   210      0.00241      0.00239     1.62e-05       0.0326        0.042         1.24      0.00345\n",
            "     48   220      0.00247      0.00245     1.69e-05       0.0321       0.0425         1.27      0.00353\n",
            "     48   230      0.00238      0.00236     1.83e-05       0.0319       0.0417         1.32      0.00367\n",
            "     48   240      0.00206      0.00198     8.23e-05       0.0295       0.0382          2.8      0.00779\n",
            "     48   250      0.00253      0.00235     0.000188       0.0313       0.0416         4.24       0.0118\n",
            "     48   260      0.00329      0.00328     2.87e-06       0.0372       0.0492        0.524      0.00146\n",
            "     48   270      0.00243      0.00229     0.000138       0.0317       0.0411         3.63       0.0101\n",
            "     48   280      0.00287      0.00275      0.00012       0.0349        0.045         3.38       0.0094\n",
            "     48   290      0.00267      0.00266     1.45e-05       0.0338       0.0443         1.18      0.00327\n",
            "     48   300       0.0026       0.0026      1.2e-06       0.0335       0.0438        0.338      0.00094\n",
            "     48   310      0.00264       0.0022     0.000439       0.0311       0.0403         6.48        0.018\n",
            "     48   320      0.00259      0.00256     2.62e-05       0.0336       0.0435         1.58       0.0044\n",
            "     48   330      0.00373      0.00373     4.48e-07       0.0376       0.0525        0.207     0.000575\n",
            "     48   340      0.00231      0.00223     7.86e-05        0.031       0.0406         2.74      0.00761\n",
            "     48   350      0.00243      0.00243     4.08e-06        0.032       0.0423        0.625      0.00174\n",
            "     48   360      0.00268      0.00226      0.00042       0.0307       0.0409         6.34       0.0176\n",
            "     48   370      0.00257      0.00254        3e-05       0.0335       0.0433         1.69      0.00471\n",
            "     48   380      0.00207      0.00204     3.47e-05       0.0297       0.0388         1.82      0.00506\n",
            "     48   390      0.00214      0.00207     7.06e-05       0.0302        0.039          2.6      0.00722\n",
            "     48   400       0.0027      0.00269     1.55e-05       0.0335       0.0445         1.22      0.00338\n",
            "     48   410      0.00264       0.0026     4.31e-05       0.0333       0.0438         2.03      0.00564\n",
            "     48   420      0.00219      0.00215     3.62e-05       0.0309       0.0398         1.86      0.00517\n",
            "     48   430       0.0019      0.00186     3.52e-05       0.0281       0.0371         1.83      0.00509\n",
            "     48   440      0.00238      0.00225     0.000132       0.0308       0.0407         3.55      0.00987\n",
            "     48   450      0.00216      0.00214     1.48e-05       0.0307       0.0398         1.19      0.00331\n",
            "     48   460      0.00234      0.00234     9.26e-07        0.032       0.0416        0.297     0.000826\n",
            "     48   470      0.00269      0.00261     7.58e-05       0.0332       0.0439         2.69      0.00748\n",
            "     48   480      0.00241      0.00227     0.000134       0.0314       0.0409         3.58      0.00993\n",
            "     48   490      0.00278      0.00278     1.36e-06       0.0347       0.0453        0.361        0.001\n",
            "     48   500      0.00304      0.00296     8.36e-05       0.0359       0.0467         2.83      0.00785\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     48    10      0.00234      0.00234     4.28e-06       0.0317       0.0415        0.471      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              48 6299.914    0.004      0.00259      7.7e-05      0.00267       0.0333       0.0437          2.1      0.00583\n",
            "! Validation         48 6299.914    0.004      0.00223      7.5e-06      0.00223       0.0307       0.0405         0.66      0.00183\n",
            "Wall time: 6299.914735672999\n",
            "! Best model       48    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     49    10      0.00252      0.00249     2.54e-05       0.0334       0.0429         1.56      0.00433\n",
            "     49    20       0.0037      0.00369     1.16e-06       0.0386       0.0522        0.333     0.000924\n",
            "     49    30      0.00326      0.00326      3.1e-06       0.0371        0.049        0.545      0.00151\n",
            "     49    40      0.00302      0.00301     9.64e-06       0.0364       0.0471         0.96      0.00267\n",
            "     49    50      0.00365      0.00364     1.09e-05        0.039       0.0518         1.02      0.00283\n",
            "     49    60      0.00227      0.00226      7.3e-06       0.0314       0.0408        0.836      0.00232\n",
            "     49    70      0.00314      0.00314     5.31e-09       0.0371       0.0481       0.0225     6.26e-05\n",
            "     49    80      0.00218      0.00217     6.77e-06       0.0305         0.04        0.804      0.00223\n",
            "     49    90       0.0027      0.00266      4.1e-05        0.035       0.0443         1.98       0.0055\n",
            "     49   100      0.00202      0.00198     3.75e-05       0.0295       0.0382         1.89      0.00526\n",
            "     49   110      0.00204        0.002     3.14e-05       0.0292       0.0384         1.73      0.00481\n",
            "     49   120      0.00228      0.00228     7.71e-06        0.031        0.041        0.859      0.00238\n",
            "     49   130      0.00283      0.00283     1.95e-07       0.0348       0.0457        0.137      0.00038\n",
            "     49   140      0.00257      0.00217     0.000405       0.0301         0.04         6.23       0.0173\n",
            "     49   150      0.00301      0.00299     2.06e-05       0.0366       0.0469          1.4      0.00389\n",
            "     49   160      0.00446      0.00446     1.18e-06       0.0429       0.0574        0.336     0.000935\n",
            "     49   170      0.00258      0.00256      1.5e-05       0.0329       0.0435          1.2      0.00333\n",
            "     49   180      0.00229      0.00216     0.000126       0.0309       0.0399         3.47      0.00965\n",
            "     49   190      0.00281      0.00277     3.62e-05       0.0337       0.0452         1.86      0.00517\n",
            "     49   200      0.00238      0.00227     0.000111        0.031       0.0409         3.25      0.00904\n",
            "     49   210      0.00254      0.00243      0.00011       0.0322       0.0424         3.24      0.00901\n",
            "     49   220      0.00236      0.00203     0.000332       0.0295       0.0387         5.64       0.0157\n",
            "     49   230      0.00225       0.0022     5.28e-05        0.031       0.0403         2.25      0.00624\n",
            "     49   240      0.00169      0.00169     2.94e-07       0.0273       0.0353        0.168     0.000466\n",
            "     49   250      0.00259      0.00257     1.83e-05       0.0336       0.0436         1.32      0.00368\n",
            "     49   260      0.00243      0.00238     4.65e-05       0.0322       0.0419         2.11      0.00586\n",
            "     49   270      0.00265      0.00263     2.53e-05       0.0334        0.044         1.55      0.00432\n",
            "     49   280      0.00319      0.00273     0.000456       0.0341       0.0449          6.6       0.0183\n",
            "     49   290      0.00293      0.00293     4.72e-06        0.035       0.0465        0.672      0.00187\n",
            "     49   300      0.00241      0.00235     5.67e-05       0.0316       0.0416         2.33      0.00647\n",
            "     49   310      0.00227      0.00224     3.24e-05       0.0307       0.0406         1.76      0.00489\n",
            "     49   320      0.00239      0.00239      1.5e-06        0.032        0.042        0.379      0.00105\n",
            "     49   330      0.00257      0.00253     4.31e-05       0.0331       0.0432         2.03      0.00564\n",
            "     49   340       0.0025       0.0025     1.42e-06       0.0326       0.0429        0.368      0.00102\n",
            "     49   350       0.0023       0.0023     2.82e-08       0.0319       0.0412       0.0519     0.000144\n",
            "     49   360      0.00259      0.00258     4.62e-06       0.0336       0.0436        0.665      0.00185\n",
            "     49   370      0.00265      0.00263     1.79e-05       0.0334        0.044         1.31      0.00364\n",
            "     49   380      0.00246      0.00245     5.86e-06       0.0317       0.0425        0.749      0.00208\n",
            "     49   390      0.00212      0.00212     1.23e-06       0.0306       0.0395        0.343     0.000954\n",
            "     49   400      0.00215      0.00215      1.3e-06       0.0302       0.0398        0.352     0.000978\n",
            "     49   410      0.00232      0.00232        3e-08       0.0319       0.0414       0.0536     0.000149\n",
            "     49   420      0.00228      0.00222     5.49e-05       0.0313       0.0405         2.29      0.00637\n",
            "     49   430      0.00242       0.0024      1.7e-05       0.0322       0.0421         1.27      0.00354\n",
            "     49   440      0.00288      0.00276     0.000122       0.0344       0.0451         3.41      0.00948\n",
            "     49   450      0.00326      0.00326      4.2e-06       0.0369        0.049        0.634      0.00176\n",
            "     49   460      0.00247      0.00238     8.63e-05       0.0318       0.0419         2.87      0.00798\n",
            "     49   470      0.00219      0.00206     0.000128       0.0304        0.039          3.5      0.00972\n",
            "     49   480       0.0022      0.00218     1.85e-05       0.0307       0.0401         1.33      0.00369\n",
            "     49   490      0.00241      0.00236     5.68e-05       0.0322       0.0417         2.33      0.00647\n",
            "     49   500      0.00227      0.00227     9.25e-08       0.0314        0.041       0.0941     0.000261\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     49    10       0.0023       0.0023     4.29e-06       0.0315       0.0412        0.471      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              49 6431.380    0.004      0.00255     7.36e-05      0.00262        0.033       0.0434         2.09      0.00582\n",
            "! Validation         49 6431.380    0.004       0.0022     7.48e-06      0.00221       0.0305       0.0403        0.658      0.00183\n",
            "Wall time: 6431.380701427999\n",
            "! Best model       49    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     50    10      0.00264      0.00263     6.87e-06        0.034        0.044         0.81      0.00225\n",
            "     50    20      0.00281      0.00263     0.000177       0.0335       0.0441         4.11       0.0114\n",
            "     50    30      0.00185       0.0018      4.4e-05       0.0282       0.0365         2.05       0.0057\n",
            "     50    40      0.00237      0.00237      7.6e-06        0.032       0.0418        0.853      0.00237\n",
            "     50    50      0.00362      0.00337      0.00025       0.0368       0.0499         4.89       0.0136\n",
            "     50    60      0.00318       0.0028     0.000379        0.034       0.0454         6.02       0.0167\n",
            "     50    70      0.00318      0.00303     0.000149       0.0365       0.0473         3.78       0.0105\n",
            "     50    80       0.0049       0.0049      3.2e-06       0.0447       0.0601        0.553      0.00154\n",
            "     50    90      0.00376      0.00322     0.000537        0.038       0.0487         7.16       0.0199\n",
            "     50   100      0.00233      0.00223     9.78e-05       0.0309       0.0406         3.06      0.00849\n",
            "     50   110      0.00336        0.003      0.00036       0.0355       0.0471         5.87       0.0163\n",
            "     50   120      0.00223      0.00223     1.35e-06       0.0308       0.0406        0.359     0.000997\n",
            "     50   130      0.00312      0.00309     2.88e-05       0.0361       0.0478         1.66      0.00461\n",
            "     50   140      0.00284      0.00278     6.37e-05       0.0351       0.0453         2.47      0.00686\n",
            "     50   150      0.00263      0.00263     1.02e-06       0.0335        0.044        0.312     0.000866\n",
            "     50   160       0.0024      0.00239     1.31e-05       0.0322        0.042         1.12       0.0031\n",
            "     50   170      0.00272      0.00257     0.000147       0.0337       0.0436         3.75       0.0104\n",
            "     50   180      0.00288      0.00268     0.000199       0.0342       0.0445         4.36       0.0121\n",
            "     50   190      0.00285      0.00233     0.000523       0.0321       0.0414         7.07       0.0196\n",
            "     50   200      0.00256      0.00249     6.94e-05       0.0327       0.0429         2.57      0.00715\n",
            "     50   210      0.00251       0.0025      1.3e-05       0.0329       0.0429         1.12       0.0031\n",
            "     50   220      0.00286      0.00247     0.000394       0.0322       0.0427         6.13        0.017\n",
            "     50   230      0.00286      0.00258     0.000278       0.0322       0.0436         5.16       0.0143\n",
            "     50   240      0.00238      0.00221      0.00017       0.0315       0.0404         4.03       0.0112\n",
            "     50   250      0.00216      0.00216      1.3e-08       0.0308       0.0399       0.0352     9.78e-05\n",
            "     50   260      0.00235      0.00233     1.89e-05       0.0318       0.0415         1.34      0.00373\n",
            "     50   270      0.00287      0.00286     1.31e-05       0.0347       0.0459         1.12      0.00311\n",
            "     50   280      0.00282      0.00281     1.07e-05       0.0359       0.0456         1.01      0.00281\n",
            "     50   290      0.00215      0.00215     3.31e-06       0.0306       0.0398        0.562      0.00156\n",
            "     50   300      0.00218      0.00216     1.19e-05        0.031       0.0399         1.07      0.00296\n",
            "     50   310       0.0025       0.0025     2.32e-06       0.0334       0.0429        0.471      0.00131\n",
            "     50   320      0.00312      0.00312     2.22e-06       0.0371       0.0479        0.461      0.00128\n",
            "     50   330       0.0026      0.00259     1.12e-05       0.0334       0.0437         1.03      0.00287\n",
            "     50   340      0.00267      0.00262     4.82e-05       0.0334        0.044         2.15      0.00596\n",
            "     50   350      0.00296      0.00293     2.81e-05       0.0354       0.0465         1.64      0.00456\n",
            "     50   360      0.00209      0.00206     3.24e-05       0.0294        0.039         1.76      0.00489\n",
            "     50   370      0.00328      0.00308     0.000193       0.0361       0.0477          4.3       0.0119\n",
            "     50   380      0.00274      0.00259     0.000146       0.0338       0.0437         3.74       0.0104\n",
            "     50   390       0.0026      0.00249     0.000107       0.0336       0.0429          3.2      0.00889\n",
            "     50   400      0.00208      0.00205     2.43e-05       0.0301       0.0389         1.53      0.00424\n",
            "     50   410      0.00222      0.00205      0.00017       0.0289       0.0389         4.03       0.0112\n",
            "     50   420      0.00215      0.00215     8.91e-07       0.0308       0.0398        0.292     0.000811\n",
            "     50   430      0.00272      0.00272      2.2e-07       0.0345       0.0448        0.145     0.000403\n",
            "     50   440      0.00312      0.00294      0.00018        0.034       0.0465         4.15       0.0115\n",
            "     50   450      0.00272       0.0026     0.000117       0.0328       0.0438         3.34      0.00927\n",
            "     50   460      0.00324      0.00312     0.000119       0.0336        0.048         3.37      0.00936\n",
            "     50   470       0.0023      0.00227      3.2e-05       0.0314       0.0409         1.75      0.00486\n",
            "     50   480      0.00259      0.00205     0.000541         0.03       0.0389         7.19         0.02\n",
            "     50   490      0.00255      0.00246     8.73e-05       0.0332       0.0426         2.89      0.00803\n",
            "     50   500      0.00303      0.00282     0.000212       0.0351       0.0456         4.51       0.0125\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     50    10       0.0023      0.00229     4.22e-06       0.0314       0.0411         0.47      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              50 6562.717    0.004      0.00258     0.000101      0.00268       0.0331       0.0436         2.47      0.00686\n",
            "! Validation         50 6562.717    0.004      0.00219     7.55e-06       0.0022       0.0304       0.0402        0.661      0.00184\n",
            "Wall time: 6562.717398266001\n",
            "! Best model       50    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     51    10      0.00336      0.00288     0.000479       0.0341       0.0461         6.77       0.0188\n",
            "     51    20      0.00225      0.00224     6.85e-06       0.0306       0.0407        0.809      0.00225\n",
            "     51    30      0.00226      0.00218     8.65e-05       0.0314       0.0401         2.88      0.00799\n",
            "     51    40      0.00288      0.00288     1.41e-06       0.0349       0.0461        0.366      0.00102\n",
            "     51    50      0.00431      0.00428     2.95e-05       0.0412       0.0562         1.68      0.00466\n",
            "     51    60      0.00251      0.00247     3.78e-05       0.0326       0.0427          1.9      0.00528\n",
            "     51    70      0.00309      0.00306     3.06e-05        0.036       0.0475         1.71      0.00475\n",
            "     51    80      0.00231      0.00231     5.87e-09        0.032       0.0413       0.0237     6.58e-05\n",
            "     51    90      0.00303      0.00297     6.55e-05       0.0359       0.0468          2.5      0.00695\n",
            "     51   100      0.00261       0.0026     1.42e-06       0.0319       0.0438        0.369      0.00102\n",
            "     51   110      0.00212      0.00212     3.81e-06       0.0299       0.0395        0.604      0.00168\n",
            "     51   120      0.00268      0.00266     1.96e-05       0.0344       0.0443         1.37      0.00381\n",
            "     51   130      0.00343      0.00342      1.3e-06       0.0374       0.0503        0.353      0.00098\n",
            "     51   140      0.00322      0.00321     3.76e-06        0.038       0.0487          0.6      0.00167\n",
            "     51   150      0.00245      0.00237     8.22e-05        0.031       0.0418          2.8      0.00779\n",
            "     51   160      0.00222      0.00218     3.71e-05       0.0305       0.0401         1.88      0.00523\n",
            "     51   170      0.00224      0.00224     1.78e-06       0.0309       0.0407        0.413      0.00115\n",
            "     51   180      0.00247       0.0024     6.56e-05       0.0324       0.0421          2.5      0.00695\n",
            "     51   190      0.00281      0.00276     5.23e-05        0.034       0.0451         2.24      0.00621\n",
            "     51   200       0.0031      0.00302     8.63e-05       0.0358       0.0472         2.87      0.00798\n",
            "     51   210      0.00257      0.00252      4.5e-05       0.0326       0.0431         2.07      0.00576\n",
            "     51   220      0.00214       0.0021     3.99e-05       0.0306       0.0393         1.95      0.00542\n",
            "     51   230      0.00268      0.00257     0.000108       0.0331       0.0435         3.21      0.00892\n",
            "     51   240      0.00236      0.00236     2.35e-09       0.0321       0.0418        0.015     4.17e-05\n",
            "     51   250      0.00286      0.00239     0.000466       0.0323        0.042         6.68       0.0185\n",
            "     51   260      0.00326      0.00326     1.43e-06       0.0376        0.049         0.37      0.00103\n",
            "     51   270       0.0022       0.0022     1.81e-06       0.0307       0.0403        0.416      0.00116\n",
            "     51   280      0.00245      0.00236     8.63e-05       0.0318       0.0417         2.87      0.00798\n",
            "     51   290      0.00211      0.00188     0.000227       0.0285       0.0373         4.65       0.0129\n",
            "     51   300      0.00258      0.00256     2.07e-05       0.0332       0.0434         1.41      0.00391\n",
            "     51   310      0.00201        0.002     1.62e-05       0.0295       0.0384         1.24      0.00346\n",
            "     51   320      0.00209      0.00208     4.56e-06       0.0301       0.0392         0.66      0.00183\n",
            "     51   330      0.00286      0.00226     0.000597       0.0304       0.0409         7.56        0.021\n",
            "     51   340      0.00261      0.00232     0.000295       0.0318       0.0413         5.31       0.0148\n",
            "     51   350      0.00184      0.00174     9.98e-05       0.0268       0.0358         3.09      0.00858\n",
            "     51   360      0.00294      0.00285      8.9e-05       0.0354       0.0459         2.92       0.0081\n",
            "     51   370      0.00222      0.00213      9.7e-05        0.031       0.0396         3.05      0.00846\n",
            "     51   380      0.00272      0.00271     9.08e-06       0.0336       0.0447        0.932      0.00259\n",
            "     51   390      0.00221       0.0021     0.000111       0.0303       0.0393         3.26      0.00905\n",
            "     51   400      0.00217      0.00217     5.06e-06       0.0306         0.04        0.695      0.00193\n",
            "     51   410      0.00234      0.00233     1.25e-05       0.0316       0.0415         1.09      0.00304\n",
            "     51   420        0.002        0.002     9.42e-07       0.0297       0.0384          0.3     0.000833\n",
            "     51   430      0.00247      0.00242     5.22e-05       0.0317       0.0422         2.23       0.0062\n",
            "     51   440      0.00202      0.00201     6.54e-06       0.0301       0.0385        0.791       0.0022\n",
            "     51   450      0.00236      0.00226     0.000102       0.0315       0.0408         3.12      0.00866\n",
            "     51   460      0.00223      0.00223     3.77e-09       0.0307       0.0405        0.019     5.27e-05\n",
            "     51   470      0.00227      0.00204     0.000234         0.03       0.0388         4.73       0.0131\n",
            "     51   480      0.00399      0.00399     1.66e-07       0.0403       0.0543        0.126      0.00035\n",
            "     51   490      0.00227      0.00215     0.000116       0.0305       0.0398         3.33      0.00926\n",
            "     51   500      0.00243      0.00242     3.83e-06       0.0325       0.0423        0.605      0.00168\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     51    10      0.00227      0.00227     3.97e-06       0.0313       0.0409        0.441      0.00123\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              51 6694.073    0.004      0.00247     8.02e-05      0.00255       0.0324       0.0427         2.17      0.00604\n",
            "! Validation         51 6694.073    0.004      0.00216     7.73e-06      0.00217       0.0302       0.0399        0.656      0.00182\n",
            "Wall time: 6694.073600583999\n",
            "! Best model       51    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     52    10      0.00212      0.00211     7.31e-06       0.0313       0.0395        0.836      0.00232\n",
            "     52    20      0.00276      0.00263     0.000128       0.0333        0.044          3.5      0.00972\n",
            "     52    30      0.00225      0.00224     2.37e-06       0.0305       0.0407        0.476      0.00132\n",
            "     52    40       0.0026      0.00259        9e-06       0.0335       0.0437        0.927      0.00258\n",
            "     52    50      0.00342      0.00317     0.000243        0.037       0.0484         4.82       0.0134\n",
            "     52    60      0.00274      0.00271     3.09e-05       0.0341       0.0447         1.72      0.00477\n",
            "     52    70      0.00325      0.00305     0.000204       0.0337       0.0474         4.42       0.0123\n",
            "     52    80      0.00276      0.00251     0.000253       0.0327        0.043         4.91       0.0137\n",
            "     52    90      0.00249       0.0022     0.000287       0.0311       0.0403         5.23       0.0145\n",
            "     52   100      0.00233       0.0023     2.77e-05       0.0317       0.0412         1.63      0.00452\n",
            "     52   110      0.00384      0.00376     7.76e-05       0.0395       0.0527         2.72      0.00756\n",
            "     52   120      0.00311      0.00288     0.000229       0.0351       0.0461         4.68        0.013\n",
            "     52   130      0.00217      0.00213     4.57e-05         0.03       0.0396         2.09       0.0058\n",
            "     52   140      0.00261      0.00259     1.67e-05       0.0344       0.0437         1.26      0.00351\n",
            "     52   150      0.00263       0.0026      3.2e-05       0.0337       0.0438         1.75      0.00486\n",
            "     52   160      0.00237      0.00226     0.000105        0.032       0.0408         3.17      0.00881\n",
            "     52   170      0.00306      0.00291     0.000145       0.0359       0.0464         3.72       0.0103\n",
            "     52   180      0.00229      0.00225     3.64e-05       0.0311       0.0408         1.86      0.00518\n",
            "     52   190      0.00319      0.00278     0.000412       0.0347       0.0453         6.28       0.0174\n",
            "     52   200      0.00288      0.00251     0.000374        0.033        0.043         5.98       0.0166\n",
            "     52   210      0.00284      0.00282     1.93e-05       0.0347       0.0456         1.36      0.00377\n",
            "     52   220      0.00238      0.00236     2.29e-05       0.0321       0.0417         1.48      0.00411\n",
            "     52   230      0.00243      0.00242     9.65e-06        0.031       0.0423         0.96      0.00267\n",
            "     52   240      0.00239      0.00239     5.48e-07       0.0316        0.042        0.229     0.000636\n",
            "     52   250      0.00316      0.00315     1.16e-05       0.0359       0.0482         1.05      0.00292\n",
            "     52   260      0.00284      0.00279      4.7e-05       0.0344       0.0454         2.12      0.00589\n",
            "     52   270      0.00528      0.00481     0.000472       0.0449       0.0595         6.71       0.0187\n",
            "     52   280      0.00253      0.00245     8.02e-05       0.0329       0.0425         2.77      0.00769\n",
            "     52   290      0.00212      0.00212     2.27e-06       0.0302       0.0395        0.465      0.00129\n",
            "     52   300      0.00227      0.00226     1.53e-05       0.0316       0.0408         1.21      0.00335\n",
            "     52   310      0.00242      0.00239     2.72e-05       0.0322        0.042         1.61      0.00448\n",
            "     52   320       0.0022      0.00219     5.38e-06       0.0308       0.0402        0.717      0.00199\n",
            "     52   330      0.00272      0.00272     3.44e-06       0.0333       0.0448        0.574      0.00159\n",
            "     52   340      0.00271      0.00227     0.000435       0.0321       0.0409         6.45       0.0179\n",
            "     52   350      0.00264      0.00236     0.000279       0.0322       0.0417         5.17       0.0143\n",
            "     52   360      0.00198      0.00195     2.54e-05       0.0294        0.038         1.56      0.00433\n",
            "     52   370      0.00358      0.00338     0.000205       0.0383       0.0499         4.42       0.0123\n",
            "     52   380      0.00259      0.00236     0.000234       0.0318       0.0417         4.73       0.0131\n",
            "     52   390      0.00334      0.00314     0.000192       0.0366       0.0482         4.28       0.0119\n",
            "     52   400      0.00332      0.00328     3.82e-05       0.0368       0.0492         1.91      0.00531\n",
            "     52   410      0.00297      0.00296     9.79e-06       0.0348       0.0467        0.967      0.00269\n",
            "     52   420      0.00272      0.00263     9.01e-05        0.034        0.044         2.93      0.00815\n",
            "     52   430      0.00224      0.00223      1.1e-05       0.0311       0.0406         1.02      0.00285\n",
            "     52   440      0.00221      0.00221     4.03e-07       0.0319       0.0404        0.196     0.000545\n",
            "     52   450      0.00299      0.00299        1e-06        0.035        0.047         0.31      0.00086\n",
            "     52   460      0.00257      0.00256     7.39e-06       0.0334       0.0434        0.841      0.00233\n",
            "     52   470      0.00251      0.00244     6.44e-05       0.0328       0.0424         2.48      0.00689\n",
            "     52   480      0.00226      0.00218     7.97e-05       0.0304       0.0401         2.76      0.00767\n",
            "     52   490      0.00181      0.00175     5.79e-05       0.0277        0.036         2.35      0.00653\n",
            "     52   500      0.00287      0.00287     2.42e-07       0.0348        0.046        0.152     0.000422\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     52    10      0.00226      0.00225     4.22e-06       0.0312       0.0408        0.469       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              52 6825.463    0.004      0.00254     0.000102      0.00264       0.0329       0.0433         2.45      0.00681\n",
            "! Validation         52 6825.463    0.004      0.00215     7.51e-06      0.00216       0.0301       0.0398         0.66      0.00183\n",
            "Wall time: 6825.463567376\n",
            "! Best model       52    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     53    10      0.00267      0.00253     0.000137       0.0335       0.0432         3.62         0.01\n",
            "     53    20      0.00258      0.00256      2.7e-05       0.0332       0.0434         1.61      0.00446\n",
            "     53    30      0.00213      0.00204     8.37e-05       0.0299       0.0388         2.83      0.00786\n",
            "     53    40      0.00264      0.00264     3.49e-06       0.0326       0.0441        0.578      0.00161\n",
            "     53    50      0.00259      0.00255     3.76e-05       0.0328       0.0434          1.9      0.00527\n",
            "     53    60      0.00224      0.00222     1.92e-05       0.0308       0.0404         1.36      0.00377\n",
            "     53    70      0.00275      0.00275     1.02e-06       0.0334        0.045        0.312     0.000867\n",
            "     53    80      0.00213        0.002     0.000131       0.0295       0.0384         3.54      0.00985\n",
            "     53    90       0.0028      0.00251     0.000291        0.033        0.043         5.28       0.0147\n",
            "     53   100      0.00336      0.00315     0.000203       0.0372       0.0482         4.41       0.0122\n",
            "     53   110      0.00255      0.00252     2.46e-05        0.033       0.0432         1.53      0.00426\n",
            "     53   120      0.00214      0.00213     7.29e-06       0.0303       0.0396        0.835      0.00232\n",
            "     53   130      0.00309      0.00307     2.63e-05       0.0363       0.0476         1.59      0.00441\n",
            "     53   140      0.00213       0.0021     2.73e-05       0.0302       0.0394         1.62      0.00449\n",
            "     53   150      0.00197      0.00197      2.5e-06       0.0287       0.0381        0.489      0.00136\n",
            "     53   160        0.002      0.00193     6.47e-05       0.0295       0.0378         2.49      0.00691\n",
            "     53   170       0.0026       0.0026     1.36e-06       0.0335       0.0438        0.361        0.001\n",
            "     53   180      0.00327      0.00324     3.39e-05        0.038       0.0489          1.8        0.005\n",
            "     53   190      0.00221      0.00219     2.57e-05       0.0302       0.0402         1.57      0.00435\n",
            "     53   200      0.00299      0.00291     7.91e-05       0.0352       0.0463         2.75      0.00764\n",
            "     53   210      0.00227      0.00191     0.000361       0.0287       0.0375         5.87       0.0163\n",
            "     53   220      0.00212      0.00193     0.000188       0.0291       0.0377         4.24       0.0118\n",
            "     53   230      0.00217      0.00191     0.000267       0.0288       0.0375         5.05        0.014\n",
            "     53   240      0.00276      0.00239     0.000372       0.0322        0.042         5.96       0.0166\n",
            "     53   250       0.0023      0.00192     0.000374       0.0294       0.0377         5.98       0.0166\n",
            "     53   260      0.00222      0.00212     9.58e-05       0.0303       0.0395         3.03       0.0084\n",
            "     53   270      0.00231      0.00217     0.000138         0.03         0.04         3.64       0.0101\n",
            "     53   280       0.0022      0.00206     0.000144       0.0299        0.039         3.71       0.0103\n",
            "     53   290      0.00278      0.00267     0.000104       0.0339       0.0444         3.15      0.00876\n",
            "     53   300      0.00218      0.00216     2.01e-05       0.0304       0.0399         1.39      0.00385\n",
            "     53   310      0.00224      0.00224     1.81e-06       0.0313       0.0406        0.416      0.00116\n",
            "     53   320      0.00208      0.00201     7.07e-05       0.0302       0.0385          2.6      0.00722\n",
            "     53   330      0.00228      0.00222      6.5e-05       0.0312       0.0404         2.49      0.00693\n",
            "     53   340      0.00228       0.0022     7.99e-05        0.031       0.0402         2.76      0.00767\n",
            "     53   350      0.00316      0.00288      0.00029       0.0351        0.046         5.26       0.0146\n",
            "     53   360      0.00297      0.00289     7.89e-05       0.0351       0.0462         2.75      0.00763\n",
            "     53   370      0.00237      0.00234     3.01e-05       0.0314       0.0416          1.7      0.00471\n",
            "     53   380      0.00258      0.00253     5.13e-05       0.0333       0.0432         2.22      0.00615\n",
            "     53   390      0.00225      0.00215     0.000107       0.0306       0.0398          3.2      0.00889\n",
            "     53   400      0.00181      0.00181     4.89e-06       0.0285       0.0365        0.684       0.0019\n",
            "     53   410      0.00196      0.00196     1.03e-06       0.0295        0.038        0.313      0.00087\n",
            "     53   420      0.00193      0.00192     6.98e-06        0.029       0.0377        0.817      0.00227\n",
            "     53   430      0.00233      0.00232     8.81e-06       0.0316       0.0414        0.918      0.00255\n",
            "     53   440       0.0028      0.00278     1.86e-05       0.0343       0.0453         1.33       0.0037\n",
            "     53   450      0.00235      0.00235     1.66e-08       0.0325       0.0416       0.0399     0.000111\n",
            "     53   460      0.00274      0.00274     2.21e-06       0.0341       0.0449        0.459      0.00128\n",
            "     53   470      0.00218      0.00212     5.97e-05       0.0288       0.0396         2.39      0.00664\n",
            "     53   480      0.00245      0.00239     6.54e-05       0.0323        0.042          2.5      0.00695\n",
            "     53   490      0.00207      0.00204     2.96e-05       0.0299       0.0388         1.68      0.00467\n",
            "     53   500      0.00263      0.00263     1.88e-07       0.0345        0.044        0.134     0.000372\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     53    10      0.00222      0.00222     4.77e-06        0.031       0.0405        0.545      0.00152\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              53 6956.867    0.004      0.00248     0.000103      0.00259       0.0325       0.0428         2.52        0.007\n",
            "! Validation         53 6956.867    0.004      0.00213     7.73e-06      0.00214         0.03       0.0397        0.697      0.00194\n",
            "Wall time: 6956.867843683\n",
            "! Best model       53    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     54    10      0.00258      0.00221     0.000375       0.0308       0.0404         5.99       0.0166\n",
            "     54    20      0.00297      0.00246      0.00051       0.0321       0.0426         6.98       0.0194\n",
            "     54    30      0.00384      0.00332     0.000521       0.0355       0.0495         7.06       0.0196\n",
            "     54    40      0.00259      0.00256     3.26e-05       0.0329       0.0435         1.77       0.0049\n",
            "     54    50      0.00327      0.00301     0.000261       0.0359       0.0471            5       0.0139\n",
            "     54    60      0.00264      0.00239     0.000242       0.0317        0.042          4.8       0.0133\n",
            "     54    70      0.00223      0.00204     0.000187       0.0289       0.0388         4.23       0.0118\n",
            "     54    80      0.00203      0.00197     6.05e-05       0.0298       0.0381          2.4      0.00668\n",
            "     54    90      0.00317      0.00295     0.000218       0.0355       0.0467         4.57       0.0127\n",
            "     54   100      0.00228      0.00211     0.000169       0.0301       0.0394         4.01       0.0112\n",
            "     54   110      0.00216      0.00212     3.43e-05       0.0308       0.0396         1.81      0.00503\n",
            "     54   120      0.00294      0.00289     5.07e-05       0.0355       0.0462          2.2      0.00611\n",
            "     54   130      0.00183      0.00181        2e-05       0.0281       0.0365         1.38      0.00384\n",
            "     54   140      0.00254       0.0024     0.000146       0.0315       0.0421         3.74       0.0104\n",
            "     54   150      0.00291       0.0029     1.12e-05       0.0343       0.0462         1.04      0.00288\n",
            "     54   160      0.00305      0.00304        1e-05       0.0359       0.0473         0.98      0.00272\n",
            "     54   170      0.00194      0.00192     1.21e-05       0.0287       0.0377         1.07      0.00298\n",
            "     54   180       0.0017      0.00165      5.5e-05       0.0269       0.0348         2.29      0.00637\n",
            "     54   190       0.0021      0.00202     8.11e-05        0.029       0.0386         2.78      0.00773\n",
            "     54   200      0.00261      0.00243     0.000185       0.0323       0.0423         4.21       0.0117\n",
            "     54   210      0.00233      0.00231     1.53e-05        0.031       0.0413         1.21      0.00336\n",
            "     54   220      0.00273      0.00271     1.84e-05       0.0345       0.0447         1.33      0.00368\n",
            "     54   230       0.0022      0.00214     5.49e-05        0.031       0.0398         2.29      0.00636\n",
            "     54   240      0.00187      0.00179     7.49e-05       0.0277       0.0364         2.68      0.00743\n",
            "     54   250      0.00201      0.00201     1.59e-06       0.0296       0.0385         0.39      0.00108\n",
            "     54   260      0.00231      0.00222     8.81e-05       0.0298       0.0405          2.9      0.00806\n",
            "     54   270      0.00201        0.002     6.83e-06       0.0293       0.0384        0.808      0.00224\n",
            "     54   280      0.00206      0.00202      4.2e-05       0.0294       0.0386            2      0.00557\n",
            "     54   290      0.00229       0.0022     9.12e-05       0.0308       0.0403         2.95       0.0082\n",
            "     54   300      0.00226      0.00226     1.86e-06        0.032       0.0408        0.422      0.00117\n",
            "     54   310      0.00249      0.00249     2.19e-06       0.0335       0.0429        0.458      0.00127\n",
            "     54   320       0.0029      0.00289        9e-06       0.0345       0.0461        0.928      0.00258\n",
            "     54   330      0.00227      0.00224     2.54e-05       0.0317       0.0407         1.56      0.00433\n",
            "     54   340      0.00256      0.00245     0.000107       0.0319       0.0425          3.2      0.00888\n",
            "     54   350      0.00218      0.00218     5.76e-07       0.0305       0.0401        0.235     0.000652\n",
            "     54   360      0.00251      0.00237     0.000136       0.0318       0.0418          3.6         0.01\n",
            "     54   370       0.0027      0.00264     6.75e-05       0.0345       0.0441         2.54      0.00705\n",
            "     54   380       0.0021       0.0019     0.000204       0.0288       0.0374         4.41       0.0123\n",
            "     54   390      0.00267      0.00258     9.09e-05       0.0338       0.0436         2.95      0.00819\n",
            "     54   400       0.0023      0.00226     3.54e-05       0.0311       0.0409         1.84      0.00511\n",
            "     54   410       0.0024      0.00238     2.68e-05       0.0324       0.0419          1.6      0.00445\n",
            "     54   420      0.00201      0.00201     6.42e-07       0.0297       0.0385        0.248     0.000688\n",
            "     54   430      0.00345      0.00345     5.67e-06       0.0369       0.0504        0.736      0.00205\n",
            "     54   440      0.00228      0.00184     0.000436        0.029       0.0369         6.46       0.0179\n",
            "     54   450      0.00325      0.00297     0.000282       0.0351       0.0468         5.19       0.0144\n",
            "     54   460      0.00298      0.00294     3.37e-05       0.0356       0.0466         1.79      0.00498\n",
            "     54   470      0.00275      0.00274      1.1e-05       0.0339        0.045         1.02      0.00284\n",
            "     54   480       0.0029      0.00286     3.51e-05       0.0351        0.046         1.83      0.00508\n",
            "     54   490      0.00216      0.00215     1.45e-05       0.0306       0.0398         1.18      0.00328\n",
            "     54   500      0.00195      0.00194     4.27e-06       0.0285       0.0379        0.639      0.00177\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     54    10      0.00221      0.00221     4.15e-06       0.0309       0.0404        0.463      0.00129\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              54 7087.958    0.004      0.00242     8.02e-05       0.0025       0.0321       0.0423         2.25      0.00625\n",
            "! Validation         54 7087.958    0.004      0.00211     7.52e-06      0.00212       0.0298       0.0394        0.653      0.00181\n",
            "Wall time: 7087.958309968999\n",
            "! Best model       54    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     55    10      0.00206      0.00202     4.06e-05       0.0297       0.0386         1.97      0.00547\n",
            "     55    20      0.00295      0.00292     3.28e-05       0.0352       0.0464         1.77      0.00492\n",
            "     55    30      0.00198      0.00198     9.41e-08       0.0292       0.0382       0.0948     0.000263\n",
            "     55    40      0.00282      0.00281     1.44e-05       0.0341       0.0455         1.17      0.00326\n",
            "     55    50      0.00239      0.00235     4.28e-05        0.032       0.0416         2.02      0.00562\n",
            "     55    60      0.00296      0.00296     4.41e-06       0.0348       0.0467        0.649       0.0018\n",
            "     55    70      0.00234      0.00222     0.000112       0.0311       0.0405         3.28       0.0091\n",
            "     55    80      0.00216      0.00212     4.24e-05       0.0301       0.0395         2.01      0.00559\n",
            "     55    90      0.00226      0.00216       0.0001       0.0305       0.0399         3.09      0.00859\n",
            "     55   100      0.00201       0.0019     0.000109       0.0291       0.0374         3.23      0.00897\n",
            "     55   110      0.00274      0.00269     4.68e-05       0.0338       0.0446         2.12      0.00588\n",
            "     55   120      0.00244      0.00242     1.79e-05       0.0324       0.0423         1.31      0.00363\n",
            "     55   130      0.00247      0.00246     5.38e-06       0.0324       0.0426        0.717      0.00199\n",
            "     55   140       0.0032       0.0032     5.11e-07       0.0366       0.0486        0.221     0.000614\n",
            "     55   150      0.00271      0.00242     0.000292       0.0316       0.0422         5.28       0.0147\n",
            "     55   160      0.00281      0.00256     0.000253       0.0332       0.0434         4.92       0.0137\n",
            "     55   170      0.00224      0.00224     7.86e-08       0.0306       0.0406       0.0867     0.000241\n",
            "     55   180       0.0023       0.0023     6.07e-09       0.0316       0.0412       0.0241     6.69e-05\n",
            "     55   190      0.00262      0.00248     0.000138       0.0325       0.0428         3.64       0.0101\n",
            "     55   200      0.00224      0.00223     1.48e-05       0.0314       0.0405         1.19       0.0033\n",
            "     55   210      0.00197      0.00196     1.06e-05       0.0295        0.038         1.01      0.00279\n",
            "     55   220      0.00229      0.00227     2.25e-05       0.0308       0.0409         1.47      0.00407\n",
            "     55   230      0.00242      0.00236     6.25e-05       0.0313       0.0417         2.44      0.00679\n",
            "     55   240      0.00226      0.00224     1.93e-05       0.0314       0.0407         1.36      0.00377\n",
            "     55   250      0.00287      0.00281     6.13e-05       0.0344       0.0455         2.42      0.00672\n",
            "     55   260      0.00229      0.00226     2.84e-05       0.0317       0.0409         1.65      0.00457\n",
            "     55   270      0.00305      0.00296      9.1e-05       0.0356       0.0467         2.95      0.00819\n",
            "     55   280      0.00268      0.00266     2.39e-05       0.0341       0.0443         1.51       0.0042\n",
            "     55   290      0.00238      0.00231     7.19e-05       0.0317       0.0413         2.62      0.00728\n",
            "     55   300      0.00169      0.00168     1.07e-05       0.0276       0.0352         1.01       0.0028\n",
            "     55   310      0.00212      0.00205     7.53e-05       0.0302       0.0388         2.68      0.00745\n",
            "     55   320       0.0021       0.0021     5.61e-07       0.0306       0.0394        0.232     0.000643\n",
            "     55   330      0.00247      0.00233     0.000143       0.0312       0.0414         3.69       0.0103\n",
            "     55   340      0.00273      0.00249     0.000241       0.0327       0.0429          4.8       0.0133\n",
            "     55   350      0.00287      0.00257       0.0003       0.0325       0.0435         5.35       0.0149\n",
            "     55   360       0.0026      0.00248     0.000126       0.0316       0.0427         3.47      0.00964\n",
            "     55   370      0.00275      0.00275     8.31e-07       0.0336       0.0451        0.282     0.000783\n",
            "     55   380      0.00259      0.00255     4.16e-05       0.0328       0.0434            2      0.00554\n",
            "     55   390      0.00201        0.002     1.21e-05       0.0297       0.0384         1.07      0.00298\n",
            "     55   400      0.00184      0.00184     5.42e-07       0.0277       0.0368        0.228     0.000632\n",
            "     55   410      0.00288      0.00287     4.54e-06       0.0353        0.046        0.659      0.00183\n",
            "     55   420      0.00234      0.00234     4.08e-07       0.0319       0.0416        0.197     0.000549\n",
            "     55   430      0.00219      0.00217     1.32e-05       0.0303         0.04         1.12      0.00311\n",
            "     55   440      0.00211      0.00211     1.18e-07       0.0302       0.0395        0.106     0.000295\n",
            "     55   450      0.00316      0.00301     0.000151       0.0363       0.0471          3.8       0.0105\n",
            "     55   460      0.00323        0.003     0.000239       0.0366        0.047         4.78       0.0133\n",
            "     55   470      0.00229      0.00217     0.000124       0.0304         0.04         3.45      0.00958\n",
            "     55   480      0.00247      0.00247     1.05e-08       0.0327       0.0427       0.0317     8.81e-05\n",
            "     55   490       0.0023      0.00227     2.41e-05       0.0307        0.041         1.52      0.00422\n",
            "     55   500      0.00205      0.00205     1.01e-06       0.0297       0.0389        0.311     0.000863\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     55    10      0.00219      0.00219     4.44e-06       0.0307       0.0402          0.5      0.00139\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              55 7219.245    0.004      0.00241     9.08e-05       0.0025        0.032       0.0421         2.34      0.00649\n",
            "! Validation         55 7219.245    0.004      0.00209     7.51e-06       0.0021       0.0297       0.0393        0.671      0.00186\n",
            "Wall time: 7219.245389280999\n",
            "! Best model       55    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     56    10      0.00319      0.00293     0.000256       0.0351       0.0465         4.94       0.0137\n",
            "     56    20      0.00251      0.00245     6.01e-05       0.0329       0.0425          2.4      0.00666\n",
            "     56    30      0.00262      0.00262     4.29e-06       0.0333        0.044         0.64      0.00178\n",
            "     56    40      0.00204      0.00194     9.22e-05       0.0284       0.0379         2.97      0.00825\n",
            "     56    50      0.00397       0.0038      0.00017       0.0381       0.0529         4.03       0.0112\n",
            "     56    60      0.00301        0.003     8.24e-06       0.0353        0.047        0.887      0.00247\n",
            "     56    70      0.00275      0.00273     2.24e-05       0.0344       0.0448         1.46      0.00406\n",
            "     56    80      0.00274      0.00268     6.27e-05       0.0344       0.0445         2.45       0.0068\n",
            "     56    90      0.00269      0.00258     0.000108       0.0334       0.0436         3.21      0.00893\n",
            "     56   100      0.00246      0.00228     0.000179       0.0307        0.041         4.14       0.0115\n",
            "     56   110      0.00194      0.00187     6.87e-05       0.0282       0.0372         2.56      0.00712\n",
            "     56   120      0.00178      0.00177     7.08e-06        0.028       0.0361        0.823      0.00229\n",
            "     56   130      0.00252      0.00251     1.36e-06        0.033       0.0431         0.36        0.001\n",
            "     56   140      0.00213      0.00209     4.34e-05         0.03       0.0392         2.04      0.00566\n",
            "     56   150      0.00245      0.00221     0.000236       0.0305       0.0404         4.75       0.0132\n",
            "     56   160      0.00217      0.00215     1.55e-05       0.0294       0.0398         1.22      0.00338\n",
            "     56   170      0.00321      0.00319     1.75e-05       0.0369       0.0485         1.29      0.00359\n",
            "     56   180      0.00274      0.00274     1.75e-06       0.0336       0.0449        0.409      0.00114\n",
            "     56   190      0.00229      0.00224     4.86e-05       0.0311       0.0406         2.16      0.00599\n",
            "     56   200       0.0022       0.0021     9.32e-05         0.03       0.0394         2.99      0.00829\n",
            "     56   210      0.00284      0.00265     0.000197       0.0333       0.0442         4.34        0.012\n",
            "     56   220      0.00197      0.00193      3.9e-05       0.0293       0.0377         1.93      0.00536\n",
            "     56   230      0.00228      0.00226     2.08e-05       0.0311       0.0408         1.41      0.00392\n",
            "     56   240      0.00264      0.00233     0.000307        0.032       0.0415         5.42       0.0151\n",
            "     56   250       0.0029       0.0025     0.000404       0.0325       0.0429         6.21       0.0173\n",
            "     56   260      0.00267      0.00233     0.000336       0.0312       0.0415         5.66       0.0157\n",
            "     56   270      0.00236      0.00226       0.0001       0.0312       0.0408          3.1       0.0086\n",
            "     56   280      0.00238      0.00238     8.18e-06       0.0317       0.0419        0.884      0.00246\n",
            "     56   290      0.00273      0.00272     1.56e-05       0.0342       0.0448         1.22      0.00339\n",
            "     56   300      0.00253      0.00252     1.47e-05       0.0335       0.0431         1.18      0.00329\n",
            "     56   310      0.00259      0.00258     2.31e-06       0.0327       0.0437         0.47      0.00131\n",
            "     56   320      0.00262      0.00258     3.47e-05       0.0336       0.0436         1.82      0.00506\n",
            "     56   330       0.0022      0.00208     0.000116       0.0301       0.0392         3.34      0.00927\n",
            "     56   340      0.00256      0.00256     5.45e-08       0.0325       0.0434       0.0722     0.000201\n",
            "     56   350       0.0026       0.0026     4.16e-06       0.0333       0.0438        0.631      0.00175\n",
            "     56   360      0.00245      0.00229     0.000162       0.0312       0.0411         3.93       0.0109\n",
            "     56   370      0.00225      0.00215     9.84e-05       0.0306       0.0398         3.07      0.00852\n",
            "     56   380      0.00187      0.00186     1.18e-05       0.0283        0.037         1.06      0.00295\n",
            "     56   390       0.0023      0.00228      1.3e-05       0.0315        0.041         1.11      0.00309\n",
            "     56   400       0.0023      0.00229     1.38e-06       0.0307       0.0411        0.363      0.00101\n",
            "     56   410      0.00245      0.00236     9.54e-05       0.0321       0.0417         3.02      0.00839\n",
            "     56   420      0.00199      0.00178     0.000212       0.0273       0.0362         4.51       0.0125\n",
            "     56   430      0.00243      0.00243     1.55e-08       0.0331       0.0424       0.0385     0.000107\n",
            "     56   440      0.00205      0.00193      0.00012       0.0294       0.0377         3.38       0.0094\n",
            "     56   450      0.00252      0.00249     2.99e-05       0.0333       0.0428         1.69       0.0047\n",
            "     56   460      0.00303      0.00303     7.94e-07       0.0371       0.0472        0.276     0.000765\n",
            "     56   470      0.00233      0.00229     4.39e-05       0.0313       0.0411         2.05      0.00569\n",
            "     56   480      0.00222      0.00196     0.000259       0.0289        0.038         4.97       0.0138\n",
            "     56   490      0.00293      0.00275     0.000179        0.034       0.0451         4.14       0.0115\n",
            "     56   500      0.00196      0.00195     5.71e-06       0.0292       0.0379        0.739      0.00205\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     56    10      0.00219      0.00218     4.38e-06       0.0307       0.0401        0.492      0.00137\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              56 7350.573    0.004      0.00241     7.74e-05      0.00249        0.032       0.0422         2.15      0.00597\n",
            "! Validation         56 7350.573    0.004      0.00208     7.53e-06      0.00209       0.0296       0.0392         0.67      0.00186\n",
            "Wall time: 7350.57303311\n",
            "! Best model       56    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     57    10      0.00278      0.00278     1.37e-06       0.0343       0.0453        0.361        0.001\n",
            "     57    20      0.00215      0.00211     3.89e-05       0.0299       0.0395         1.93      0.00535\n",
            "     57    30      0.00221       0.0022      3.4e-06       0.0312       0.0403         0.57      0.00158\n",
            "     57    40      0.00279      0.00274     5.16e-05       0.0344        0.045         2.22      0.00617\n",
            "     57    50      0.00213      0.00196     0.000172       0.0294        0.038         4.06       0.0113\n",
            "     57    60      0.00286       0.0025     0.000357       0.0327        0.043         5.84       0.0162\n",
            "     57    70      0.00239      0.00213      0.00026       0.0302       0.0396         4.98       0.0138\n",
            "     57    80      0.00221      0.00217     3.83e-05       0.0308         0.04         1.91      0.00532\n",
            "     57    90      0.00295      0.00294     5.03e-06       0.0354       0.0466        0.693      0.00193\n",
            "     57   100       0.0019      0.00189     1.89e-05       0.0286       0.0373         1.34      0.00373\n",
            "     57   110      0.00202        0.002     2.73e-05       0.0299       0.0384         1.62      0.00449\n",
            "     57   120      0.00291      0.00285      5.9e-05       0.0352       0.0459         2.38       0.0066\n",
            "     57   130      0.00232      0.00232     2.56e-07       0.0322       0.0414        0.157     0.000435\n",
            "     57   140      0.00219      0.00216     3.01e-05       0.0307       0.0399          1.7      0.00471\n",
            "     57   150       0.0021      0.00208     1.42e-05       0.0295       0.0392         1.16      0.00323\n",
            "     57   160       0.0024      0.00235     5.08e-05       0.0317       0.0416          2.2      0.00612\n",
            "     57   170      0.00243      0.00238     5.04e-05       0.0322       0.0419         2.19       0.0061\n",
            "     57   180      0.00193      0.00193     2.11e-06       0.0289       0.0377        0.449      0.00125\n",
            "     57   190      0.00316      0.00312     4.46e-05       0.0373       0.0479         2.07      0.00574\n",
            "     57   200      0.00233      0.00233     2.94e-09       0.0315       0.0414       0.0168     4.66e-05\n",
            "     57   210      0.00248      0.00247     3.24e-06       0.0339       0.0427        0.556      0.00155\n",
            "     57   220      0.00254      0.00253     9.79e-06       0.0322       0.0432        0.967      0.00269\n",
            "     57   230      0.00248      0.00248     4.25e-06       0.0326       0.0427        0.638      0.00177\n",
            "     57   240      0.00247      0.00247     2.52e-07       0.0329       0.0427        0.155     0.000431\n",
            "     57   250      0.00227      0.00226     1.01e-05       0.0312       0.0409        0.982      0.00273\n",
            "     57   260      0.00253      0.00245     8.12e-05       0.0323       0.0425         2.79      0.00774\n",
            "     57   270      0.00206      0.00201     5.08e-05       0.0293       0.0385          2.2      0.00612\n",
            "     57   280      0.00189      0.00187     1.56e-05       0.0279       0.0371         1.22      0.00339\n",
            "     57   290      0.00367      0.00356     0.000112       0.0384       0.0513         3.27      0.00909\n",
            "     57   300      0.00211      0.00209     1.86e-05        0.031       0.0393         1.33       0.0037\n",
            "     57   310      0.00244      0.00237     6.47e-05        0.032       0.0418         2.49      0.00691\n",
            "     57   320      0.00216      0.00213     2.44e-05       0.0304       0.0396         1.53      0.00424\n",
            "     57   330      0.00231      0.00227     4.23e-05       0.0314       0.0409         2.01      0.00558\n",
            "     57   340      0.00241      0.00235     5.92e-05       0.0322       0.0417         2.38      0.00661\n",
            "     57   350      0.00203      0.00201     2.76e-05       0.0297       0.0385         1.62      0.00451\n",
            "     57   360      0.00239      0.00239     3.73e-06       0.0332        0.042        0.597      0.00166\n",
            "     57   370      0.00272      0.00266     5.73e-05       0.0338       0.0443         2.34       0.0065\n",
            "     57   380      0.00182      0.00178     4.14e-05       0.0281       0.0362         1.99      0.00553\n",
            "     57   390      0.00194      0.00194      3.1e-07       0.0288       0.0379        0.172     0.000478\n",
            "     57   400      0.00263      0.00242      0.00021       0.0324       0.0423         4.48       0.0124\n",
            "     57   410      0.00231      0.00229      1.6e-05       0.0317       0.0411         1.24      0.00343\n",
            "     57   420      0.00264      0.00245     0.000185       0.0329       0.0426         4.21       0.0117\n",
            "     57   430      0.00209      0.00206      3.7e-05       0.0304        0.039         1.88      0.00522\n",
            "     57   440      0.00208      0.00206     1.58e-05       0.0302        0.039         1.23      0.00341\n",
            "     57   450      0.00334      0.00309     0.000254       0.0359       0.0477         4.93       0.0137\n",
            "     57   460      0.00226      0.00218     7.77e-05       0.0312       0.0401         2.73      0.00757\n",
            "     57   470      0.00193      0.00192     5.49e-06        0.029       0.0376        0.724      0.00201\n",
            "     57   480       0.0028       0.0028     2.89e-06       0.0344       0.0454        0.526      0.00146\n",
            "     57   490      0.00206      0.00204     1.41e-05       0.0294       0.0388         1.16      0.00322\n",
            "     57   500        0.002      0.00193     6.09e-05       0.0291       0.0378         2.41       0.0067\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     57    10      0.00217      0.00217     4.23e-06       0.0306         0.04         0.48      0.00133\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              57 7481.637    0.004      0.00237     6.79e-05      0.00244       0.0318       0.0418         2.04      0.00567\n",
            "! Validation         57 7481.637    0.004      0.00207      7.5e-06      0.00207       0.0295        0.039        0.666      0.00185\n",
            "Wall time: 7481.63754043\n",
            "! Best model       57    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     58    10      0.00242      0.00234     7.26e-05       0.0318       0.0416         2.63      0.00732\n",
            "     58    20      0.00205      0.00201     3.47e-05       0.0298       0.0385         1.82      0.00506\n",
            "     58    30      0.00307       0.0028     0.000266       0.0347       0.0455         5.04        0.014\n",
            "     58    40      0.00179       0.0017     8.98e-05        0.028       0.0354         2.93      0.00814\n",
            "     58    50      0.00214      0.00209     5.39e-05       0.0296       0.0392         2.27      0.00631\n",
            "     58    60      0.00285      0.00267     0.000171       0.0344       0.0444         4.05       0.0112\n",
            "     58    70      0.00292       0.0029     2.75e-05       0.0357       0.0462         1.62      0.00451\n",
            "     58    80      0.00246      0.00244     1.93e-05       0.0319       0.0425         1.36      0.00378\n",
            "     58    90      0.00224       0.0022     3.61e-05       0.0301       0.0403         1.86      0.00516\n",
            "     58   100      0.00267      0.00263     3.94e-05       0.0329        0.044         1.94      0.00539\n",
            "     58   110      0.00229      0.00228     9.95e-06       0.0316        0.041        0.975      0.00271\n",
            "     58   120      0.00266      0.00266     7.24e-07       0.0337       0.0443        0.263     0.000731\n",
            "     58   130      0.00206      0.00206     5.88e-07       0.0291        0.039        0.237     0.000659\n",
            "     58   140      0.00254      0.00253     1.49e-05       0.0323       0.0432         1.19      0.00332\n",
            "     58   150      0.00286      0.00286     4.89e-06       0.0359       0.0459        0.684       0.0019\n",
            "     58   160      0.00303      0.00302     1.58e-05       0.0368       0.0472         1.23      0.00341\n",
            "     58   170       0.0025      0.00249     6.53e-06       0.0321       0.0429         0.79       0.0022\n",
            "     58   180      0.00232      0.00228      4.5e-05       0.0313        0.041         2.07      0.00576\n",
            "     58   190      0.00265      0.00262     2.66e-05       0.0332        0.044          1.6      0.00443\n",
            "     58   200      0.00215      0.00215     2.75e-09       0.0299       0.0398       0.0162      4.5e-05\n",
            "     58   210       0.0031      0.00295     0.000148       0.0344       0.0466         3.77       0.0105\n",
            "     58   220      0.00252      0.00251     1.11e-05       0.0338       0.0431         1.03      0.00286\n",
            "     58   230      0.00196      0.00193     3.08e-05       0.0285       0.0377         1.71      0.00476\n",
            "     58   240      0.00254      0.00235     0.000195       0.0319       0.0416         4.31        0.012\n",
            "     58   250      0.00234      0.00217     0.000171        0.031         0.04         4.04       0.0112\n",
            "     58   260      0.00166      0.00165     1.01e-05       0.0268       0.0349        0.982      0.00273\n",
            "     58   270       0.0023      0.00223      7.1e-05       0.0313       0.0405         2.61      0.00724\n",
            "     58   280      0.00258      0.00258     2.57e-06       0.0327       0.0436        0.496      0.00138\n",
            "     58   290      0.00282      0.00282     6.56e-06        0.034       0.0456        0.792       0.0022\n",
            "     58   300      0.00286      0.00245     0.000414       0.0326       0.0425         6.29       0.0175\n",
            "     58   310      0.00256      0.00243     0.000136       0.0319       0.0423          3.6         0.01\n",
            "     58   320      0.00291      0.00288     2.88e-05       0.0347       0.0461         1.66      0.00461\n",
            "     58   330       0.0023      0.00228     2.53e-05       0.0302        0.041         1.55      0.00432\n",
            "     58   340      0.00258      0.00257     9.29e-06       0.0338       0.0436        0.942      0.00262\n",
            "     58   350       0.0023      0.00229      9.3e-06       0.0314       0.0411        0.943      0.00262\n",
            "     58   360      0.00269      0.00266     2.76e-05       0.0338       0.0443         1.62      0.00451\n",
            "     58   370      0.00213      0.00209     3.81e-05       0.0301       0.0393         1.91       0.0053\n",
            "     58   380      0.00224      0.00222     1.45e-05        0.031       0.0405         1.18      0.00327\n",
            "     58   390      0.00367      0.00363     4.08e-05       0.0388       0.0517         1.98      0.00549\n",
            "     58   400      0.00295      0.00295     8.23e-08       0.0339       0.0466       0.0887     0.000246\n",
            "     58   410       0.0028      0.00272     7.38e-05       0.0344       0.0448         2.66      0.00738\n",
            "     58   420      0.00268      0.00266     2.23e-05       0.0342       0.0443         1.46      0.00405\n",
            "     58   430      0.00232      0.00227     4.52e-05       0.0314        0.041         2.08      0.00577\n",
            "     58   440      0.00248      0.00245     2.94e-05       0.0324       0.0425         1.68      0.00466\n",
            "     58   450      0.00246      0.00233     0.000132       0.0318       0.0414         3.56      0.00988\n",
            "     58   460      0.00168      0.00167     4.11e-07       0.0275       0.0351        0.198      0.00055\n",
            "     58   470      0.00206      0.00205     8.09e-06         0.03       0.0389        0.879      0.00244\n",
            "     58   480      0.00202      0.00201     8.39e-06       0.0299       0.0385        0.896      0.00249\n",
            "     58   490      0.00315        0.003     0.000154       0.0357        0.047         3.83       0.0106\n",
            "     58   500      0.00189      0.00184     4.59e-05        0.028       0.0369          2.1      0.00582\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     58    10      0.00216      0.00216      4.6e-06       0.0305       0.0399        0.525      0.00146\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              58 7612.687    0.004      0.00246     7.79e-05      0.00253       0.0323       0.0426         2.09      0.00581\n",
            "! Validation         58 7612.687    0.004      0.00206     7.63e-06      0.00207       0.0294        0.039        0.687      0.00191\n",
            "Wall time: 7612.687907227\n",
            "! Best model       58    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     59    10      0.00181      0.00178     3.09e-05       0.0279       0.0362         1.72      0.00478\n",
            "     59    20      0.00183      0.00183      4.8e-06       0.0277       0.0367        0.677      0.00188\n",
            "     59    30      0.00193      0.00192     8.17e-06       0.0288       0.0376        0.884      0.00246\n",
            "     59    40       0.0027      0.00267     2.97e-05       0.0302       0.0444         1.69      0.00468\n",
            "     59    50      0.00299      0.00294     4.51e-05       0.0361       0.0466         2.08      0.00577\n",
            "     59    60      0.00222      0.00222      2.9e-06         0.03       0.0404        0.527      0.00146\n",
            "     59    70      0.00216      0.00215     1.24e-05       0.0301       0.0398         1.09      0.00302\n",
            "     59    80      0.00211      0.00181     0.000305       0.0283       0.0365          5.4        0.015\n",
            "     59    90      0.00435      0.00409     0.000258       0.0406       0.0549         4.96       0.0138\n",
            "     59   100      0.00258      0.00243     0.000147       0.0326       0.0423         3.75       0.0104\n",
            "     59   110      0.00197      0.00193     4.34e-05       0.0285       0.0377         2.04      0.00566\n",
            "     59   120      0.00233      0.00232     5.58e-06       0.0318       0.0414         0.73      0.00203\n",
            "     59   130      0.00237      0.00237      3.6e-06       0.0316       0.0418        0.587      0.00163\n",
            "     59   140      0.00217      0.00215     1.99e-05       0.0301       0.0398         1.38      0.00383\n",
            "     59   150      0.00231       0.0022     0.000118        0.031       0.0403         3.36      0.00934\n",
            "     59   160      0.00267      0.00261     5.34e-05       0.0338       0.0439         2.26      0.00627\n",
            "     59   170      0.00199      0.00198      4.8e-06       0.0289       0.0382        0.677      0.00188\n",
            "     59   180      0.00213      0.00213     6.39e-07       0.0298       0.0397        0.247     0.000687\n",
            "     59   190      0.00185      0.00177     7.48e-05       0.0276       0.0362         2.67      0.00743\n",
            "     59   200      0.00246      0.00222     0.000232       0.0308       0.0405         4.71       0.0131\n",
            "     59   210      0.00202       0.0019     0.000123       0.0289       0.0375         3.43      0.00952\n",
            "     59   220      0.00362      0.00342     0.000205       0.0383       0.0502         4.43       0.0123\n",
            "     59   230      0.00292      0.00279     0.000134       0.0349       0.0454         3.58      0.00996\n",
            "     59   240      0.00209       0.0018     0.000294       0.0286       0.0364          5.3       0.0147\n",
            "     59   250      0.00256      0.00256     6.12e-07       0.0334       0.0434        0.242     0.000672\n",
            "     59   260      0.00259      0.00257     2.28e-05        0.033       0.0435         1.48       0.0041\n",
            "     59   270      0.00237      0.00237     1.19e-06       0.0323       0.0418        0.338     0.000938\n",
            "     59   280      0.00195      0.00186     8.78e-05       0.0283        0.037          2.9      0.00805\n",
            "     59   290      0.00216      0.00204     0.000115       0.0299       0.0388         3.31      0.00921\n",
            "     59   300      0.00266      0.00262     3.92e-05       0.0331        0.044         1.93      0.00537\n",
            "     59   310      0.00202      0.00202     5.17e-11       0.0289       0.0386      0.00222     6.18e-06\n",
            "     59   320      0.00221      0.00218     2.93e-05       0.0305       0.0401         1.67      0.00465\n",
            "     59   330      0.00216      0.00215     1.18e-05       0.0301       0.0398         1.06      0.00295\n",
            "     59   340        0.002      0.00199     1.24e-05       0.0292       0.0383         1.09      0.00303\n",
            "     59   350      0.00228      0.00228     5.45e-06       0.0313        0.041        0.722        0.002\n",
            "     59   360       0.0023      0.00206     0.000233         0.03        0.039         4.72       0.0131\n",
            "     59   370      0.00204      0.00203     1.61e-05         0.03       0.0387         1.24      0.00345\n",
            "     59   380      0.00244      0.00243     4.35e-06       0.0325       0.0424        0.645      0.00179\n",
            "     59   390      0.00184      0.00183     1.81e-06       0.0284       0.0368        0.416      0.00115\n",
            "     59   400      0.00189      0.00185     3.54e-05        0.029        0.037         1.84      0.00511\n",
            "     59   410      0.00228      0.00228     8.99e-07       0.0316        0.041        0.293     0.000814\n",
            "     59   420      0.00359      0.00357     1.27e-05       0.0389       0.0513          1.1      0.00306\n",
            "     59   430      0.00273      0.00259     0.000146       0.0335       0.0437         3.73       0.0104\n",
            "     59   440      0.00193      0.00192     2.86e-06       0.0287       0.0377        0.523      0.00145\n",
            "     59   450      0.00171      0.00169     2.38e-05       0.0272       0.0353         1.51      0.00419\n",
            "     59   460      0.00203      0.00203     2.02e-06       0.0299       0.0387        0.439      0.00122\n",
            "     59   470      0.00231      0.00231     7.76e-06       0.0313       0.0412        0.861      0.00239\n",
            "     59   480      0.00261      0.00256     4.56e-05       0.0333       0.0435         2.09       0.0058\n",
            "     59   490      0.00254      0.00253     1.64e-05       0.0325       0.0432         1.25      0.00348\n",
            "     59   500      0.00248      0.00241     7.11e-05        0.032       0.0421         2.61      0.00724\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     59    10      0.00214      0.00214     4.26e-06       0.0303       0.0397        0.472      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              59 7743.983    0.004       0.0023     7.04e-05      0.00237       0.0313       0.0412         2.06      0.00572\n",
            "! Validation         59 7743.983    0.004      0.00203     7.45e-06      0.00204       0.0292       0.0387        0.657      0.00182\n",
            "Wall time: 7743.983811853999\n",
            "! Best model       59    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     60    10      0.00284      0.00281     2.38e-05       0.0347       0.0456         1.51      0.00419\n",
            "     60    20      0.00238      0.00231     6.73e-05       0.0322       0.0413         2.54      0.00705\n",
            "     60    30       0.0028      0.00275      4.4e-05       0.0334       0.0451         2.05       0.0057\n",
            "     60    40      0.00235      0.00233     2.72e-05       0.0319       0.0414         1.61      0.00448\n",
            "     60    50      0.00246      0.00241      5.4e-05       0.0326       0.0422         2.27      0.00631\n",
            "     60    60      0.00232      0.00221      0.00011        0.031       0.0404         3.24      0.00899\n",
            "     60    70       0.0027      0.00268     1.82e-05       0.0338       0.0444         1.32      0.00366\n",
            "     60    80       0.0022       0.0022     2.54e-06       0.0307       0.0403        0.493      0.00137\n",
            "     60    90       0.0019       0.0019     3.42e-06       0.0283       0.0374        0.572      0.00159\n",
            "     60   100      0.00393      0.00392     5.54e-06       0.0397       0.0538        0.728      0.00202\n",
            "     60   110      0.00217      0.00217     5.22e-07       0.0309         0.04        0.223      0.00062\n",
            "     60   120      0.00193      0.00192     1.51e-05       0.0287       0.0376          1.2      0.00333\n",
            "     60   130      0.00232      0.00231     1.09e-05       0.0306       0.0412         1.02      0.00284\n",
            "     60   140      0.00193      0.00177     0.000166       0.0281       0.0361         3.99       0.0111\n",
            "     60   150      0.00236      0.00216     0.000198       0.0303       0.0399         4.35       0.0121\n",
            "     60   160      0.00197      0.00196     4.88e-06        0.029       0.0381        0.683       0.0019\n",
            "     60   170      0.00221       0.0022     2.81e-06       0.0313       0.0403        0.519      0.00144\n",
            "     60   180      0.00204        0.002     4.14e-05       0.0299       0.0384         1.99      0.00552\n",
            "     60   190       0.0026      0.00234      0.00026       0.0326       0.0416         4.98       0.0138\n",
            "     60   200      0.00227      0.00221     6.14e-05       0.0305       0.0404         2.42      0.00673\n",
            "     60   210      0.00228      0.00223     5.55e-05       0.0312       0.0405          2.3       0.0064\n",
            "     60   220      0.00191      0.00184     7.15e-05       0.0277       0.0368         2.62      0.00726\n",
            "     60   230      0.00218      0.00208     0.000102       0.0298       0.0392         3.13      0.00868\n",
            "     60   240      0.00389      0.00328     0.000612       0.0374       0.0492         7.65       0.0212\n",
            "     60   250       0.0021      0.00206     3.67e-05       0.0303        0.039         1.87       0.0052\n",
            "     60   260      0.00279      0.00271      8.4e-05       0.0337       0.0447         2.83      0.00787\n",
            "     60   270      0.00272      0.00271     6.67e-06       0.0342       0.0447        0.798      0.00222\n",
            "     60   280      0.00217      0.00207     0.000103       0.0305       0.0391         3.14      0.00871\n",
            "     60   290      0.00228      0.00207       0.0002       0.0306       0.0391         4.38       0.0122\n",
            "     60   300      0.00196      0.00193     2.64e-05       0.0292       0.0378         1.59      0.00442\n",
            "     60   310       0.0025       0.0025     1.15e-06       0.0316        0.043        0.332     0.000922\n",
            "     60   320      0.00239      0.00237     1.89e-05        0.032       0.0418         1.34      0.00373\n",
            "     60   330      0.00247      0.00241      5.7e-05       0.0312       0.0422         2.33      0.00648\n",
            "     60   340      0.00215      0.00205     9.57e-05       0.0302       0.0389         3.02       0.0084\n",
            "     60   350      0.00202      0.00202     1.52e-07       0.0295       0.0386        0.121     0.000335\n",
            "     60   360      0.00265      0.00265     8.44e-07       0.0332       0.0442        0.284     0.000789\n",
            "     60   370      0.00337      0.00336     1.75e-05       0.0367       0.0497         1.29      0.00359\n",
            "     60   380      0.00227      0.00226     8.55e-06       0.0314       0.0408        0.904      0.00251\n",
            "     60   390      0.00209      0.00196     0.000134       0.0285        0.038         3.58      0.00993\n",
            "     60   400      0.00184      0.00183     1.56e-05       0.0283       0.0367         1.22      0.00339\n",
            "     60   410      0.00199      0.00198     1.07e-05       0.0286       0.0382         1.01      0.00281\n",
            "     60   420       0.0031      0.00309     8.33e-06       0.0352       0.0477        0.893      0.00248\n",
            "     60   430      0.00254      0.00236     0.000182       0.0324       0.0417         4.17       0.0116\n",
            "     60   440      0.00197      0.00194     2.57e-05       0.0294       0.0379         1.57      0.00435\n",
            "     60   450      0.00285      0.00285     1.01e-06       0.0348       0.0458        0.311     0.000863\n",
            "     60   460      0.00207      0.00204      2.4e-05       0.0298       0.0388         1.51       0.0042\n",
            "     60   470      0.00182       0.0018     1.94e-05       0.0283       0.0364         1.36      0.00378\n",
            "     60   480      0.00204      0.00196     7.78e-05       0.0292        0.038         2.73      0.00758\n",
            "     60   490      0.00263      0.00253     0.000107       0.0324       0.0432         3.19      0.00887\n",
            "     60   500      0.00248      0.00241     7.43e-05       0.0317       0.0421         2.67       0.0074\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     60    10      0.00212      0.00212     4.56e-06       0.0302       0.0395        0.524      0.00145\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              60 7875.314    0.004      0.00228     6.97e-05      0.00235       0.0312        0.041         2.06      0.00571\n",
            "! Validation         60 7875.314    0.004      0.00202     7.68e-06      0.00203       0.0291       0.0386        0.689      0.00191\n",
            "Wall time: 7875.3140197150005\n",
            "! Best model       60    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     61    10      0.00289      0.00289     1.73e-07       0.0356       0.0462        0.129     0.000358\n",
            "     61    20      0.00265      0.00242     0.000232       0.0332       0.0422          4.7       0.0131\n",
            "     61    30      0.00252      0.00224     0.000277       0.0313       0.0407         5.14       0.0143\n",
            "     61    40      0.00272       0.0027     1.48e-05       0.0336       0.0446         1.19      0.00331\n",
            "     61    50      0.00214        0.002     0.000136       0.0293       0.0384         3.61         0.01\n",
            "     61    60      0.00227      0.00226     7.39e-06       0.0305       0.0409        0.841      0.00234\n",
            "     61    70      0.00292      0.00288     4.43e-05       0.0325       0.0461         2.06      0.00572\n",
            "     61    80      0.00191      0.00185     5.67e-05       0.0285        0.037         2.33      0.00646\n",
            "     61    90      0.00186      0.00186     1.92e-06       0.0287        0.037        0.428      0.00119\n",
            "     61   100      0.00196      0.00191     5.21e-05       0.0286       0.0375         2.23       0.0062\n",
            "     61   110       0.0016      0.00159     1.73e-05       0.0265       0.0342         1.28      0.00357\n",
            "     61   120      0.00236      0.00235     6.68e-06       0.0318       0.0416        0.799      0.00222\n",
            "     61   130      0.00232       0.0023     1.47e-05       0.0321       0.0412         1.18      0.00329\n",
            "     61   140      0.00252      0.00247      4.2e-05       0.0323       0.0427            2      0.00557\n",
            "     61   150      0.00247      0.00246     3.28e-07       0.0331       0.0426        0.177     0.000492\n",
            "     61   160      0.00304      0.00292     0.000127       0.0351       0.0464         3.48      0.00968\n",
            "     61   170      0.00258      0.00257     1.14e-05       0.0327       0.0435         1.04       0.0029\n",
            "     61   180      0.00245      0.00245     5.04e-07       0.0326       0.0425         0.22      0.00061\n",
            "     61   190      0.00242      0.00224      0.00018       0.0313       0.0407         4.15       0.0115\n",
            "     61   200       0.0031      0.00303     6.83e-05       0.0342       0.0473         2.55       0.0071\n",
            "     61   210      0.00182      0.00181     7.46e-06       0.0283       0.0366        0.844      0.00235\n",
            "     61   220      0.00187      0.00186     1.05e-05       0.0286        0.037            1      0.00279\n",
            "     61   230      0.00206      0.00206     2.51e-07       0.0299        0.039        0.155      0.00043\n",
            "     61   240      0.00214      0.00209     4.65e-05       0.0305       0.0393         2.11      0.00586\n",
            "     61   250      0.00246      0.00246     6.45e-06       0.0326       0.0426        0.785      0.00218\n",
            "     61   260      0.00223      0.00217      5.8e-05       0.0308         0.04         2.35      0.00654\n",
            "     61   270      0.00231      0.00204     0.000263       0.0305       0.0388         5.02       0.0139\n",
            "     61   280      0.00323      0.00319      3.7e-05        0.036       0.0485         1.88      0.00523\n",
            "     61   290      0.00222       0.0022     2.02e-05       0.0311       0.0403         1.39      0.00386\n",
            "     61   300      0.00213      0.00212      9.9e-06       0.0307       0.0396        0.973       0.0027\n",
            "     61   310      0.00231      0.00226     4.69e-05       0.0309       0.0408         2.12      0.00588\n",
            "     61   320      0.00216      0.00216        2e-06       0.0298       0.0399        0.438      0.00122\n",
            "     61   330      0.00238      0.00237     1.16e-05       0.0319       0.0418         1.05      0.00292\n",
            "     61   340       0.0023      0.00221     8.89e-05       0.0316       0.0404         2.92       0.0081\n",
            "     61   350      0.00239      0.00239      4.2e-06       0.0301        0.042        0.633      0.00176\n",
            "     61   360      0.00165       0.0016     4.54e-05       0.0262       0.0344         2.08      0.00578\n",
            "     61   370       0.0038      0.00375     4.78e-05       0.0397       0.0526         2.14      0.00594\n",
            "     61   380       0.0024      0.00238     1.68e-05       0.0315       0.0419         1.27      0.00352\n",
            "     61   390      0.00219      0.00219     1.51e-06        0.031       0.0402         0.38      0.00106\n",
            "     61   400      0.00188      0.00185     2.96e-05       0.0283       0.0369         1.68      0.00468\n",
            "     61   410      0.00195      0.00195     1.58e-07        0.029        0.038        0.123     0.000342\n",
            "     61   420      0.00192       0.0019     1.44e-05       0.0279       0.0374         1.17      0.00326\n",
            "     61   430      0.00245      0.00242     2.76e-05       0.0315       0.0423         1.63      0.00451\n",
            "     61   440      0.00193      0.00189     4.72e-05       0.0285       0.0373         2.12       0.0059\n",
            "     61   450      0.00234      0.00232     1.67e-05       0.0323       0.0414         1.26      0.00351\n",
            "     61   460      0.00225       0.0022     5.44e-05       0.0306       0.0403         2.28      0.00633\n",
            "     61   470      0.00261      0.00237     0.000241       0.0307       0.0418          4.8       0.0133\n",
            "     61   480      0.00253      0.00249     3.38e-05       0.0331       0.0429          1.8      0.00499\n",
            "     61   490      0.00282      0.00278     3.43e-05       0.0343       0.0453         1.81      0.00503\n",
            "     61   500      0.00215      0.00211     3.95e-05       0.0301       0.0395         1.94       0.0054\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     61    10      0.00211       0.0021     4.04e-06       0.0301       0.0394        0.457      0.00127\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              61 8006.416    0.004      0.00232     7.57e-05       0.0024       0.0314       0.0414         2.18      0.00606\n",
            "! Validation         61 8006.416    0.004      0.00201      7.6e-06      0.00202       0.0291       0.0385         0.66      0.00183\n",
            "Wall time: 8006.415995613999\n",
            "! Best model       61    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     62    10      0.00285      0.00284     1.34e-05       0.0353       0.0458         1.13      0.00314\n",
            "     62    20      0.00233      0.00225     8.91e-05       0.0307       0.0407         2.92      0.00811\n",
            "     62    30      0.00248      0.00246     1.95e-05       0.0324       0.0426         1.36      0.00379\n",
            "     62    40      0.00229      0.00229     3.36e-06       0.0315       0.0411        0.566      0.00157\n",
            "     62    50      0.00239      0.00239     4.44e-06       0.0313       0.0419        0.651      0.00181\n",
            "     62    60       0.0027      0.00264     6.25e-05       0.0324       0.0441         2.44      0.00679\n",
            "     62    70      0.00233      0.00223     9.93e-05        0.031       0.0406         3.08      0.00856\n",
            "     62    80      0.00207      0.00207      3.1e-09         0.03       0.0391       0.0172     4.78e-05\n",
            "     62    90      0.00271      0.00267     3.97e-05       0.0338       0.0444         1.95      0.00541\n",
            "     62   100       0.0024       0.0023     0.000108       0.0313       0.0412         3.22      0.00894\n",
            "     62   110      0.00238      0.00208     0.000302       0.0301       0.0392         5.37       0.0149\n",
            "     62   120      0.00171       0.0017     1.05e-05       0.0272       0.0355            1      0.00279\n",
            "     62   130      0.00254      0.00253     1.04e-05       0.0333       0.0432        0.997      0.00277\n",
            "     62   140      0.00214      0.00211     3.05e-05       0.0291       0.0395         1.71      0.00474\n",
            "     62   150      0.00197      0.00194     3.08e-05       0.0289       0.0378         1.71      0.00476\n",
            "     62   160      0.00234      0.00234     8.32e-07       0.0318       0.0415        0.282     0.000783\n",
            "     62   170      0.00207      0.00206        1e-05       0.0303        0.039        0.979      0.00272\n",
            "     62   180        0.002      0.00199     7.23e-06       0.0295       0.0383        0.831      0.00231\n",
            "     62   190      0.00272      0.00239     0.000324       0.0324        0.042         5.57       0.0155\n",
            "     62   200      0.00203      0.00185     0.000179       0.0283       0.0369         4.14       0.0115\n",
            "     62   210      0.00299      0.00289      9.2e-05       0.0345       0.0462         2.97      0.00824\n",
            "     62   220      0.00211      0.00205     5.13e-05       0.0301       0.0389         2.22      0.00615\n",
            "     62   230      0.00264      0.00263     1.09e-05       0.0332       0.0441         1.02      0.00283\n",
            "     62   240      0.00312      0.00295      0.00017       0.0353       0.0466         4.03       0.0112\n",
            "     62   250      0.00209      0.00187     0.000216       0.0278       0.0372         4.54       0.0126\n",
            "     62   260      0.00235      0.00228     6.18e-05       0.0308        0.041         2.43      0.00675\n",
            "     62   270      0.00229      0.00225     4.66e-05       0.0312       0.0407         2.11      0.00586\n",
            "     62   280      0.00203      0.00202     9.78e-06       0.0297       0.0386        0.967      0.00269\n",
            "     62   290      0.00306      0.00256     0.000493       0.0334       0.0435         6.86       0.0191\n",
            "     62   300      0.00307      0.00266     0.000405       0.0343       0.0443         6.22       0.0173\n",
            "     62   310      0.00207      0.00207     5.59e-06       0.0301        0.039        0.731      0.00203\n",
            "     62   320      0.00214      0.00213     9.65e-06       0.0304       0.0397         0.96      0.00267\n",
            "     62   330      0.00178      0.00178     1.44e-06        0.028       0.0362        0.371      0.00103\n",
            "     62   340      0.00212      0.00211     1.01e-05       0.0293       0.0394        0.982      0.00273\n",
            "     62   350      0.00193      0.00193     6.58e-07        0.029       0.0377        0.251     0.000697\n",
            "     62   360      0.00191      0.00189      2.2e-05       0.0284       0.0373         1.45      0.00403\n",
            "     62   370      0.00178      0.00177     8.31e-06       0.0279       0.0361        0.891      0.00248\n",
            "     62   380      0.00287      0.00274     0.000123       0.0344        0.045         3.43      0.00952\n",
            "     62   390      0.00234      0.00232     2.01e-05       0.0306       0.0414         1.39      0.00385\n",
            "     62   400      0.00192      0.00192      1.4e-07       0.0287       0.0376        0.116     0.000322\n",
            "     62   410      0.00254      0.00246     8.44e-05       0.0321       0.0426         2.84      0.00789\n",
            "     62   420      0.00199      0.00193     6.41e-05       0.0291       0.0377         2.48      0.00688\n",
            "     62   430      0.00256      0.00242     0.000143       0.0323       0.0422         3.69       0.0103\n",
            "     62   440      0.00247      0.00247     2.38e-06       0.0325       0.0427        0.477      0.00133\n",
            "     62   450      0.00264      0.00263     1.08e-05       0.0335       0.0441         1.02      0.00282\n",
            "     62   460      0.00301      0.00293     8.59e-05       0.0346       0.0465         2.87      0.00796\n",
            "     62   470      0.00217      0.00215     2.22e-05       0.0297       0.0398         1.46      0.00405\n",
            "     62   480      0.00211      0.00211     2.17e-07       0.0298       0.0394        0.144       0.0004\n",
            "     62   490      0.00283      0.00277     5.46e-05        0.035       0.0452         2.29      0.00635\n",
            "     62   500      0.00214      0.00206     7.96e-05       0.0302        0.039         2.76      0.00766\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     62    10       0.0021      0.00209     4.04e-06         0.03       0.0393        0.458      0.00127\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              62 8137.473    0.004      0.00227     6.48e-05      0.00234       0.0311       0.0409         1.97      0.00548\n",
            "! Validation         62 8137.473    0.004        0.002     7.53e-06        0.002       0.0289       0.0384        0.658      0.00183\n",
            "Wall time: 8137.473938775\n",
            "! Best model       62    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     63    10       0.0023      0.00226      4.1e-05        0.032       0.0408         1.98       0.0055\n",
            "     63    20      0.00238      0.00238     1.57e-07        0.032       0.0419        0.123      0.00034\n",
            "     63    30      0.00218      0.00216     2.47e-05       0.0299       0.0399         1.54      0.00427\n",
            "     63    40      0.00189      0.00185     4.01e-05       0.0282       0.0369         1.96      0.00544\n",
            "     63    50      0.00265      0.00265     2.05e-06       0.0344       0.0442        0.442      0.00123\n",
            "     63    60       0.0023      0.00229     1.05e-05        0.032       0.0411            1      0.00279\n",
            "     63    70      0.00195      0.00193     1.58e-05       0.0285       0.0377         1.23      0.00341\n",
            "     63    80      0.00257       0.0024      0.00017       0.0307       0.0421         4.03       0.0112\n",
            "     63    90      0.00227      0.00173     0.000535       0.0284       0.0357         7.15       0.0199\n",
            "     63   100       0.0021      0.00197     0.000137       0.0287       0.0381         3.61         0.01\n",
            "     63   110      0.00211      0.00203     7.82e-05       0.0295       0.0387         2.73      0.00759\n",
            "     63   120       0.0024      0.00238     1.65e-05       0.0308       0.0419         1.26      0.00349\n",
            "     63   130      0.00239      0.00239     2.85e-06       0.0313        0.042        0.522      0.00145\n",
            "     63   140      0.00218      0.00215     2.71e-05         0.03       0.0399         1.61      0.00447\n",
            "     63   150      0.00288      0.00288     1.15e-06       0.0346       0.0461        0.332     0.000921\n",
            "     63   160      0.00358      0.00358     1.17e-06       0.0392       0.0514        0.335      0.00093\n",
            "     63   170      0.00279      0.00276     2.96e-05       0.0343       0.0451         1.68      0.00467\n",
            "     63   180      0.00199      0.00197     2.37e-05       0.0293       0.0381         1.51      0.00418\n",
            "     63   190      0.00193      0.00193     4.48e-06       0.0277       0.0377        0.654      0.00182\n",
            "     63   200      0.00273       0.0026     0.000128       0.0321       0.0438         3.49      0.00971\n",
            "     63   210       0.0024       0.0024     3.71e-09       0.0326       0.0421       0.0188     5.23e-05\n",
            "     63   220      0.00244      0.00238     6.31e-05       0.0321       0.0419         2.46      0.00682\n",
            "     63   230      0.00216      0.00215     5.18e-06       0.0308       0.0398        0.704      0.00195\n",
            "     63   240      0.00237      0.00217     0.000198       0.0306         0.04         4.36       0.0121\n",
            "     63   250      0.00228      0.00224     3.48e-05       0.0307       0.0407         1.82      0.00507\n",
            "     63   260      0.00209      0.00209     7.83e-08       0.0298       0.0392       0.0865      0.00024\n",
            "     63   270      0.00267      0.00267     5.26e-09        0.034       0.0444       0.0224     6.23e-05\n",
            "     63   280      0.00244      0.00232     0.000113       0.0321       0.0414         3.29      0.00913\n",
            "     63   290      0.00323      0.00323     2.38e-06        0.037       0.0488        0.477      0.00132\n",
            "     63   300      0.00316      0.00316     1.02e-06       0.0362       0.0483        0.312     0.000868\n",
            "     63   310      0.00247      0.00246     8.32e-06       0.0335       0.0426        0.892      0.00248\n",
            "     63   320      0.00248      0.00247     8.77e-06       0.0327       0.0427        0.915      0.00254\n",
            "     63   330       0.0024      0.00236     3.23e-05       0.0318       0.0418         1.76      0.00488\n",
            "     63   340      0.00253      0.00252     8.86e-06       0.0324       0.0431         0.92      0.00256\n",
            "     63   350      0.00254      0.00254     3.93e-08       0.0335       0.0433       0.0613      0.00017\n",
            "     63   360      0.00234      0.00233     1.09e-05       0.0321       0.0415         1.02      0.00284\n",
            "     63   370      0.00188      0.00187     1.31e-05       0.0288       0.0371         1.12      0.00311\n",
            "     63   380      0.00256      0.00255     1.43e-05       0.0327       0.0433         1.17      0.00325\n",
            "     63   390      0.00403      0.00331     0.000721       0.0374       0.0494          8.3       0.0231\n",
            "     63   400       0.0023      0.00198     0.000324       0.0295       0.0382         5.56       0.0155\n",
            "     63   410      0.00203      0.00202     8.41e-06       0.0296       0.0386        0.897      0.00249\n",
            "     63   420      0.00254       0.0025     3.48e-05       0.0323        0.043         1.82      0.00507\n",
            "     63   430      0.00248      0.00234      0.00014       0.0295       0.0416         3.66       0.0102\n",
            "     63   440      0.00222      0.00219     3.59e-05       0.0302       0.0402         1.85      0.00515\n",
            "     63   450      0.00232       0.0021     0.000219       0.0303       0.0394         4.57       0.0127\n",
            "     63   460      0.00216      0.00214     1.49e-05       0.0306       0.0397         1.19      0.00331\n",
            "     63   470      0.00184      0.00184     3.55e-06       0.0288       0.0368        0.582      0.00162\n",
            "     63   480      0.00359      0.00353     5.96e-05       0.0385        0.051         2.39      0.00663\n",
            "     63   490      0.00283      0.00277     5.46e-05        0.035       0.0452         2.28      0.00635\n",
            "     63   500      0.00222      0.00213     9.03e-05       0.0304       0.0396         2.94      0.00816\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     63    10      0.00208      0.00208     4.13e-06       0.0299       0.0392        0.465      0.00129\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              63 8268.616    0.004      0.00231     9.21e-05       0.0024       0.0314       0.0413         2.33      0.00647\n",
            "! Validation         63 8268.616    0.004      0.00199     7.51e-06        0.002       0.0289       0.0383        0.661      0.00184\n",
            "Wall time: 8268.616802288\n",
            "! Best model       63    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     64    10      0.00263       0.0025     0.000127       0.0328        0.043         3.48      0.00967\n",
            "     64    20      0.00239      0.00229     9.82e-05        0.031       0.0411         3.06      0.00851\n",
            "     64    30      0.00232      0.00228      3.9e-05       0.0313        0.041         1.93      0.00537\n",
            "     64    40      0.00237      0.00234     3.72e-05       0.0311       0.0415         1.88      0.00524\n",
            "     64    50      0.00203        0.002     3.21e-05       0.0291       0.0384         1.75      0.00487\n",
            "     64    60      0.00273      0.00271     1.98e-05       0.0348       0.0447         1.38      0.00382\n",
            "     64    70      0.00213      0.00208     5.06e-05       0.0296       0.0392          2.2      0.00611\n",
            "     64    80       0.0019      0.00178     0.000114       0.0284       0.0363          3.3      0.00917\n",
            "     64    90      0.00208      0.00205      2.7e-05       0.0296       0.0389         1.61      0.00446\n",
            "     64   100      0.00256      0.00252      4.2e-05       0.0338       0.0431            2      0.00557\n",
            "     64   110      0.00203      0.00203     2.98e-06       0.0297       0.0387        0.534      0.00148\n",
            "     64   120      0.00229      0.00228     2.41e-06       0.0315        0.041         0.48      0.00133\n",
            "     64   130       0.0021       0.0017     0.000396       0.0276       0.0354         6.15       0.0171\n",
            "     64   140      0.00224      0.00183     0.000417       0.0281       0.0367         6.32       0.0175\n",
            "     64   150      0.00181       0.0018     8.23e-06       0.0273       0.0365        0.887      0.00246\n",
            "     64   160      0.00185      0.00182     2.76e-05       0.0279       0.0366         1.63      0.00451\n",
            "     64   170      0.00298      0.00278     0.000204       0.0338       0.0453         4.42       0.0123\n",
            "     64   180      0.00241      0.00241     1.33e-07       0.0323       0.0422        0.113     0.000314\n",
            "     64   190      0.00194       0.0019     3.54e-05       0.0293       0.0375         1.84      0.00511\n",
            "     64   200      0.00205        0.002     4.98e-05       0.0296       0.0384         2.18      0.00606\n",
            "     64   210      0.00236      0.00226     0.000104       0.0308       0.0408         3.16      0.00877\n",
            "     64   220      0.00261      0.00261     4.94e-08       0.0322       0.0439       0.0687     0.000191\n",
            "     64   230      0.00357      0.00356     1.46e-05       0.0382       0.0512         1.18      0.00328\n",
            "     64   240      0.00256       0.0024      0.00015       0.0315       0.0421         3.79       0.0105\n",
            "     64   250      0.00236      0.00223     0.000139       0.0304       0.0405         3.64       0.0101\n",
            "     64   260      0.00319      0.00295     0.000247       0.0353       0.0466         4.86       0.0135\n",
            "     64   270      0.00196      0.00188        8e-05       0.0281       0.0373         2.77      0.00768\n",
            "     64   280      0.00317      0.00269     0.000472        0.034       0.0446         6.72       0.0187\n",
            "     64   290        0.003      0.00279     0.000206       0.0354       0.0454         4.44       0.0123\n",
            "     64   300      0.00245       0.0024     5.25e-05       0.0325       0.0421         2.24      0.00622\n",
            "     64   310      0.00217      0.00201     0.000154       0.0297       0.0385         3.83       0.0107\n",
            "     64   320      0.00243      0.00229     0.000145       0.0316       0.0411         3.72       0.0103\n",
            "     64   330      0.00189      0.00189     7.86e-06       0.0274       0.0373        0.867      0.00241\n",
            "     64   340       0.0022      0.00217     2.92e-05       0.0305         0.04         1.67      0.00464\n",
            "     64   350       0.0015      0.00149     8.19e-06       0.0255       0.0331        0.885      0.00246\n",
            "     64   360      0.00238      0.00219     0.000194       0.0298       0.0402          4.3        0.012\n",
            "     64   370      0.00194      0.00185     9.08e-05       0.0286       0.0369         2.95      0.00818\n",
            "     64   380      0.00194      0.00194     1.69e-06       0.0296       0.0378        0.402      0.00112\n",
            "     64   390      0.00238      0.00222     0.000163       0.0302       0.0404         3.95        0.011\n",
            "     64   400      0.00253      0.00241      0.00012       0.0323       0.0421         3.39      0.00941\n",
            "     64   410      0.00256      0.00255     1.54e-06       0.0322       0.0434        0.384      0.00107\n",
            "     64   420      0.00162      0.00162     1.29e-06       0.0269       0.0346        0.351     0.000975\n",
            "     64   430      0.00182      0.00181     1.25e-05       0.0285       0.0365         1.09      0.00303\n",
            "     64   440      0.00352      0.00351      6.9e-06       0.0382       0.0509        0.812      0.00226\n",
            "     64   450      0.00181      0.00181     4.26e-06       0.0278       0.0365        0.638      0.00177\n",
            "     64   460      0.00237      0.00235     1.64e-05        0.032       0.0416         1.25      0.00348\n",
            "     64   470      0.00196      0.00195        8e-06       0.0289        0.038        0.874      0.00243\n",
            "     64   480      0.00289      0.00289     4.71e-06       0.0352       0.0461        0.671      0.00186\n",
            "     64   490      0.00199      0.00199     1.13e-06       0.0293       0.0383        0.329     0.000914\n",
            "     64   500      0.00286      0.00283     3.14e-05        0.035       0.0457         1.73      0.00481\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     64    10      0.00206      0.00205     4.43e-06       0.0297       0.0389        0.504       0.0014\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              64 8399.795    0.004      0.00225     7.24e-05      0.00232       0.0309       0.0407         2.06      0.00571\n",
            "! Validation         64 8399.795    0.004      0.00197     7.61e-06      0.00198       0.0288       0.0381         0.68      0.00189\n",
            "Wall time: 8399.795784123\n",
            "! Best model       64    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     65    10      0.00218      0.00189     0.000295       0.0283       0.0373         5.31       0.0147\n",
            "     65    20      0.00197      0.00196     7.85e-06       0.0288       0.0381        0.866      0.00241\n",
            "     65    30      0.00235      0.00231     3.72e-05       0.0314       0.0413         1.89      0.00524\n",
            "     65    40      0.00171      0.00166     5.29e-05       0.0271       0.0349         2.25      0.00624\n",
            "     65    50      0.00199      0.00198     1.06e-05       0.0289       0.0382         1.01       0.0028\n",
            "     65    60       0.0019      0.00178     0.000117       0.0278       0.0362         3.34      0.00928\n",
            "     65    70      0.00206      0.00205     1.22e-05       0.0303       0.0389         1.08        0.003\n",
            "     65    80       0.0024      0.00239     1.73e-06       0.0323        0.042        0.406      0.00113\n",
            "     65    90      0.00207      0.00187     0.000199       0.0296       0.0372         4.36       0.0121\n",
            "     65   100      0.00167      0.00167     1.73e-08       0.0274       0.0351       0.0406     0.000113\n",
            "     65   110      0.00201      0.00199      1.3e-05       0.0294       0.0383         1.11       0.0031\n",
            "     65   120      0.00198      0.00195     2.49e-05       0.0292       0.0379         1.54      0.00429\n",
            "     65   130      0.00253      0.00248     4.22e-05       0.0326       0.0428         2.01      0.00558\n",
            "     65   140      0.00365       0.0036     4.99e-05       0.0392       0.0515         2.18      0.00606\n",
            "     65   150      0.00197      0.00197     1.55e-06       0.0294       0.0381        0.385      0.00107\n",
            "     65   160      0.00248      0.00223     0.000253       0.0315       0.0406         4.92       0.0137\n",
            "     65   170      0.00238      0.00238     2.04e-06       0.0315       0.0419        0.442      0.00123\n",
            "     65   180      0.00217      0.00208     8.36e-05       0.0299       0.0392         2.83      0.00785\n",
            "     65   190      0.00194      0.00194     1.22e-07        0.029       0.0378        0.108       0.0003\n",
            "     65   200      0.00205      0.00204     1.79e-05       0.0296       0.0388         1.31      0.00364\n",
            "     65   210      0.00245      0.00238     6.97e-05       0.0318       0.0419         2.58      0.00717\n",
            "     65   220      0.00253      0.00248     5.66e-05       0.0325       0.0427         2.33      0.00646\n",
            "     65   230      0.00198      0.00191     7.13e-05        0.029       0.0375         2.61      0.00725\n",
            "     65   240      0.00259      0.00257      1.7e-05       0.0333       0.0435         1.27      0.00354\n",
            "     65   250      0.00228      0.00222     5.84e-05       0.0314       0.0405         2.36      0.00656\n",
            "     65   260      0.00177      0.00167       0.0001       0.0273       0.0351          3.1       0.0086\n",
            "     65   270      0.00175      0.00173     1.69e-05       0.0277       0.0358         1.27      0.00353\n",
            "     65   280      0.00199      0.00197     2.54e-05       0.0287       0.0381         1.56      0.00433\n",
            "     65   290      0.00204      0.00204     4.15e-06       0.0295       0.0388         0.63      0.00175\n",
            "     65   300       0.0021       0.0021     5.33e-06       0.0305       0.0393        0.714      0.00198\n",
            "     65   310      0.00189      0.00189     4.09e-06       0.0287       0.0373        0.626      0.00174\n",
            "     65   320      0.00215       0.0021     4.23e-05       0.0305       0.0394         2.01      0.00559\n",
            "     65   330      0.00251      0.00241      9.7e-05       0.0321       0.0422         3.04      0.00846\n",
            "     65   340      0.00249      0.00249     2.16e-06        0.033       0.0428        0.454      0.00126\n",
            "     65   350      0.00192      0.00192     4.43e-08       0.0285       0.0376        0.065     0.000181\n",
            "     65   360      0.00203      0.00199     4.15e-05       0.0294       0.0383         1.99      0.00554\n",
            "     65   370        0.002      0.00196     4.18e-05         0.03        0.038            2      0.00555\n",
            "     65   380      0.00197      0.00196     3.76e-06       0.0293        0.038          0.6      0.00167\n",
            "     65   390      0.00214      0.00214     2.02e-06         0.03       0.0397         0.44      0.00122\n",
            "     65   400      0.00204      0.00201      2.7e-05       0.0298       0.0385         1.61      0.00446\n",
            "     65   410      0.00227      0.00226     1.26e-06       0.0309       0.0409        0.347     0.000964\n",
            "     65   420      0.00192      0.00192     9.69e-07       0.0289       0.0376        0.304     0.000845\n",
            "     65   430        0.002        0.002     4.22e-08       0.0289       0.0384       0.0635     0.000176\n",
            "     65   440      0.00236      0.00236     2.47e-07       0.0318       0.0417        0.154     0.000426\n",
            "     65   450      0.00214      0.00204     9.43e-05       0.0295       0.0388            3      0.00834\n",
            "     65   460       0.0022      0.00202     0.000177       0.0296       0.0386         4.11       0.0114\n",
            "     65   470      0.00232      0.00211     0.000211       0.0295       0.0395         4.49       0.0125\n",
            "     65   480      0.00223      0.00221     1.92e-05       0.0302       0.0404         1.35      0.00376\n",
            "     65   490      0.00279      0.00261     0.000188       0.0331       0.0438         4.24       0.0118\n",
            "     65   500      0.00306      0.00296     9.89e-05       0.0341       0.0467         3.07      0.00854\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     65    10      0.00207      0.00206     4.91e-06       0.0298        0.039         0.56      0.00155\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              65 8530.834    0.004      0.00224     6.74e-05      0.00231       0.0309       0.0407         2.04      0.00565\n",
            "! Validation         65 8530.834    0.004      0.00196     7.84e-06      0.00197       0.0287        0.038        0.709      0.00197\n",
            "Wall time: 8530.834407549\n",
            "! Best model       65    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     66    10      0.00213      0.00208     4.94e-05       0.0298       0.0392         2.17      0.00603\n",
            "     66    20      0.00185      0.00181     3.19e-05       0.0285       0.0366         1.75      0.00485\n",
            "     66    30      0.00192      0.00185     7.57e-05       0.0279       0.0369         2.69      0.00747\n",
            "     66    40      0.00209      0.00199      9.7e-05       0.0295       0.0383         3.04      0.00846\n",
            "     66    50        0.002        0.002     4.49e-08       0.0292       0.0384       0.0655     0.000182\n",
            "     66    60      0.00295       0.0028     0.000148       0.0308       0.0454         3.76       0.0104\n",
            "     66    70      0.00216      0.00213     3.03e-05       0.0304       0.0397          1.7      0.00472\n",
            "     66    80      0.00173      0.00173     2.27e-06       0.0283       0.0357        0.465      0.00129\n",
            "     66    90      0.00221      0.00221     1.99e-06       0.0309       0.0404        0.436      0.00121\n",
            "     66   100      0.00226      0.00194     0.000317       0.0281       0.0378          5.5       0.0153\n",
            "     66   110      0.00223      0.00212     0.000114       0.0294       0.0395         3.31      0.00918\n",
            "     66   120      0.00196      0.00195     1.36e-05       0.0291       0.0379         1.14      0.00316\n",
            "     66   130      0.00225      0.00222     2.44e-05       0.0312       0.0405         1.53      0.00425\n",
            "     66   140      0.00249      0.00248     8.37e-06       0.0324       0.0428        0.894      0.00248\n",
            "     66   150      0.00287      0.00258     0.000294       0.0327       0.0436          5.3       0.0147\n",
            "     66   160      0.00288      0.00287     1.32e-05       0.0347        0.046         1.12      0.00312\n",
            "     66   170      0.00214      0.00201     0.000125       0.0295       0.0385         3.46      0.00962\n",
            "     66   180      0.00213      0.00213     2.33e-08       0.0304       0.0397       0.0472     0.000131\n",
            "     66   190      0.00229      0.00228     1.12e-05       0.0306        0.041         1.03      0.00287\n",
            "     66   200      0.00227      0.00219     8.09e-05       0.0314       0.0402         2.78      0.00772\n",
            "     66   210      0.00203      0.00202     7.58e-07       0.0296       0.0386        0.269     0.000748\n",
            "     66   220      0.00374      0.00348      0.00026       0.0378       0.0507         4.99       0.0138\n",
            "     66   230      0.00241       0.0021     0.000314       0.0303       0.0394         5.48       0.0152\n",
            "     66   240      0.00255      0.00255     4.67e-07       0.0324       0.0433        0.211     0.000587\n",
            "     66   250      0.00189      0.00184     5.66e-05       0.0285       0.0368         2.33      0.00646\n",
            "     66   260      0.00247      0.00243     4.39e-05       0.0313       0.0423         2.05      0.00569\n",
            "     66   270      0.00229      0.00221     7.87e-05       0.0306       0.0404         2.74      0.00762\n",
            "     66   280      0.00199      0.00191     7.66e-05       0.0281       0.0376         2.71      0.00752\n",
            "     66   290       0.0021       0.0021     4.63e-06       0.0296       0.0393        0.665      0.00185\n",
            "     66   300      0.00253      0.00246     6.98e-05       0.0318       0.0426         2.58      0.00717\n",
            "     66   310      0.00228       0.0022     7.99e-05       0.0306       0.0403         2.76      0.00768\n",
            "     66   320      0.00251      0.00246      5.2e-05       0.0316       0.0426         2.23      0.00619\n",
            "     66   330      0.00196      0.00195     1.32e-05       0.0291       0.0379         1.13      0.00313\n",
            "     66   340      0.00248      0.00246      1.8e-05       0.0326       0.0426         1.31      0.00364\n",
            "     66   350      0.00191      0.00187     3.57e-05       0.0282       0.0371         1.85      0.00513\n",
            "     66   360      0.00222      0.00221     1.04e-05       0.0308       0.0404        0.997      0.00277\n",
            "     66   370      0.00198      0.00197     7.77e-06       0.0291       0.0382        0.862      0.00239\n",
            "     66   380      0.00273      0.00261     0.000127       0.0336       0.0439         3.48      0.00968\n",
            "     66   390      0.00247       0.0024     6.67e-05        0.032       0.0421         2.53      0.00702\n",
            "     66   400      0.00314      0.00288     0.000263       0.0345       0.0461         5.01       0.0139\n",
            "     66   410      0.00286      0.00265     0.000208       0.0335       0.0442         4.46       0.0124\n",
            "     66   420      0.00192      0.00189     3.07e-05       0.0284       0.0373         1.71      0.00475\n",
            "     66   430      0.00215      0.00211      4.7e-05         0.03       0.0394         2.12      0.00589\n",
            "     66   440      0.00191      0.00191     7.71e-09        0.029       0.0375       0.0271     7.54e-05\n",
            "     66   450      0.00218      0.00187     0.000305       0.0282       0.0372          5.4        0.015\n",
            "     66   460      0.00255       0.0025     5.52e-05       0.0328       0.0429          2.3      0.00638\n",
            "     66   470      0.00217      0.00211     6.17e-05       0.0297       0.0395         2.43      0.00675\n",
            "     66   480      0.00199      0.00198     4.37e-06       0.0296       0.0382        0.647       0.0018\n",
            "     66   490       0.0021      0.00207     3.27e-05       0.0298        0.039         1.77      0.00491\n",
            "     66   500      0.00299      0.00297     2.18e-05        0.036       0.0468         1.44      0.00401\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     66    10      0.00204      0.00203     4.02e-06       0.0295       0.0387        0.453      0.00126\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              66 8661.953    0.004      0.00221     6.74e-05      0.00228       0.0306       0.0404         2.04      0.00567\n",
            "! Validation         66 8661.953    0.004      0.00195     7.59e-06      0.00196       0.0286       0.0379        0.655      0.00182\n",
            "Wall time: 8661.95347854\n",
            "! Best model       66    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     67    10      0.00229      0.00228      1.2e-05       0.0314        0.041         1.07      0.00297\n",
            "     67    20      0.00202      0.00201     5.61e-06       0.0293       0.0385        0.732      0.00203\n",
            "     67    30      0.00216      0.00216     1.01e-06       0.0306       0.0399        0.311     0.000864\n",
            "     67    40      0.00199      0.00199     1.14e-06       0.0294       0.0383         0.33     0.000916\n",
            "     67    50       0.0019       0.0019     1.66e-08       0.0291       0.0375       0.0398     0.000111\n",
            "     67    60      0.00218      0.00218     9.48e-07       0.0305       0.0401        0.301     0.000836\n",
            "     67    70       0.0022       0.0022     1.38e-07       0.0307       0.0403        0.115     0.000319\n",
            "     67    80       0.0025       0.0025     9.26e-07       0.0325       0.0429        0.297     0.000826\n",
            "     67    90      0.00183      0.00183     3.85e-06       0.0286       0.0367        0.607      0.00169\n",
            "     67   100      0.00294      0.00262     0.000326       0.0338       0.0439         5.58       0.0155\n",
            "     67   110      0.00224      0.00222     1.98e-05       0.0307       0.0404         1.38      0.00382\n",
            "     67   120      0.00192      0.00185     6.14e-05       0.0282        0.037         2.42      0.00673\n",
            "     67   130      0.00249      0.00232     0.000161       0.0318       0.0414         3.93       0.0109\n",
            "     67   140      0.00238      0.00232     6.47e-05       0.0319       0.0413         2.49      0.00691\n",
            "     67   150      0.00221      0.00217     3.82e-05       0.0301         0.04         1.91      0.00531\n",
            "     67   160      0.00251      0.00223     0.000282       0.0308       0.0406         5.19       0.0144\n",
            "     67   170      0.00266      0.00261     5.05e-05        0.033       0.0438          2.2       0.0061\n",
            "     67   180      0.00195      0.00194     1.15e-05       0.0292       0.0378         1.05      0.00291\n",
            "     67   190      0.00271      0.00242     0.000289       0.0323       0.0422         5.26       0.0146\n",
            "     67   200      0.00204      0.00203     1.57e-05       0.0294       0.0387         1.23      0.00341\n",
            "     67   210      0.00236      0.00232     4.45e-05       0.0319       0.0413         2.06      0.00573\n",
            "     67   220      0.00206      0.00205     1.62e-05       0.0299       0.0388         1.25      0.00346\n",
            "     67   230      0.00223      0.00223      8.4e-06       0.0307       0.0405        0.896      0.00249\n",
            "     67   240      0.00161      0.00159     1.62e-05       0.0261       0.0343         1.25      0.00346\n",
            "     67   250      0.00251      0.00227     0.000236       0.0308        0.041         4.75       0.0132\n",
            "     67   260      0.00241      0.00214     0.000274       0.0305       0.0397         5.12       0.0142\n",
            "     67   270      0.00281       0.0026     0.000215       0.0335       0.0438         4.53       0.0126\n",
            "     67   280      0.00222      0.00216     5.79e-05       0.0304       0.0399         2.35      0.00653\n",
            "     67   290      0.00214      0.00212     1.97e-05       0.0304       0.0396         1.37      0.00381\n",
            "     67   300      0.00368      0.00326     0.000425       0.0369        0.049         6.37       0.0177\n",
            "     67   310      0.00226      0.00222      4.4e-05        0.031       0.0404         2.05       0.0057\n",
            "     67   320      0.00203      0.00199     4.26e-05       0.0291       0.0383         2.02       0.0056\n",
            "     67   330      0.00226      0.00218     8.53e-05       0.0305       0.0401         2.85      0.00793\n",
            "     67   340      0.00256      0.00236       0.0002       0.0315       0.0417         4.38       0.0122\n",
            "     67   350      0.00259      0.00258     5.67e-06       0.0326       0.0436        0.736      0.00205\n",
            "     67   360      0.00305      0.00299     6.37e-05       0.0357       0.0469         2.47      0.00686\n",
            "     67   370      0.00233      0.00225      7.4e-05       0.0318       0.0408         2.66      0.00739\n",
            "     67   380      0.00271      0.00241     0.000302       0.0319       0.0421         5.37       0.0149\n",
            "     67   390      0.00206      0.00205     3.89e-06       0.0301       0.0389         0.61      0.00169\n",
            "     67   400      0.00165      0.00164     6.44e-06       0.0271       0.0348        0.785      0.00218\n",
            "     67   410      0.00253      0.00252     1.11e-05       0.0336       0.0431         1.03      0.00286\n",
            "     67   420      0.00244      0.00243     6.87e-06       0.0328       0.0423         0.81      0.00225\n",
            "     67   430      0.00209      0.00208     3.85e-06         0.03       0.0392        0.606      0.00168\n",
            "     67   440      0.00193      0.00192     1.62e-05       0.0288       0.0376         1.25      0.00346\n",
            "     67   450      0.00167      0.00167      2.4e-06       0.0272       0.0351        0.479      0.00133\n",
            "     67   460      0.00199      0.00191     8.66e-05        0.029       0.0375         2.88      0.00799\n",
            "     67   470      0.00217      0.00211     6.21e-05       0.0297       0.0394         2.44      0.00677\n",
            "     67   480      0.00238      0.00234     3.61e-05        0.032       0.0416         1.86      0.00516\n",
            "     67   490      0.00245      0.00218     0.000277       0.0306       0.0401         5.15       0.0143\n",
            "     67   500      0.00172      0.00168     3.82e-05       0.0272       0.0352         1.91      0.00531\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     67    10      0.00203      0.00202     4.09e-06       0.0295       0.0386        0.463      0.00129\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              67 8793.103    0.004      0.00222     7.92e-05       0.0023       0.0307       0.0405          2.2       0.0061\n",
            "! Validation         67 8793.103    0.004      0.00194     7.58e-06      0.00194       0.0285       0.0378        0.661      0.00184\n",
            "Wall time: 8793.103266221\n",
            "! Best model       67    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     68    10      0.00239      0.00233     5.72e-05       0.0321       0.0415         2.34      0.00649\n",
            "     68    20      0.00309      0.00295     0.000139       0.0347       0.0466         3.64       0.0101\n",
            "     68    30      0.00295      0.00295     1.59e-07       0.0345       0.0466        0.123     0.000342\n",
            "     68    40      0.00287      0.00283        4e-05       0.0343       0.0457         1.96      0.00543\n",
            "     68    50      0.00227      0.00222     4.99e-05       0.0312       0.0404         2.18      0.00606\n",
            "     68    60      0.00212      0.00211     9.31e-06       0.0303       0.0394        0.943      0.00262\n",
            "     68    70      0.00235      0.00235     1.23e-09       0.0321       0.0417       0.0109     3.02e-05\n",
            "     68    80      0.00209      0.00209     6.68e-06       0.0296       0.0392        0.799      0.00222\n",
            "     68    90      0.00332      0.00288     0.000438       0.0349       0.0461         6.47        0.018\n",
            "     68   100      0.00335      0.00277      0.00058       0.0354       0.0452         7.45       0.0207\n",
            "     68   110      0.00204      0.00172     0.000327       0.0272       0.0356         5.59       0.0155\n",
            "     68   120      0.00211       0.0021      3.1e-06         0.03       0.0394        0.544      0.00151\n",
            "     68   130      0.00187      0.00184     3.57e-05       0.0282       0.0368         1.85      0.00513\n",
            "     68   140      0.00205      0.00199     5.62e-05       0.0297       0.0383         2.32      0.00644\n",
            "     68   150      0.00215      0.00208     6.67e-05       0.0303       0.0392         2.53      0.00701\n",
            "     68   160      0.00167      0.00164     2.88e-05       0.0269       0.0348         1.66      0.00461\n",
            "     68   170      0.00268      0.00259     8.46e-05       0.0326       0.0437         2.84       0.0079\n",
            "     68   180      0.00199      0.00189     0.000101       0.0283       0.0373          3.1      0.00861\n",
            "     68   190      0.00164      0.00163      3.8e-06       0.0266       0.0347        0.603      0.00167\n",
            "     68   200      0.00211        0.002     0.000108       0.0293       0.0384         3.21      0.00892\n",
            "     68   210      0.00266      0.00266     8.68e-07       0.0333       0.0443        0.288       0.0008\n",
            "     68   220      0.00185      0.00184     9.31e-06       0.0283       0.0368        0.943      0.00262\n",
            "     68   230       0.0021      0.00195     0.000148       0.0292       0.0379         3.76       0.0105\n",
            "     68   240      0.00269      0.00246     0.000226       0.0323       0.0426         4.65       0.0129\n",
            "     68   250      0.00252      0.00252     3.39e-06       0.0318       0.0431        0.569      0.00158\n",
            "     68   260      0.00178      0.00175     2.17e-05       0.0286        0.036         1.44        0.004\n",
            "     68   270      0.00235      0.00228     7.36e-05       0.0305        0.041         2.65      0.00737\n",
            "     68   280      0.00199      0.00193     6.04e-05       0.0287       0.0377          2.4      0.00668\n",
            "     68   290      0.00263      0.00252     0.000116       0.0328       0.0431         3.33      0.00926\n",
            "     68   300      0.00192      0.00184     8.67e-05       0.0284       0.0368         2.88        0.008\n",
            "     68   310      0.00249      0.00238     0.000104       0.0319       0.0419         3.16      0.00877\n",
            "     68   320      0.00291      0.00212     0.000791       0.0284       0.0395         8.69       0.0241\n",
            "     68   330      0.00255      0.00248      6.4e-05       0.0332       0.0428         2.47      0.00687\n",
            "     68   340      0.00234      0.00227     6.31e-05       0.0311        0.041         2.46      0.00682\n",
            "     68   350      0.00202      0.00201     1.19e-05       0.0294       0.0385         1.06      0.00296\n",
            "     68   360      0.00194      0.00193     1.07e-05       0.0292       0.0377         1.01      0.00281\n",
            "     68   370      0.00199      0.00199     5.84e-07       0.0295       0.0383        0.236     0.000656\n",
            "     68   380      0.00247      0.00247     1.56e-06       0.0325       0.0427        0.387      0.00107\n",
            "     68   390      0.00246      0.00245      2.2e-06       0.0329       0.0425        0.458      0.00127\n",
            "     68   400      0.00267      0.00252     0.000154       0.0315       0.0431         3.83       0.0106\n",
            "     68   410      0.00226       0.0021     0.000165       0.0304       0.0393         3.97        0.011\n",
            "     68   420      0.00185      0.00181      3.9e-05       0.0274       0.0365         1.93      0.00536\n",
            "     68   430      0.00258      0.00247     0.000116       0.0323       0.0427         3.33      0.00924\n",
            "     68   440      0.00257      0.00257      4.5e-06       0.0332       0.0435        0.656      0.00182\n",
            "     68   450      0.00204      0.00204     1.39e-07       0.0294       0.0388        0.115      0.00032\n",
            "     68   460      0.00218      0.00216     1.43e-05       0.0299         0.04         1.17      0.00324\n",
            "     68   470      0.00203      0.00199     3.78e-05       0.0289       0.0383          1.9      0.00528\n",
            "     68   480      0.00195      0.00187     7.09e-05       0.0286       0.0372          2.6      0.00723\n",
            "     68   490      0.00266      0.00264      1.7e-05       0.0332       0.0442         1.27      0.00354\n",
            "     68   500      0.00254      0.00238     0.000165        0.032       0.0419         3.97        0.011\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     68    10      0.00202      0.00202     3.92e-06       0.0294       0.0386        0.437      0.00122\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              68 8924.168    0.004      0.00217     7.49e-05      0.00224       0.0303         0.04         2.07      0.00574\n",
            "! Validation         68 8924.168    0.004      0.00192     7.76e-06      0.00193       0.0284       0.0377        0.657      0.00182\n",
            "Wall time: 8924.168786617\n",
            "! Best model       68    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     69    10       0.0018       0.0018     6.01e-07       0.0283       0.0364         0.24     0.000666\n",
            "     69    20      0.00187      0.00183     4.05e-05       0.0283       0.0367         1.97      0.00547\n",
            "     69    30      0.00237      0.00229     8.08e-05       0.0312       0.0411         2.78      0.00772\n",
            "     69    40      0.00276      0.00272      3.8e-05       0.0341       0.0448         1.91       0.0053\n",
            "     69    50      0.00219      0.00218     9.49e-07       0.0304       0.0401        0.301     0.000837\n",
            "     69    60      0.00182      0.00182      3.9e-07        0.028       0.0366        0.193     0.000537\n",
            "     69    70      0.00268      0.00263     5.64e-05       0.0334        0.044         2.32      0.00645\n",
            "     69    80      0.00237      0.00236     6.83e-06        0.032       0.0417        0.808      0.00224\n",
            "     69    90      0.00271       0.0027     1.75e-05       0.0335       0.0446         1.29       0.0036\n",
            "     69   100      0.00203        0.002     2.46e-05       0.0296       0.0385         1.53      0.00426\n",
            "     69   110      0.00162      0.00162     1.29e-06       0.0267       0.0346        0.351     0.000974\n",
            "     69   120      0.00189      0.00182     6.19e-05       0.0275       0.0367         2.43      0.00675\n",
            "     69   130      0.00179      0.00179     1.06e-06       0.0278       0.0363        0.318     0.000885\n",
            "     69   140      0.00209      0.00207     1.67e-05       0.0295       0.0391         1.26      0.00351\n",
            "     69   150      0.00252      0.00243     8.93e-05       0.0326       0.0423         2.92      0.00811\n",
            "     69   160      0.00208      0.00208     8.73e-07       0.0299       0.0391        0.289     0.000802\n",
            "     69   170      0.00301      0.00301     2.49e-06       0.0355       0.0471        0.488      0.00135\n",
            "     69   180      0.00149      0.00149     2.55e-07       0.0256       0.0331        0.156     0.000433\n",
            "     69   190      0.00182      0.00179     2.92e-05        0.027       0.0364         1.67      0.00464\n",
            "     69   200       0.0023      0.00225     5.35e-05       0.0309       0.0407         2.26      0.00628\n",
            "     69   210      0.00178      0.00177     1.21e-05       0.0282       0.0362         1.08      0.00299\n",
            "     69   220      0.00337      0.00336     1.14e-05       0.0376       0.0498         1.05      0.00291\n",
            "     69   230      0.00213      0.00213     3.44e-08       0.0306       0.0396       0.0573     0.000159\n",
            "     69   240      0.00267      0.00265     2.13e-05       0.0334       0.0442         1.43      0.00396\n",
            "     69   250      0.00217      0.00217     4.17e-08       0.0308         0.04       0.0631     0.000175\n",
            "     69   260      0.00248      0.00245     2.71e-05       0.0314       0.0425         1.61      0.00447\n",
            "     69   270      0.00213      0.00204     8.66e-05       0.0301       0.0388         2.88      0.00799\n",
            "     69   280      0.00256      0.00251     4.81e-05       0.0332        0.043         2.14      0.00595\n",
            "     69   290      0.00269      0.00269     1.22e-06       0.0342       0.0445        0.341     0.000949\n",
            "     69   300       0.0024      0.00234     6.21e-05       0.0316       0.0415         2.44      0.00677\n",
            "     69   310      0.00253       0.0023     0.000229       0.0318       0.0412         4.68        0.013\n",
            "     69   320      0.00296      0.00292     4.25e-05       0.0349       0.0464         2.02       0.0056\n",
            "     69   330       0.0023      0.00229     1.06e-05       0.0316       0.0411         1.01      0.00279\n",
            "     69   340      0.00242      0.00233      9.5e-05       0.0318       0.0414         3.01      0.00837\n",
            "     69   350      0.00229      0.00228     1.68e-05       0.0309        0.041         1.27      0.00353\n",
            "     69   360      0.00264      0.00264     4.59e-09        0.034       0.0441       0.0209     5.82e-05\n",
            "     69   370       0.0021      0.00208     2.11e-05       0.0299       0.0392         1.42      0.00395\n",
            "     69   380      0.00207      0.00207     3.93e-07       0.0295       0.0391        0.194     0.000538\n",
            "     69   390      0.00241      0.00238     2.88e-05       0.0317       0.0419         1.66      0.00461\n",
            "     69   400      0.00256      0.00246     9.93e-05       0.0319       0.0426         3.08      0.00856\n",
            "     69   410      0.00208      0.00203     4.22e-05       0.0299       0.0387         2.01      0.00558\n",
            "     69   420       0.0023      0.00229     1.15e-05        0.031       0.0411         1.05      0.00291\n",
            "     69   430      0.00175      0.00171      4.1e-05       0.0273       0.0355         1.98       0.0055\n",
            "     69   440      0.00263      0.00262      3.3e-06       0.0336        0.044        0.561      0.00156\n",
            "     69   450      0.00195      0.00192     2.74e-05       0.0283       0.0377         1.62      0.00449\n",
            "     69   460      0.00248      0.00247     1.19e-05       0.0319       0.0427         1.07      0.00297\n",
            "     69   470      0.00267      0.00265     1.66e-05       0.0329       0.0442         1.26       0.0035\n",
            "     69   480      0.00285      0.00285     2.77e-06       0.0332       0.0458        0.514      0.00143\n",
            "     69   490      0.00232      0.00217     0.000144       0.0307         0.04         3.71       0.0103\n",
            "     69   500      0.00193      0.00187      5.7e-05       0.0282       0.0371         2.33      0.00648\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     69    10      0.00202      0.00202     4.16e-06       0.0294       0.0386        0.467       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              69 9055.303    0.004      0.00225     5.72e-05      0.00231        0.031       0.0407         1.84      0.00512\n",
            "! Validation         69 9055.303    0.004      0.00192     7.48e-06      0.00192       0.0283       0.0376        0.659      0.00183\n",
            "Wall time: 9055.303229674\n",
            "! Best model       69    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     70    10      0.00171      0.00171     9.24e-07       0.0274       0.0355        0.297     0.000826\n",
            "     70    20      0.00282      0.00282     2.33e-06        0.034       0.0456        0.472      0.00131\n",
            "     70    30      0.00219      0.00218     9.44e-06       0.0312       0.0401         0.95      0.00264\n",
            "     70    40      0.00273      0.00272     1.07e-05       0.0334       0.0448         1.01       0.0028\n",
            "     70    50      0.00255      0.00254     1.01e-05       0.0331       0.0433        0.984      0.00273\n",
            "     70    60      0.00248      0.00246     2.22e-05       0.0319       0.0426         1.46      0.00405\n",
            "     70    70      0.00321      0.00317     4.64e-05       0.0365       0.0483          2.1      0.00585\n",
            "     70    80      0.00199      0.00194     5.02e-05       0.0292       0.0378         2.19      0.00608\n",
            "     70    90      0.00179      0.00178     5.82e-06       0.0279       0.0363        0.746      0.00207\n",
            "     70   100      0.00194      0.00184     9.95e-05       0.0282       0.0369         3.08      0.00857\n",
            "     70   110      0.00235      0.00224     0.000111       0.0306       0.0406         3.26      0.00905\n",
            "     70   120      0.00213      0.00212     1.01e-05       0.0305       0.0396         0.98      0.00272\n",
            "     70   130      0.00309      0.00289     0.000195       0.0338       0.0462         4.31        0.012\n",
            "     70   140      0.00216      0.00215     6.55e-06       0.0304       0.0399        0.792       0.0022\n",
            "     70   150      0.00221      0.00219     2.24e-05       0.0299       0.0402         1.46      0.00407\n",
            "     70   160      0.00229      0.00216     0.000133       0.0306       0.0399         3.57      0.00992\n",
            "     70   170      0.00214      0.00211     2.94e-05         0.03       0.0394         1.68      0.00466\n",
            "     70   180      0.00223      0.00209     0.000137       0.0308       0.0393         3.62       0.0101\n",
            "     70   190      0.00204      0.00196     7.56e-05       0.0286        0.038         2.69      0.00747\n",
            "     70   200      0.00214      0.00211     3.09e-05       0.0301       0.0394         1.72      0.00477\n",
            "     70   210      0.00213      0.00207     5.51e-05       0.0302       0.0391         2.29      0.00637\n",
            "     70   220      0.00194      0.00184     0.000101        0.028       0.0368          3.1      0.00862\n",
            "     70   230      0.00225      0.00225     9.28e-07       0.0311       0.0407        0.298     0.000827\n",
            "     70   240      0.00181      0.00178     3.17e-05        0.028       0.0363         1.74      0.00484\n",
            "     70   250      0.00227      0.00224     2.93e-05       0.0307       0.0406         1.67      0.00465\n",
            "     70   260      0.00191      0.00191     2.06e-06        0.029       0.0375        0.443      0.00123\n",
            "     70   270      0.00295      0.00271     0.000238       0.0323       0.0447         4.77       0.0133\n",
            "     70   280       0.0016       0.0016     4.18e-07       0.0259       0.0343          0.2     0.000556\n",
            "     70   290      0.00298      0.00293     5.54e-05       0.0355       0.0465          2.3      0.00639\n",
            "     70   300      0.00216      0.00215     9.14e-06       0.0291       0.0398        0.935       0.0026\n",
            "     70   310      0.00195      0.00192     2.83e-05       0.0288       0.0377         1.65      0.00457\n",
            "     70   320      0.00316      0.00315     9.05e-06       0.0362       0.0482         0.93      0.00258\n",
            "     70   330      0.00199      0.00195     4.64e-05       0.0295       0.0379         2.11      0.00585\n",
            "     70   340      0.00205      0.00202     2.83e-05       0.0297       0.0386         1.64      0.00457\n",
            "     70   350      0.00204      0.00199     4.72e-05       0.0285       0.0383         2.12       0.0059\n",
            "     70   360      0.00233      0.00233     1.82e-08       0.0316       0.0415       0.0417     0.000116\n",
            "     70   370       0.0023       0.0023     9.48e-07        0.031       0.0412        0.301     0.000836\n",
            "     70   380      0.00274      0.00257     0.000163       0.0334       0.0436         3.95        0.011\n",
            "     70   390      0.00235      0.00198     0.000369       0.0296       0.0382         5.94       0.0165\n",
            "     70   400      0.00253      0.00249     3.51e-05        0.033       0.0429         1.83      0.00509\n",
            "     70   410      0.00169      0.00166     3.27e-05       0.0273        0.035         1.77      0.00491\n",
            "     70   420      0.00228      0.00228     2.98e-07       0.0314        0.041        0.169     0.000469\n",
            "     70   430      0.00197      0.00197     2.01e-08       0.0296       0.0381       0.0438     0.000122\n",
            "     70   440      0.00278      0.00277     1.07e-05       0.0347       0.0452         1.01      0.00281\n",
            "     70   450      0.00252      0.00252     9.23e-07       0.0331       0.0431        0.297     0.000825\n",
            "     70   460      0.00188      0.00188     4.06e-07       0.0287       0.0372        0.197     0.000547\n",
            "     70   470      0.00246      0.00244     1.92e-05       0.0328       0.0424         1.36      0.00377\n",
            "     70   480      0.00199      0.00196      3.5e-05        0.029        0.038         1.83      0.00508\n",
            "     70   490       0.0022      0.00212     7.92e-05         0.03       0.0395         2.75      0.00764\n",
            "     70   500      0.00253      0.00235     0.000175       0.0318       0.0417         4.09       0.0114\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     70    10        0.002      0.00199     4.16e-06       0.0292       0.0383        0.465      0.00129\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              70 9186.613    0.004      0.00218     5.33e-05      0.00223       0.0304       0.0401          1.8        0.005\n",
            "! Validation         70 9186.613    0.004       0.0019     7.53e-06      0.00191       0.0282       0.0375         0.66      0.00183\n",
            "Wall time: 9186.612900215\n",
            "! Best model       70    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     71    10      0.00213      0.00213     2.03e-06       0.0303       0.0396        0.441      0.00123\n",
            "     71    20      0.00195      0.00183     0.000118       0.0279       0.0367         3.36      0.00933\n",
            "     71    30      0.00179      0.00179     2.44e-06       0.0274       0.0363        0.483      0.00134\n",
            "     71    40      0.00171       0.0017     1.65e-05       0.0272       0.0354         1.26      0.00349\n",
            "     71    50      0.00198      0.00198     1.28e-06       0.0293       0.0382         0.35     0.000971\n",
            "     71    60      0.00207      0.00206     7.88e-06       0.0298        0.039        0.868      0.00241\n",
            "     71    70      0.00302      0.00285     0.000172       0.0342       0.0458         4.05       0.0113\n",
            "     71    80      0.00226       0.0022     5.74e-05       0.0312       0.0403         2.34      0.00651\n",
            "     71    90      0.00174      0.00173     1.43e-05       0.0274       0.0357         1.17      0.00324\n",
            "     71   100      0.00256      0.00242     0.000132       0.0315       0.0423         3.55      0.00987\n",
            "     71   110      0.00224      0.00222     1.35e-05       0.0306       0.0405         1.14      0.00316\n",
            "     71   120      0.00175      0.00174     1.01e-05       0.0277       0.0358        0.985      0.00274\n",
            "     71   130      0.00367      0.00367     6.76e-06       0.0378        0.052        0.804      0.00223\n",
            "     71   140      0.00221      0.00216     4.75e-05       0.0306       0.0399         2.13      0.00592\n",
            "     71   150      0.00205      0.00202     2.88e-05       0.0293       0.0386         1.66      0.00461\n",
            "     71   160      0.00176      0.00166     9.82e-05       0.0265        0.035         3.06      0.00851\n",
            "     71   170      0.00243      0.00242     1.17e-05       0.0316       0.0422         1.06      0.00294\n",
            "     71   180      0.00227      0.00225     2.85e-05       0.0307       0.0407         1.65      0.00459\n",
            "     71   190      0.00204      0.00177      0.00027       0.0268       0.0361         5.08       0.0141\n",
            "     71   200      0.00297      0.00294     3.38e-05       0.0341       0.0466          1.8        0.005\n",
            "     71   210       0.0029      0.00288      1.9e-05       0.0344       0.0461         1.35      0.00374\n",
            "     71   220      0.00286      0.00281     5.16e-05       0.0349       0.0455         2.22      0.00617\n",
            "     71   230       0.0035      0.00349     5.24e-06       0.0378       0.0508        0.708      0.00197\n",
            "     71   240      0.00235      0.00231     3.65e-05       0.0315       0.0413         1.87      0.00519\n",
            "     71   250      0.00233      0.00233      2.6e-06        0.031       0.0414        0.498      0.00138\n",
            "     71   260      0.00209      0.00196     0.000126       0.0288        0.038         3.48      0.00966\n",
            "     71   270      0.00264      0.00243     0.000212       0.0325       0.0423          4.5       0.0125\n",
            "     71   280      0.00197      0.00191     5.36e-05       0.0285       0.0376         2.26      0.00629\n",
            "     71   290      0.00265      0.00264     6.53e-06       0.0333       0.0441         0.79      0.00219\n",
            "     71   300      0.00262      0.00262     8.42e-06       0.0334       0.0439        0.897      0.00249\n",
            "     71   310      0.00174      0.00173     3.47e-06       0.0275       0.0358        0.576       0.0016\n",
            "     71   320      0.00201      0.00198     3.33e-05       0.0294       0.0382         1.78      0.00496\n",
            "     71   330      0.00258      0.00252     6.17e-05       0.0323       0.0431         2.43      0.00675\n",
            "     71   340      0.00262      0.00252     0.000106       0.0334       0.0431         3.18      0.00884\n",
            "     71   350      0.00155      0.00155     5.51e-06       0.0262       0.0338        0.726      0.00202\n",
            "     71   360      0.00203      0.00198     4.49e-05       0.0291       0.0382         2.07      0.00576\n",
            "     71   370      0.00204      0.00201     3.25e-05       0.0293       0.0385         1.76       0.0049\n",
            "     71   380      0.00215      0.00171     0.000443       0.0275       0.0355         6.51       0.0181\n",
            "     71   390      0.00331      0.00269      0.00062       0.0316       0.0445          7.7       0.0214\n",
            "     71   400      0.00247      0.00227     0.000202        0.031       0.0409         4.39       0.0122\n",
            "     71   410      0.00179      0.00171     8.09e-05       0.0276       0.0355         2.78      0.00772\n",
            "     71   420       0.0021      0.00207     3.33e-05       0.0302       0.0391         1.78      0.00496\n",
            "     71   430      0.00226      0.00201     0.000246       0.0297       0.0385         4.85       0.0135\n",
            "     71   440      0.00202      0.00201     1.43e-05       0.0292       0.0385         1.17      0.00325\n",
            "     71   450      0.00305      0.00302     2.55e-05       0.0359       0.0472         1.56      0.00433\n",
            "     71   460      0.00185      0.00183     2.16e-05       0.0279       0.0368         1.44      0.00399\n",
            "     71   470      0.00243      0.00242     8.66e-06        0.032       0.0422         0.91      0.00253\n",
            "     71   480      0.00277      0.00271     5.33e-05       0.0334       0.0447         2.26      0.00627\n",
            "     71   490      0.00223      0.00221     2.54e-05       0.0313       0.0403         1.56      0.00433\n",
            "     71   500      0.00262      0.00259     3.39e-05       0.0324       0.0437          1.8        0.005\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     71    10      0.00199      0.00198     4.35e-06       0.0292       0.0382        0.496      0.00138\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              71 9317.853    0.004      0.00214     6.39e-05       0.0022       0.0301       0.0397         1.95      0.00543\n",
            "! Validation         71 9317.853    0.004       0.0019      7.6e-06      0.00191       0.0282       0.0374        0.678      0.00188\n",
            "Wall time: 9317.853493908\n",
            "! Best model       71    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     72    10      0.00205      0.00203     1.69e-05       0.0301       0.0387         1.27      0.00353\n",
            "     72    20       0.0022      0.00207     0.000131       0.0297       0.0391         3.53      0.00981\n",
            "     72    30      0.00238      0.00235     2.96e-05       0.0325       0.0417         1.68      0.00467\n",
            "     72    40      0.00239       0.0023     9.03e-05       0.0313       0.0412         2.94      0.00816\n",
            "     72    50      0.00205      0.00191     0.000139       0.0286       0.0375         3.65       0.0101\n",
            "     72    60      0.00181      0.00176     4.53e-05       0.0277       0.0361         2.08      0.00578\n",
            "     72    70       0.0022      0.00213     7.05e-05       0.0302       0.0397          2.6      0.00721\n",
            "     72    80      0.00176      0.00175     9.27e-06       0.0275       0.0359        0.941      0.00261\n",
            "     72    90      0.00212       0.0021     2.66e-05       0.0296       0.0393         1.59      0.00443\n",
            "     72   100      0.00281      0.00281     9.27e-07       0.0338       0.0455        0.298     0.000827\n",
            "     72   110      0.00195      0.00195      1.9e-06       0.0289       0.0379        0.426      0.00118\n",
            "     72   120      0.00193      0.00193     1.11e-08       0.0289       0.0377       0.0325     9.04e-05\n",
            "     72   130      0.00194      0.00194     6.97e-06        0.029       0.0378        0.816      0.00227\n",
            "     72   140      0.00222      0.00222     7.93e-07       0.0311       0.0405        0.275     0.000765\n",
            "     72   150      0.00215      0.00211     3.49e-05       0.0288       0.0395         1.83      0.00507\n",
            "     72   160       0.0024      0.00222     0.000181       0.0313       0.0404         4.16       0.0116\n",
            "     72   170      0.00186      0.00185     1.61e-05       0.0278       0.0369         1.24      0.00345\n",
            "     72   180      0.00207      0.00205     1.57e-05       0.0299       0.0389         1.23       0.0034\n",
            "     72   190      0.00191      0.00191     2.05e-06       0.0288       0.0376        0.443      0.00123\n",
            "     72   200      0.00168      0.00162     6.32e-05        0.027       0.0345         2.46      0.00683\n",
            "     72   210       0.0021       0.0021     2.89e-07       0.0296       0.0394        0.166     0.000462\n",
            "     72   220      0.00212       0.0021     1.93e-05       0.0307       0.0394         1.36      0.00377\n",
            "     72   230       0.0019      0.00187     2.71e-05       0.0279       0.0371         1.61      0.00447\n",
            "     72   240      0.00223      0.00215     8.07e-05       0.0299       0.0398         2.78      0.00771\n",
            "     72   250      0.00192       0.0019      1.9e-05        0.028       0.0375         1.35      0.00375\n",
            "     72   260      0.00282      0.00282     3.21e-08       0.0348       0.0456       0.0554     0.000154\n",
            "     72   270      0.00307      0.00286     0.000203       0.0352        0.046         4.41       0.0122\n",
            "     72   280      0.00156      0.00151     4.99e-05       0.0262       0.0334         2.18      0.00607\n",
            "     72   290      0.00215      0.00214     1.25e-05       0.0295       0.0397         1.09      0.00303\n",
            "     72   300      0.00183      0.00183     9.65e-06       0.0279       0.0367        0.961      0.00267\n",
            "     72   310      0.00207      0.00206     1.17e-05       0.0301        0.039         1.06      0.00294\n",
            "     72   320      0.00245      0.00244     3.46e-06       0.0323       0.0425        0.575       0.0016\n",
            "     72   330      0.00236      0.00233     2.66e-05       0.0322       0.0415          1.6      0.00443\n",
            "     72   340      0.00189      0.00189     5.98e-07       0.0287       0.0374        0.239     0.000664\n",
            "     72   350      0.00208      0.00206     2.15e-05       0.0305        0.039         1.43      0.00398\n",
            "     72   360       0.0026      0.00259     1.27e-05       0.0329       0.0437          1.1      0.00307\n",
            "     72   370      0.00186      0.00178     8.34e-05        0.028       0.0362         2.82      0.00784\n",
            "     72   380      0.00188      0.00179     8.97e-05       0.0276       0.0364         2.93      0.00813\n",
            "     72   390      0.00253      0.00253     1.01e-07       0.0329       0.0432       0.0981     0.000273\n",
            "     72   400      0.00216      0.00215        5e-06       0.0302       0.0398        0.692      0.00192\n",
            "     72   410      0.00207      0.00204     2.53e-05       0.0304       0.0388         1.55      0.00432\n",
            "     72   420      0.00207      0.00206     1.29e-05       0.0306       0.0389         1.11      0.00309\n",
            "     72   430      0.00253      0.00253     2.54e-07       0.0325       0.0432        0.156     0.000433\n",
            "     72   440      0.00224      0.00223     1.13e-05       0.0308       0.0405         1.04      0.00289\n",
            "     72   450      0.00231      0.00226     4.62e-05       0.0311       0.0408          2.1      0.00584\n",
            "     72   460      0.00208      0.00192     0.000167       0.0289       0.0376            4       0.0111\n",
            "     72   470      0.00175      0.00174     7.99e-06       0.0271       0.0358        0.874      0.00243\n",
            "     72   480      0.00346      0.00345     5.23e-06        0.035       0.0505        0.707      0.00196\n",
            "     72   490      0.00217      0.00216     1.31e-05       0.0307       0.0399         1.12      0.00311\n",
            "     72   500      0.00195      0.00192     3.62e-05       0.0292       0.0376         1.86      0.00516\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     72    10      0.00197      0.00197     4.22e-06        0.029       0.0381        0.472      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              72 9449.443    0.004      0.00212     4.82e-05      0.00217         0.03       0.0396         1.77      0.00491\n",
            "! Validation         72 9449.443    0.004      0.00188     7.47e-06      0.00189       0.0281       0.0373         0.66      0.00183\n",
            "Wall time: 9449.443561615999\n",
            "! Best model       72    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     73    10      0.00173      0.00173     7.87e-07       0.0269       0.0358        0.274     0.000762\n",
            "     73    20      0.00185      0.00184     1.01e-05       0.0284       0.0369        0.983      0.00273\n",
            "     73    30      0.00194      0.00179     0.000144       0.0289       0.0364         3.71       0.0103\n",
            "     73    40      0.00258      0.00226     0.000317       0.0314       0.0408         5.51       0.0153\n",
            "     73    50      0.00242      0.00199     0.000436       0.0301       0.0383         6.46       0.0179\n",
            "     73    60      0.00239      0.00201     0.000386       0.0295       0.0385         6.07       0.0169\n",
            "     73    70      0.00219      0.00216     2.38e-05       0.0308       0.0399         1.51      0.00419\n",
            "     73    80      0.00201      0.00199     1.83e-05       0.0291       0.0383         1.32      0.00368\n",
            "     73    90      0.00205      0.00203     1.12e-05       0.0287       0.0387         1.03      0.00287\n",
            "     73   100      0.00181      0.00174     6.11e-05        0.028       0.0359         2.42      0.00671\n",
            "     73   110      0.00281      0.00278     2.21e-05       0.0347       0.0453         1.45      0.00404\n",
            "     73   120      0.00238      0.00238     3.14e-06       0.0323       0.0419        0.547      0.00152\n",
            "     73   130      0.00256      0.00251     5.09e-05       0.0329        0.043          2.2      0.00612\n",
            "     73   140       0.0021       0.0021     3.03e-06         0.03       0.0393        0.538      0.00149\n",
            "     73   150      0.00216      0.00216     2.84e-06       0.0306       0.0399        0.521      0.00145\n",
            "     73   160      0.00243      0.00237     5.54e-05       0.0294       0.0418          2.3      0.00639\n",
            "     73   170      0.00179      0.00167     0.000127       0.0268        0.035         3.49      0.00969\n",
            "     73   180       0.0027      0.00258     0.000124       0.0324       0.0436         3.45      0.00958\n",
            "     73   190      0.00211      0.00187     0.000241       0.0286       0.0371          4.8       0.0133\n",
            "     73   200      0.00221      0.00219     1.93e-05       0.0303       0.0402         1.36      0.00377\n",
            "     73   210      0.00212      0.00205     7.41e-05       0.0298       0.0388         2.66      0.00739\n",
            "     73   220      0.00267      0.00266     6.93e-06       0.0337       0.0443        0.814      0.00226\n",
            "     73   230      0.00181      0.00167     0.000135       0.0266       0.0351          3.6      0.00999\n",
            "     73   240      0.00213      0.00202     0.000104       0.0288       0.0386         3.15      0.00876\n",
            "     73   250      0.00215      0.00212     2.63e-05       0.0298       0.0396         1.59      0.00441\n",
            "     73   260      0.00278      0.00278     6.62e-07       0.0351       0.0453        0.252     0.000699\n",
            "     73   270      0.00195      0.00188     7.61e-05       0.0291       0.0372          2.7      0.00749\n",
            "     73   280      0.00275      0.00274     3.26e-06        0.033        0.045        0.558      0.00155\n",
            "     73   290      0.00196      0.00196      3.5e-07       0.0293        0.038        0.183     0.000508\n",
            "     73   300      0.00344      0.00344     2.67e-06       0.0379       0.0504        0.505       0.0014\n",
            "     73   310      0.00203      0.00192     0.000108        0.029       0.0376         3.22      0.00894\n",
            "     73   320      0.00257      0.00235     0.000228       0.0319       0.0416         4.67        0.013\n",
            "     73   330      0.00278      0.00278     6.57e-07       0.0354       0.0453        0.251     0.000696\n",
            "     73   340      0.00244      0.00244     1.82e-06        0.033       0.0424        0.417      0.00116\n",
            "     73   350      0.00206      0.00203     3.48e-05       0.0297       0.0386         1.82      0.00507\n",
            "     73   360      0.00254      0.00254     9.29e-07        0.034       0.0433        0.298     0.000828\n",
            "     73   370      0.00171      0.00168     3.06e-05       0.0276       0.0352         1.71      0.00475\n",
            "     73   380      0.00203      0.00201     1.37e-05       0.0293       0.0385         1.14      0.00318\n",
            "     73   390      0.00176      0.00173     3.49e-05        0.027       0.0357         1.83      0.00507\n",
            "     73   400      0.00306      0.00296       0.0001       0.0346       0.0468          3.1       0.0086\n",
            "     73   410      0.00206      0.00206     1.44e-08       0.0296        0.039       0.0371     0.000103\n",
            "     73   420      0.00216      0.00183     0.000339       0.0282       0.0367         5.69       0.0158\n",
            "     73   430      0.00207       0.0019     0.000164       0.0289       0.0375         3.96        0.011\n",
            "     73   440      0.00195      0.00186     9.12e-05       0.0276        0.037         2.95       0.0082\n",
            "     73   450      0.00258      0.00252     5.16e-05       0.0329       0.0431         2.22      0.00617\n",
            "     73   460      0.00253      0.00245     7.86e-05       0.0324       0.0425         2.74      0.00762\n",
            "     73   470      0.00338      0.00334     4.61e-05       0.0358       0.0496          2.1      0.00583\n",
            "     73   480      0.00193      0.00193     8.34e-08       0.0282       0.0377       0.0893     0.000248\n",
            "     73   490      0.00187      0.00182     4.57e-05       0.0276       0.0366         2.09       0.0058\n",
            "     73   500      0.00169      0.00165     4.46e-05       0.0269       0.0349         2.07      0.00574\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     73    10      0.00197      0.00197     4.13e-06       0.0291       0.0381        0.464      0.00129\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              73 9581.002    0.004       0.0022     6.59e-05      0.00227       0.0306       0.0403         2.03      0.00563\n",
            "! Validation         73 9581.002    0.004      0.00188     7.53e-06      0.00189        0.028       0.0373         0.66      0.00183\n",
            "Wall time: 9581.002138603\n",
            "! Best model       73    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     74    10      0.00177       0.0016     0.000169       0.0265       0.0344         4.02       0.0112\n",
            "     74    20      0.00215      0.00214     9.75e-06       0.0308       0.0397        0.965      0.00268\n",
            "     74    30      0.00188      0.00174     0.000147       0.0274       0.0358         3.75       0.0104\n",
            "     74    40      0.00227      0.00187       0.0004       0.0287       0.0372         6.18       0.0172\n",
            "     74    50      0.00299      0.00291     7.96e-05       0.0339       0.0463         2.76      0.00766\n",
            "     74    60       0.0022       0.0022     7.88e-06       0.0308       0.0402        0.868      0.00241\n",
            "     74    70      0.00163      0.00151     0.000121       0.0263       0.0334         3.41      0.00946\n",
            "     74    80      0.00175      0.00171      3.6e-05       0.0275       0.0355         1.86      0.00515\n",
            "     74    90      0.00279      0.00276     2.63e-05       0.0336       0.0451         1.59      0.00441\n",
            "     74   100      0.00316       0.0031     5.43e-05       0.0359       0.0478         2.28      0.00633\n",
            "     74   110      0.00205      0.00187     0.000177        0.029       0.0372         4.12       0.0114\n",
            "     74   120      0.00244       0.0024     3.09e-05       0.0316       0.0421         1.72      0.00478\n",
            "     74   130      0.00217      0.00196     0.000209       0.0292        0.038         4.47       0.0124\n",
            "     74   140      0.00214      0.00208     5.94e-05       0.0299       0.0392         2.38      0.00662\n",
            "     74   150      0.00191      0.00186     5.45e-05       0.0283        0.037         2.28      0.00634\n",
            "     74   160      0.00227      0.00216     0.000112       0.0294       0.0399         3.27      0.00908\n",
            "     74   170      0.00167      0.00163     3.85e-05       0.0265       0.0347         1.92      0.00533\n",
            "     74   180      0.00214      0.00209     4.92e-05       0.0298       0.0393         2.17      0.00602\n",
            "     74   190      0.00214      0.00202     0.000122       0.0297       0.0386         3.42      0.00949\n",
            "     74   200      0.00239      0.00211     0.000287       0.0303       0.0394         5.23       0.0145\n",
            "     74   210       0.0022      0.00219     1.04e-05        0.031       0.0402        0.996      0.00277\n",
            "     74   220      0.00232      0.00227     5.07e-05        0.031       0.0409          2.2      0.00612\n",
            "     74   230      0.00176      0.00169     6.94e-05       0.0273       0.0353         2.57      0.00715\n",
            "     74   240      0.00238      0.00237     5.06e-06       0.0313       0.0418        0.695      0.00193\n",
            "     74   250      0.00235      0.00232     2.79e-05        0.032       0.0414         1.63      0.00453\n",
            "     74   260      0.00171       0.0017     9.06e-06       0.0276       0.0354        0.931      0.00259\n",
            "     74   270      0.00241      0.00215     0.000259       0.0303       0.0399         4.97       0.0138\n",
            "     74   280       0.0019       0.0019     7.68e-07        0.029       0.0374        0.271     0.000753\n",
            "     74   290      0.00202        0.002     1.76e-05       0.0292       0.0384          1.3       0.0036\n",
            "     74   300      0.00198      0.00191     6.91e-05       0.0281       0.0376         2.57      0.00714\n",
            "     74   310      0.00201      0.00197     4.32e-05       0.0283       0.0381         2.03      0.00564\n",
            "     74   320      0.00254      0.00254     1.34e-06       0.0325       0.0433        0.358     0.000993\n",
            "     74   330      0.00173      0.00172      1.1e-05        0.027       0.0356         1.03      0.00285\n",
            "     74   340      0.00297      0.00283     0.000146       0.0362       0.0457         3.74       0.0104\n",
            "     74   350      0.00214      0.00206     7.61e-05       0.0302        0.039          2.7      0.00749\n",
            "     74   360       0.0023      0.00225     4.92e-05       0.0311       0.0407         2.17      0.00602\n",
            "     74   370       0.0018      0.00172     7.55e-05       0.0271       0.0357         2.69      0.00746\n",
            "     74   380      0.00171      0.00171     1.63e-06        0.027       0.0355        0.394       0.0011\n",
            "     74   390      0.00156      0.00153     2.55e-05       0.0251       0.0336         1.56      0.00433\n",
            "     74   400      0.00263      0.00244     0.000185       0.0322       0.0424         4.21       0.0117\n",
            "     74   410      0.00199      0.00195     3.99e-05       0.0293       0.0379         1.95      0.00543\n",
            "     74   420      0.00198      0.00198     8.19e-09       0.0291       0.0382        0.028     7.77e-05\n",
            "     74   430      0.00231      0.00228     3.03e-05       0.0313        0.041          1.7      0.00473\n",
            "     74   440      0.00226      0.00224     2.27e-05       0.0311       0.0406         1.47      0.00409\n",
            "     74   450      0.00277      0.00272     4.78e-05       0.0335       0.0448         2.14      0.00594\n",
            "     74   460      0.00199      0.00194     5.09e-05        0.029       0.0378          2.2      0.00612\n",
            "     74   470      0.00184       0.0018     4.16e-05       0.0278       0.0364         1.99      0.00554\n",
            "     74   480      0.00256      0.00243     0.000128       0.0324       0.0424          3.5      0.00973\n",
            "     74   490       0.0026      0.00259     1.05e-05       0.0344       0.0437            1      0.00278\n",
            "     74   500      0.00216      0.00213     3.04e-05       0.0295       0.0396          1.7      0.00474\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     74    10      0.00196      0.00196     4.27e-06        0.029        0.038        0.475      0.00132\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              74 9712.440    0.004      0.00213     7.28e-05       0.0022         0.03       0.0396         2.15      0.00597\n",
            "! Validation         74 9712.440    0.004      0.00187      7.5e-06      0.00188        0.028       0.0372        0.666      0.00185\n",
            "Wall time: 9712.439964838\n",
            "! Best model       74    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     75    10       0.0019      0.00187     2.59e-05       0.0285       0.0372         1.57      0.00437\n",
            "     75    20      0.00241       0.0024     1.33e-05       0.0322        0.042         1.13      0.00313\n",
            "     75    30      0.00247      0.00246     9.53e-06       0.0323       0.0426        0.954      0.00265\n",
            "     75    40      0.00237      0.00233     3.15e-05       0.0315       0.0415         1.73      0.00482\n",
            "     75    50      0.00156      0.00153     2.92e-05       0.0259       0.0336         1.67      0.00464\n",
            "     75    60      0.00243      0.00239     3.96e-05       0.0324        0.042         1.95      0.00541\n",
            "     75    70      0.00155      0.00155     9.37e-07       0.0265       0.0338        0.299     0.000831\n",
            "     75    80      0.00213      0.00203     9.96e-05       0.0293       0.0387         3.09      0.00857\n",
            "     75    90      0.00172      0.00166     5.93e-05       0.0269        0.035         2.38      0.00662\n",
            "     75   100      0.00229      0.00209     0.000199       0.0305       0.0393         4.36       0.0121\n",
            "     75   110      0.00201      0.00189     0.000115       0.0281       0.0374         3.31      0.00921\n",
            "     75   120      0.00171      0.00171     3.28e-08       0.0267       0.0356        0.056     0.000155\n",
            "     75   130      0.00246      0.00223     0.000226       0.0309       0.0406         4.64       0.0129\n",
            "     75   140      0.00196      0.00195     7.15e-06       0.0291        0.038        0.827       0.0023\n",
            "     75   150      0.00181      0.00181     4.99e-06       0.0281       0.0365        0.691      0.00192\n",
            "     75   160      0.00272      0.00272     7.46e-08       0.0331       0.0448       0.0844     0.000235\n",
            "     75   170       0.0024      0.00236     4.48e-05       0.0315       0.0417         2.07      0.00575\n",
            "     75   180      0.00196      0.00186     9.96e-05       0.0286        0.037         3.09      0.00857\n",
            "     75   190      0.00218      0.00217     4.63e-06       0.0292         0.04        0.665      0.00185\n",
            "     75   200      0.00199      0.00199     1.37e-06       0.0291       0.0383        0.362      0.00101\n",
            "     75   210      0.00205      0.00202     3.03e-05       0.0289       0.0386          1.7      0.00472\n",
            "     75   220      0.00223      0.00222     1.07e-05       0.0309       0.0405         1.01      0.00281\n",
            "     75   230      0.00278       0.0027     7.61e-05       0.0336       0.0447          2.7      0.00749\n",
            "     75   240      0.00155       0.0015     5.26e-05       0.0253       0.0333         2.24      0.00623\n",
            "     75   250      0.00209      0.00209     3.02e-07       0.0298       0.0393         0.17     0.000472\n",
            "     75   260      0.00206      0.00206     8.28e-07       0.0295        0.039        0.281     0.000782\n",
            "     75   270        0.002      0.00194     5.58e-05       0.0288       0.0379         2.31      0.00642\n",
            "     75   280      0.00165      0.00155     9.41e-05       0.0267       0.0338            3      0.00833\n",
            "     75   290      0.00217      0.00217     1.61e-06       0.0308         0.04        0.393      0.00109\n",
            "     75   300      0.00199      0.00199     8.98e-07       0.0286       0.0383        0.293     0.000814\n",
            "     75   310      0.00256      0.00255     1.13e-05       0.0332       0.0434         1.04      0.00289\n",
            "     75   320      0.00218      0.00216     2.02e-05       0.0306         0.04         1.39      0.00386\n",
            "     75   330      0.00157      0.00148     9.34e-05       0.0254        0.033         2.99       0.0083\n",
            "     75   340      0.00178      0.00157     0.000212       0.0265        0.034         4.51       0.0125\n",
            "     75   350       0.0019      0.00188     2.29e-05       0.0286       0.0372         1.48      0.00411\n",
            "     75   360      0.00208      0.00203     5.17e-05       0.0296       0.0386         2.22      0.00617\n",
            "     75   370      0.00271      0.00271     3.89e-06       0.0332       0.0447         0.61      0.00169\n",
            "     75   380      0.00179      0.00175     3.32e-05       0.0278        0.036         1.78      0.00495\n",
            "     75   390      0.00232      0.00228     4.05e-05       0.0311        0.041         1.97      0.00546\n",
            "     75   400       0.0028      0.00261     0.000185       0.0331       0.0439          4.2       0.0117\n",
            "     75   410      0.00205      0.00204     1.93e-05       0.0296       0.0387         1.36      0.00378\n",
            "     75   420      0.00237      0.00218     0.000188       0.0305       0.0401         4.24       0.0118\n",
            "     75   430       0.0017      0.00166     3.85e-05       0.0266        0.035         1.92      0.00533\n",
            "     75   440      0.00267      0.00266     7.36e-06       0.0343       0.0443        0.839      0.00233\n",
            "     75   450      0.00214      0.00199     0.000143         0.03       0.0383         3.69       0.0103\n",
            "     75   460      0.00163      0.00159     4.01e-05       0.0258       0.0343         1.96      0.00544\n",
            "     75   470      0.00191      0.00189     1.44e-05       0.0287       0.0374         1.17      0.00326\n",
            "     75   480        0.002      0.00197     2.69e-05       0.0288       0.0381          1.6      0.00445\n",
            "     75   490      0.00196      0.00193     3.42e-05        0.029       0.0377         1.81      0.00502\n",
            "     75   500      0.00194      0.00182     0.000117       0.0281       0.0366         3.35       0.0093\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     75    10      0.00195      0.00194     4.25e-06       0.0289       0.0379        0.478      0.00133\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              75 9843.867    0.004      0.00209     5.96e-05      0.00215       0.0297       0.0392         1.93      0.00537\n",
            "! Validation         75 9843.867    0.004      0.00186     7.56e-06      0.00187       0.0279        0.037        0.671      0.00186\n",
            "Wall time: 9843.867312068\n",
            "! Best model       75    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     76    10        0.002      0.00174     0.000251       0.0275       0.0359          4.9       0.0136\n",
            "     76    20      0.00193      0.00192     1.92e-05       0.0283       0.0376         1.35      0.00376\n",
            "     76    30      0.00233      0.00207     0.000259       0.0299       0.0391         4.98       0.0138\n",
            "     76    40      0.00189      0.00183     5.76e-05       0.0291       0.0368         2.35      0.00652\n",
            "     76    50       0.0019       0.0019      5.4e-06       0.0288       0.0374        0.719        0.002\n",
            "     76    60       0.0028       0.0028     2.22e-06       0.0343       0.0454         0.46      0.00128\n",
            "     76    70      0.00198      0.00193     5.73e-05       0.0285       0.0377         2.34       0.0065\n",
            "     76    80      0.00244      0.00236     8.43e-05       0.0316       0.0417         2.84      0.00788\n",
            "     76    90      0.00183      0.00181     1.78e-05        0.028       0.0365          1.3      0.00362\n",
            "     76   100      0.00245      0.00231      0.00014       0.0305       0.0413         3.66       0.0102\n",
            "     76   110      0.00197       0.0019     7.23e-05       0.0286       0.0374         2.63       0.0073\n",
            "     76   120      0.00202      0.00191     0.000106        0.029       0.0376         3.18      0.00883\n",
            "     76   130      0.00198      0.00195     3.55e-05        0.029       0.0379         1.84      0.00512\n",
            "     76   140      0.00232      0.00226     5.87e-05       0.0304       0.0408         2.37      0.00658\n",
            "     76   150       0.0028      0.00279     1.01e-05       0.0342       0.0454        0.984      0.00273\n",
            "     76   160       0.0015      0.00148     1.86e-05       0.0256       0.0331         1.33       0.0037\n",
            "     76   170      0.00177      0.00177     6.22e-08       0.0279       0.0361       0.0771     0.000214\n",
            "     76   180      0.00285      0.00284     5.61e-06       0.0345       0.0458        0.732      0.00203\n",
            "     76   190      0.00262      0.00257     4.64e-05       0.0342       0.0435         2.11      0.00585\n",
            "     76   200      0.00173      0.00169     3.72e-05       0.0267       0.0354         1.89      0.00524\n",
            "     76   210      0.00193      0.00189      3.4e-05       0.0291       0.0374          1.8      0.00501\n",
            "     76   220      0.00215       0.0019     0.000251       0.0293       0.0374          4.9       0.0136\n",
            "     76   230      0.00257      0.00239     0.000179       0.0318        0.042         4.13       0.0115\n",
            "     76   240      0.00284       0.0028     3.69e-05       0.0346       0.0455         1.88      0.00521\n",
            "     76   250      0.00203      0.00201     2.15e-05       0.0298       0.0385         1.43      0.00398\n",
            "     76   260      0.00198      0.00198     4.61e-06       0.0289       0.0382        0.664      0.00184\n",
            "     76   270      0.00196      0.00193     3.09e-05       0.0292       0.0377         1.72      0.00478\n",
            "     76   280       0.0021      0.00201      8.8e-05       0.0302       0.0385          2.9      0.00806\n",
            "     76   290      0.00171      0.00169     2.35e-05       0.0268       0.0353          1.5      0.00416\n",
            "     76   300      0.00253      0.00242     0.000112       0.0322       0.0422         3.27      0.00909\n",
            "     76   310      0.00284       0.0028     3.85e-05       0.0334       0.0455         1.92      0.00533\n",
            "     76   320      0.00289      0.00289     1.52e-06       0.0345       0.0462        0.382      0.00106\n",
            "     76   330      0.00205      0.00205     3.56e-06       0.0302       0.0389        0.584      0.00162\n",
            "     76   340      0.00226      0.00223     2.79e-05       0.0313       0.0406         1.63      0.00454\n",
            "     76   350      0.00188      0.00188     1.14e-06       0.0284       0.0372        0.331     0.000919\n",
            "     76   360      0.00247      0.00234     0.000126       0.0322       0.0416         3.47      0.00965\n",
            "     76   370       0.0017      0.00164     5.59e-05       0.0267       0.0348         2.31      0.00642\n",
            "     76   380      0.00217      0.00213     4.62e-05       0.0299       0.0396          2.1      0.00584\n",
            "     76   390      0.00199      0.00196     2.51e-05       0.0295       0.0381         1.55       0.0043\n",
            "     76   400      0.00326      0.00326     2.11e-07       0.0365        0.049        0.142     0.000394\n",
            "     76   410      0.00235      0.00233     2.12e-05       0.0309       0.0414         1.42      0.00395\n",
            "     76   420      0.00177      0.00173     4.44e-05       0.0272       0.0357         2.06      0.00573\n",
            "     76   430      0.00173      0.00172     1.13e-05       0.0277       0.0356         1.04      0.00289\n",
            "     76   440      0.00223      0.00198     0.000241       0.0292       0.0383          4.8       0.0133\n",
            "     76   450      0.00227       0.0019     0.000377       0.0285       0.0374            6       0.0167\n",
            "     76   460      0.00206      0.00205     4.88e-06       0.0295       0.0389        0.683       0.0019\n",
            "     76   470      0.00256      0.00216     0.000398       0.0298       0.0399         6.17       0.0171\n",
            "     76   480      0.00212      0.00211     3.25e-06       0.0305       0.0395        0.557      0.00155\n",
            "     76   490      0.00213      0.00191     0.000222       0.0284       0.0375         4.61       0.0128\n",
            "     76   500      0.00237      0.00236      1.2e-05       0.0319       0.0417         1.07      0.00298\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     76    10      0.00195      0.00195     4.16e-06       0.0289       0.0379        0.471      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              76 9975.143    0.004      0.00213     6.33e-05      0.00219       0.0301       0.0396         1.97      0.00548\n",
            "! Validation         76 9975.143    0.004      0.00186     7.49e-06      0.00186       0.0279        0.037        0.662      0.00184\n",
            "Wall time: 9975.143203157\n",
            "! Best model       76    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     77    10      0.00174      0.00174      1.7e-06       0.0282       0.0358        0.403      0.00112\n",
            "     77    20      0.00267      0.00266     8.92e-06       0.0327       0.0443        0.923      0.00256\n",
            "     77    30      0.00209      0.00204     4.96e-05         0.03       0.0388         2.18      0.00605\n",
            "     77    40       0.0016      0.00159     5.61e-06       0.0259       0.0342        0.733      0.00203\n",
            "     77    50      0.00268      0.00264     3.77e-05       0.0329       0.0441          1.9      0.00528\n",
            "     77    60      0.00181      0.00181     3.33e-06       0.0277       0.0365        0.564      0.00157\n",
            "     77    70      0.00201      0.00201     4.54e-08       0.0298       0.0385       0.0659     0.000183\n",
            "     77    80      0.00271      0.00254     0.000176       0.0333       0.0433          4.1       0.0114\n",
            "     77    90       0.0024       0.0022     0.000203       0.0307       0.0403          4.4       0.0122\n",
            "     77   100      0.00315      0.00311      4.1e-05       0.0358       0.0479         1.98       0.0055\n",
            "     77   110       0.0024       0.0023       0.0001       0.0311       0.0412         3.09      0.00859\n",
            "     77   120       0.0018       0.0018     2.71e-06       0.0279       0.0365        0.509      0.00141\n",
            "     77   130       0.0024      0.00239     1.26e-05       0.0317        0.042          1.1      0.00305\n",
            "     77   140      0.00238      0.00223     0.000147       0.0315       0.0406         3.75       0.0104\n",
            "     77   150      0.00291      0.00288     3.58e-05       0.0342       0.0461         1.85      0.00514\n",
            "     77   160      0.00234      0.00229     4.65e-05        0.031       0.0411         2.11      0.00586\n",
            "     77   170      0.00192      0.00185     6.89e-05       0.0281        0.037         2.57      0.00713\n",
            "     77   180      0.00197      0.00197     9.36e-07        0.029       0.0382        0.299     0.000831\n",
            "     77   190      0.00173       0.0016     0.000126        0.026       0.0344         3.47      0.00963\n",
            "     77   200      0.00144      0.00142     1.79e-05       0.0251       0.0323         1.31      0.00364\n",
            "     77   210       0.0022      0.00215     5.56e-05       0.0301       0.0398          2.3       0.0064\n",
            "     77   220      0.00158      0.00158     2.34e-08       0.0261       0.0341       0.0473     0.000131\n",
            "     77   230       0.0019      0.00188     1.69e-05       0.0286       0.0372         1.27      0.00353\n",
            "     77   240      0.00252      0.00247     5.51e-05       0.0318       0.0426          2.3      0.00638\n",
            "     77   250       0.0021      0.00208     1.85e-05       0.0303       0.0392         1.33       0.0037\n",
            "     77   260      0.00237      0.00229     7.99e-05       0.0313       0.0411         2.76      0.00767\n",
            "     77   270      0.00231      0.00229     1.74e-05       0.0313       0.0411         1.29      0.00359\n",
            "     77   280       0.0022      0.00216     3.83e-05       0.0303       0.0399         1.91      0.00532\n",
            "     77   290       0.0017      0.00169     1.18e-05       0.0272       0.0353         1.06      0.00295\n",
            "     77   300      0.00204      0.00203     2.87e-07       0.0289       0.0387        0.166      0.00046\n",
            "     77   310      0.00238      0.00238     3.68e-06       0.0322       0.0419        0.593      0.00165\n",
            "     77   320      0.00197      0.00197     2.58e-07       0.0295       0.0382        0.157     0.000436\n",
            "     77   330      0.00256      0.00256     1.58e-07       0.0333       0.0434        0.123     0.000342\n",
            "     77   340       0.0018      0.00172     7.78e-05       0.0275       0.0356         2.73      0.00758\n",
            "     77   350      0.00201        0.002     7.32e-06       0.0292       0.0384        0.836      0.00232\n",
            "     77   360      0.00176      0.00172     4.15e-05       0.0274       0.0356         1.99      0.00553\n",
            "     77   370      0.00264      0.00264     9.33e-08       0.0332       0.0442       0.0944     0.000262\n",
            "     77   380      0.00189      0.00187     1.78e-05       0.0283       0.0372          1.3      0.00362\n",
            "     77   390      0.00209      0.00188     0.000212       0.0281       0.0372         4.51       0.0125\n",
            "     77   400      0.00252      0.00239     0.000138       0.0318       0.0419         3.63       0.0101\n",
            "     77   410      0.00287      0.00271      0.00016       0.0336       0.0447         3.91       0.0109\n",
            "     77   420      0.00188      0.00188      2.5e-06       0.0278       0.0372        0.489      0.00136\n",
            "     77   430      0.00217      0.00217     3.51e-07       0.0298         0.04        0.183     0.000509\n",
            "     77   440      0.00191      0.00191     4.42e-08        0.029       0.0375        0.065     0.000181\n",
            "     77   450      0.00264      0.00261     3.54e-05       0.0322       0.0438         1.84      0.00511\n",
            "     77   460      0.00184      0.00184      3.5e-06       0.0273       0.0368        0.578      0.00161\n",
            "     77   470      0.00203      0.00199     3.86e-05       0.0296       0.0384         1.92      0.00533\n",
            "     77   480      0.00312      0.00308     3.93e-05       0.0319       0.0477         1.94      0.00538\n",
            "     77   490      0.00228      0.00198     0.000302       0.0294       0.0382         5.37       0.0149\n",
            "     77   500      0.00199       0.0018     0.000184       0.0281       0.0365         4.19       0.0116\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     77    10      0.00193      0.00193     4.17e-06       0.0287       0.0377        0.472      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              77 10106.354    0.004       0.0021     4.34e-05      0.00215       0.0299       0.0394         1.63      0.00452\n",
            "! Validation         77 10106.354    0.004      0.00184     7.54e-06      0.00185       0.0277       0.0369        0.666      0.00185\n",
            "Wall time: 10106.354349953\n",
            "! Best model       77    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     78    10      0.00211      0.00209     2.44e-05       0.0283       0.0393         1.53      0.00424\n",
            "     78    20      0.00214      0.00202     0.000114       0.0294       0.0386          3.3      0.00917\n",
            "     78    30      0.00191      0.00182     8.92e-05       0.0285       0.0367         2.92      0.00811\n",
            "     78    40      0.00217      0.00203     0.000139       0.0299       0.0387         3.64       0.0101\n",
            "     78    50      0.00181       0.0018     1.24e-05       0.0277       0.0364         1.09      0.00303\n",
            "     78    60      0.00293      0.00292     1.36e-05       0.0346       0.0464         1.14      0.00317\n",
            "     78    70      0.00173      0.00173     5.39e-06        0.027       0.0357        0.718      0.00199\n",
            "     78    80      0.00283      0.00281      2.1e-05        0.034       0.0456         1.42      0.00394\n",
            "     78    90      0.00157      0.00152     5.26e-05       0.0259       0.0335         2.24      0.00623\n",
            "     78   100      0.00223      0.00213     0.000103       0.0304       0.0396         3.14      0.00873\n",
            "     78   110      0.00176      0.00156     0.000199       0.0259       0.0339         4.37       0.0121\n",
            "     78   120      0.00154      0.00148     5.79e-05       0.0256       0.0331         2.35      0.00654\n",
            "     78   130      0.00198      0.00195     2.45e-05       0.0291       0.0379         1.53      0.00425\n",
            "     78   140      0.00175       0.0017      4.6e-05       0.0274       0.0354          2.1      0.00582\n",
            "     78   150      0.00171       0.0017     2.77e-06       0.0275       0.0355        0.515      0.00143\n",
            "     78   160      0.00231      0.00231     8.62e-07       0.0309       0.0413        0.287     0.000797\n",
            "     78   170      0.00207      0.00203     3.34e-05        0.029       0.0387         1.79      0.00496\n",
            "     78   180      0.00255      0.00255     3.24e-07       0.0321       0.0434        0.176     0.000489\n",
            "     78   190      0.00219      0.00219      1.2e-06       0.0306       0.0402        0.338      0.00094\n",
            "     78   200      0.00215      0.00201     0.000133       0.0295       0.0385         3.57      0.00991\n",
            "     78   210      0.00189      0.00186     2.57e-05       0.0285       0.0371         1.57      0.00435\n",
            "     78   220      0.00249      0.00249     3.02e-06       0.0324       0.0429        0.537      0.00149\n",
            "     78   230      0.00241      0.00241     3.01e-07        0.032       0.0422         0.17     0.000471\n",
            "     78   240      0.00251      0.00238     0.000126       0.0315       0.0419         3.47      0.00963\n",
            "     78   250      0.00206      0.00193      0.00013       0.0287       0.0377         3.52      0.00978\n",
            "     78   260      0.00195      0.00195     2.57e-06       0.0295       0.0379        0.496      0.00138\n",
            "     78   270      0.00192      0.00188     4.51e-05        0.029       0.0372         2.08      0.00577\n",
            "     78   280      0.00234      0.00233     5.86e-06       0.0317       0.0415        0.748      0.00208\n",
            "     78   290      0.00182      0.00175     6.32e-05       0.0277        0.036         2.46      0.00683\n",
            "     78   300      0.00263      0.00253     9.09e-05       0.0318       0.0432         2.95      0.00819\n",
            "     78   310      0.00201        0.002     9.43e-06       0.0302       0.0384         0.95      0.00264\n",
            "     78   320      0.00185      0.00159     0.000268       0.0265       0.0342         5.06       0.0141\n",
            "     78   330      0.00234      0.00231     3.25e-05       0.0313       0.0412         1.76       0.0049\n",
            "     78   340      0.00221      0.00218     2.59e-05       0.0307       0.0401         1.57      0.00437\n",
            "     78   350      0.00215      0.00215     3.34e-06       0.0305       0.0398        0.565      0.00157\n",
            "     78   360      0.00198      0.00194     3.97e-05       0.0293       0.0378         1.95      0.00541\n",
            "     78   370      0.00234      0.00229        5e-05       0.0315       0.0411         2.19      0.00607\n",
            "     78   380      0.00189      0.00171      0.00018       0.0273       0.0355         4.15       0.0115\n",
            "     78   390      0.00207      0.00196     0.000111       0.0293        0.038         3.26      0.00906\n",
            "     78   400      0.00314      0.00308     5.71e-05       0.0356       0.0477         2.34      0.00649\n",
            "     78   410      0.00295       0.0027     0.000246       0.0334       0.0447         4.84       0.0135\n",
            "     78   420      0.00229      0.00229     3.25e-06       0.0312       0.0411        0.557      0.00155\n",
            "     78   430      0.00195      0.00194     1.06e-05        0.029       0.0378         1.01       0.0028\n",
            "     78   440      0.00188      0.00186     1.93e-05       0.0281        0.037         1.36      0.00377\n",
            "     78   450      0.00257      0.00235     0.000213       0.0316       0.0417         4.51       0.0125\n",
            "     78   460      0.00193      0.00174      0.00019       0.0281       0.0358         4.26       0.0118\n",
            "     78   470      0.00204      0.00201     3.76e-05       0.0285       0.0385          1.9      0.00527\n",
            "     78   480      0.00229      0.00229     1.92e-06       0.0312       0.0411        0.428      0.00119\n",
            "     78   490      0.00175       0.0017        5e-05       0.0272       0.0354         2.19      0.00607\n",
            "     78   500      0.00197      0.00195     1.59e-05        0.029        0.038         1.23      0.00343\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     78    10      0.00192      0.00192     4.16e-06       0.0287       0.0376        0.468       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              78 10237.697    0.004      0.00206     5.52e-05      0.00211       0.0295       0.0389         1.86      0.00517\n",
            "! Validation         78 10237.697    0.004      0.00183     7.53e-06      0.00184       0.0277       0.0368        0.659      0.00183\n",
            "Wall time: 10237.697165203\n",
            "! Best model       78    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     79    10      0.00274      0.00264     0.000106       0.0338       0.0441         3.19      0.00886\n",
            "     79    20      0.00202      0.00202     5.34e-06       0.0296       0.0386        0.714      0.00198\n",
            "     79    30      0.00339      0.00297      0.00042       0.0349       0.0468         6.33       0.0176\n",
            "     79    40      0.00195      0.00177     0.000174       0.0286       0.0362         4.08       0.0113\n",
            "     79    50      0.00243      0.00243     1.23e-09       0.0313       0.0424       0.0109     3.02e-05\n",
            "     79    60      0.00186      0.00176      9.4e-05        0.028        0.036            3      0.00833\n",
            "     79    70       0.0021      0.00209      7.1e-06       0.0299       0.0393        0.824      0.00229\n",
            "     79    80      0.00189      0.00178      0.00011       0.0281       0.0362         3.24        0.009\n",
            "     79    90      0.00179      0.00168     0.000113       0.0269       0.0352         3.28      0.00911\n",
            "     79   100      0.00157      0.00155     1.55e-05       0.0261       0.0338         1.22      0.00338\n",
            "     79   110      0.00212      0.00212     1.38e-06       0.0304       0.0396        0.364      0.00101\n",
            "     79   120      0.00209      0.00208     2.89e-06         0.03       0.0392        0.526      0.00146\n",
            "     79   130      0.00196      0.00196      3.5e-06       0.0285        0.038        0.579      0.00161\n",
            "     79   140      0.00197      0.00181      0.00016       0.0278       0.0365         3.91       0.0109\n",
            "     79   150      0.00195      0.00194     8.86e-06       0.0283       0.0378         0.92      0.00256\n",
            "     79   160      0.00194      0.00193      6.2e-06       0.0291       0.0377         0.77      0.00214\n",
            "     79   170      0.00232      0.00231     1.39e-05       0.0323       0.0412         1.15       0.0032\n",
            "     79   180       0.0023      0.00227     2.57e-05        0.032       0.0409         1.57      0.00436\n",
            "     79   190      0.00171      0.00171     4.12e-07       0.0274       0.0355        0.198     0.000551\n",
            "     79   200      0.00213      0.00187     0.000267       0.0284       0.0371         5.05        0.014\n",
            "     79   210      0.00211       0.0021     1.16e-05       0.0307       0.0393         1.05      0.00293\n",
            "     79   220       0.0019      0.00189     6.73e-06       0.0287       0.0373        0.802      0.00223\n",
            "     79   230      0.00147      0.00147     3.66e-07       0.0258       0.0329        0.187     0.000519\n",
            "     79   240       0.0026      0.00258     2.37e-05       0.0329       0.0436         1.51      0.00418\n",
            "     79   250      0.00212      0.00194     0.000183       0.0287       0.0378         4.18       0.0116\n",
            "     79   260      0.00236      0.00209     0.000265        0.029       0.0393         5.04        0.014\n",
            "     79   270      0.00228      0.00221     7.63e-05       0.0316       0.0404          2.7       0.0075\n",
            "     79   280      0.00171      0.00171     8.17e-08       0.0265       0.0356       0.0884     0.000245\n",
            "     79   290       0.0016      0.00152      8.3e-05       0.0255       0.0335         2.82      0.00783\n",
            "     79   300      0.00213      0.00209      3.5e-05       0.0294       0.0393         1.83      0.00508\n",
            "     79   310      0.00158      0.00146     0.000117       0.0253       0.0328         3.35      0.00929\n",
            "     79   320       0.0028      0.00273     6.88e-05       0.0346       0.0449         2.56      0.00712\n",
            "     79   330      0.00203      0.00201     1.38e-05       0.0295       0.0385         1.15      0.00318\n",
            "     79   340      0.00191      0.00186     4.67e-05       0.0285        0.037         2.11      0.00587\n",
            "     79   350      0.00266      0.00264     1.39e-05       0.0336       0.0441         1.15       0.0032\n",
            "     79   360      0.00172      0.00167     5.15e-05        0.027       0.0351         2.22      0.00616\n",
            "     79   370       0.0019      0.00186     3.75e-05       0.0287        0.037         1.89      0.00526\n",
            "     79   380      0.00254      0.00251     2.73e-05       0.0329       0.0431         1.62      0.00449\n",
            "     79   390       0.0021      0.00205     4.72e-05       0.0299       0.0389         2.12       0.0059\n",
            "     79   400      0.00276      0.00274     2.29e-05       0.0334        0.045         1.48      0.00411\n",
            "     79   410      0.00179      0.00179     1.47e-08        0.028       0.0363       0.0375     0.000104\n",
            "     79   420      0.00157      0.00156     5.05e-06       0.0265       0.0339        0.695      0.00193\n",
            "     79   430      0.00162      0.00162     1.85e-06       0.0265       0.0346        0.421      0.00117\n",
            "     79   440      0.00167      0.00155     0.000117       0.0261       0.0338         3.35      0.00931\n",
            "     79   450      0.00176       0.0017     6.09e-05       0.0269       0.0354         2.41       0.0067\n",
            "     79   460       0.0025      0.00249      1.4e-06       0.0325       0.0429        0.365      0.00102\n",
            "     79   470      0.00151       0.0015     1.46e-05       0.0254       0.0332         1.18      0.00328\n",
            "     79   480      0.00199      0.00193     5.53e-05        0.029       0.0377          2.3      0.00639\n",
            "     79   490      0.00191      0.00189     2.74e-05       0.0288       0.0373         1.62      0.00449\n",
            "     79   500      0.00156      0.00154     2.16e-05       0.0254       0.0337         1.44      0.00399\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     79    10      0.00191      0.00191     4.38e-06       0.0286       0.0375         0.49      0.00136\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              79 10368.964    0.004      0.00207      5.7e-05      0.00212       0.0296        0.039         1.88      0.00522\n",
            "! Validation         79 10368.964    0.004      0.00183     7.61e-06      0.00183       0.0276       0.0367        0.676      0.00188\n",
            "Wall time: 10368.964467666\n",
            "! Best model       79    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     80    10      0.00201      0.00188     0.000131       0.0286       0.0373         3.54      0.00984\n",
            "     80    20      0.00171      0.00162     8.91e-05       0.0267       0.0346         2.92      0.00811\n",
            "     80    30      0.00194      0.00194     2.04e-08       0.0289       0.0378       0.0441     0.000123\n",
            "     80    40      0.00207      0.00203     4.11e-05       0.0293       0.0387         1.98       0.0055\n",
            "     80    50      0.00182      0.00181     1.21e-05       0.0281       0.0365         1.07      0.00298\n",
            "     80    60      0.00234      0.00234     2.58e-07       0.0316       0.0415        0.157     0.000436\n",
            "     80    70      0.00208      0.00202     6.02e-05       0.0299       0.0386          2.4      0.00666\n",
            "     80    80      0.00209      0.00154     0.000553       0.0259       0.0337         7.27       0.0202\n",
            "     80    90      0.00203      0.00201     1.81e-05       0.0305       0.0385         1.32      0.00366\n",
            "     80   100      0.00231      0.00196     0.000349       0.0292        0.038         5.78       0.0161\n",
            "     80   110      0.00301      0.00296     5.57e-05       0.0307       0.0467         2.31      0.00641\n",
            "     80   120       0.0017      0.00163     7.16e-05       0.0263       0.0347         2.62      0.00727\n",
            "     80   130      0.00206      0.00202     4.61e-05       0.0294       0.0386          2.1      0.00583\n",
            "     80   140      0.00139      0.00138        2e-06       0.0244       0.0319        0.437      0.00121\n",
            "     80   150       0.0036      0.00351      8.8e-05       0.0374       0.0509          2.9      0.00806\n",
            "     80   160      0.00191      0.00187     4.16e-05       0.0281       0.0372         1.99      0.00554\n",
            "     80   170      0.00171      0.00171     1.29e-07       0.0279       0.0355        0.111     0.000308\n",
            "     80   180       0.0021      0.00206     3.43e-05       0.0301        0.039         1.81      0.00503\n",
            "     80   190      0.00199       0.0019     9.19e-05       0.0285       0.0375         2.96      0.00823\n",
            "     80   200      0.00242      0.00242     1.19e-08       0.0318       0.0423       0.0337     9.36e-05\n",
            "     80   210      0.00192      0.00191     8.91e-06        0.028       0.0375        0.923      0.00256\n",
            "     80   220      0.00193      0.00187     6.23e-05       0.0292       0.0372         2.44      0.00678\n",
            "     80   230      0.00243      0.00242     3.98e-06       0.0324       0.0423        0.617      0.00171\n",
            "     80   240      0.00265      0.00262     2.97e-05       0.0337        0.044         1.69      0.00468\n",
            "     80   250      0.00301      0.00301     1.57e-06       0.0352       0.0471        0.387      0.00107\n",
            "     80   260      0.00203      0.00195     8.19e-05       0.0286       0.0379          2.8      0.00777\n",
            "     80   270       0.0023      0.00216     0.000139       0.0307       0.0399         3.65       0.0101\n",
            "     80   280      0.00201      0.00196     5.26e-05       0.0287        0.038         2.24      0.00623\n",
            "     80   290      0.00234      0.00234      1.6e-08       0.0319       0.0415       0.0391     0.000108\n",
            "     80   300      0.00211      0.00189     0.000219       0.0288       0.0374         4.58       0.0127\n",
            "     80   310      0.00252      0.00233     0.000195        0.031       0.0414         4.31        0.012\n",
            "     80   320      0.00215      0.00206     8.45e-05       0.0299        0.039         2.84      0.00789\n",
            "     80   330      0.00175      0.00175     1.18e-07       0.0277        0.036        0.106     0.000295\n",
            "     80   340       0.0019       0.0019     5.53e-06       0.0288       0.0374        0.727      0.00202\n",
            "     80   350      0.00299      0.00294     5.59e-05       0.0345       0.0465         2.31      0.00642\n",
            "     80   360       0.0018      0.00179     1.27e-05       0.0272       0.0364          1.1      0.00306\n",
            "     80   370       0.0019      0.00155      0.00035       0.0258       0.0338         5.78       0.0161\n",
            "     80   380      0.00291      0.00275     0.000164       0.0341        0.045         3.96        0.011\n",
            "     80   390      0.00159      0.00158     4.49e-06       0.0268       0.0342        0.655      0.00182\n",
            "     80   400      0.00171      0.00164     6.84e-05       0.0264       0.0348         2.56       0.0071\n",
            "     80   410      0.00197      0.00197     1.01e-06       0.0293       0.0381        0.311     0.000863\n",
            "     80   420       0.0018       0.0018     4.68e-07       0.0273       0.0365        0.212     0.000588\n",
            "     80   430      0.00165      0.00165     1.62e-06       0.0267       0.0349        0.393      0.00109\n",
            "     80   440      0.00142      0.00142     2.98e-08       0.0251       0.0324       0.0534     0.000148\n",
            "     80   450      0.00159      0.00158     8.55e-06       0.0265       0.0342        0.904      0.00251\n",
            "     80   460       0.0018      0.00154     0.000258       0.0259       0.0337         4.97       0.0138\n",
            "     80   470      0.00208      0.00208     3.04e-07       0.0295       0.0392        0.171     0.000474\n",
            "     80   480      0.00178      0.00178     1.11e-07        0.027       0.0363        0.103     0.000286\n",
            "     80   490      0.00189      0.00183     5.95e-05       0.0276       0.0367         2.39      0.00663\n",
            "     80   500      0.00243      0.00243     5.16e-07        0.032       0.0423        0.222     0.000617\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     80    10      0.00191      0.00191     4.26e-06       0.0286       0.0375        0.477      0.00133\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              80 10500.439    0.004      0.00205     6.28e-05      0.00212       0.0295       0.0389         1.91      0.00531\n",
            "! Validation         80 10500.439    0.004      0.00182     7.57e-06      0.00182       0.0275       0.0366        0.669      0.00186\n",
            "Wall time: 10500.439537527\n",
            "! Best model       80    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     81    10      0.00216      0.00216      8.7e-06       0.0284       0.0399        0.912      0.00253\n",
            "     81    20      0.00198      0.00196      2.1e-05       0.0292        0.038         1.42      0.00394\n",
            "     81    30      0.00187      0.00187     2.55e-06       0.0281       0.0371        0.494      0.00137\n",
            "     81    40      0.00226      0.00219     6.23e-05       0.0304       0.0402         2.44      0.00678\n",
            "     81    50      0.00181      0.00181     2.37e-06        0.028       0.0366        0.476      0.00132\n",
            "     81    60      0.00199      0.00191     8.84e-05        0.029       0.0375         2.91      0.00807\n",
            "     81    70      0.00246      0.00201     0.000455       0.0294       0.0385         6.59       0.0183\n",
            "     81    80      0.00165       0.0016     4.28e-05       0.0266       0.0344         2.02      0.00562\n",
            "     81    90      0.00207      0.00172     0.000344       0.0275       0.0357         5.74       0.0159\n",
            "     81   100      0.00256      0.00253     3.56e-05       0.0324       0.0432         1.84      0.00512\n",
            "     81   110       0.0027      0.00262     8.17e-05       0.0321        0.044          2.8      0.00776\n",
            "     81   120      0.00283       0.0027     0.000126       0.0334       0.0447         3.48      0.00965\n",
            "     81   130      0.00238      0.00237     7.66e-06       0.0318       0.0418        0.856      0.00238\n",
            "     81   140      0.00221      0.00212     8.83e-05       0.0293       0.0396          2.9      0.00807\n",
            "     81   150      0.00247      0.00233     0.000141       0.0312       0.0415         3.67       0.0102\n",
            "     81   160      0.00207      0.00207     2.03e-07       0.0299       0.0391        0.139     0.000387\n",
            "     81   170      0.00204      0.00204     4.95e-06       0.0292       0.0388        0.688      0.00191\n",
            "     81   180      0.00202      0.00195     7.22e-05       0.0284       0.0379         2.63       0.0073\n",
            "     81   190      0.00195      0.00195     4.69e-08       0.0293        0.038       0.0669     0.000186\n",
            "     81   200      0.00233      0.00218     0.000145       0.0308       0.0401         3.72       0.0103\n",
            "     81   210      0.00193      0.00192     1.29e-05       0.0294       0.0376         1.11      0.00309\n",
            "     81   220      0.00165      0.00164     1.67e-05       0.0267       0.0347         1.26      0.00351\n",
            "     81   230       0.0023       0.0023     4.41e-06       0.0316       0.0412        0.649       0.0018\n",
            "     81   240      0.00179      0.00173     5.34e-05       0.0281       0.0358         2.26      0.00627\n",
            "     81   250      0.00193      0.00192     1.53e-06       0.0285       0.0377        0.382      0.00106\n",
            "     81   260      0.00163      0.00163     9.92e-07       0.0268       0.0347        0.308     0.000856\n",
            "     81   270      0.00205      0.00205      7.6e-06       0.0289       0.0389        0.852      0.00237\n",
            "     81   280      0.00264      0.00223     0.000403        0.031       0.0406         6.21       0.0172\n",
            "     81   290       0.0018      0.00176     3.53e-05       0.0272       0.0361         1.84       0.0051\n",
            "     81   300       0.0024      0.00227     0.000123       0.0309       0.0409         3.43      0.00954\n",
            "     81   310      0.00266      0.00255     0.000107       0.0332       0.0434          3.2       0.0089\n",
            "     81   320      0.00233      0.00232     8.18e-06       0.0316       0.0414        0.884      0.00246\n",
            "     81   330      0.00209      0.00208     2.64e-06       0.0294       0.0392        0.502      0.00139\n",
            "     81   340      0.00172      0.00167     5.04e-05       0.0269       0.0351          2.2       0.0061\n",
            "     81   350      0.00226      0.00225     8.64e-06       0.0312       0.0407        0.909      0.00252\n",
            "     81   360      0.00217      0.00209     7.73e-05       0.0295       0.0392         2.72      0.00755\n",
            "     81   370      0.00268      0.00268     7.96e-06       0.0329       0.0444        0.872      0.00242\n",
            "     81   380      0.00185      0.00182     2.83e-05       0.0286       0.0366         1.64      0.00456\n",
            "     81   390       0.0022      0.00213     7.05e-05       0.0304       0.0397          2.6      0.00721\n",
            "     81   400      0.00222      0.00216     5.89e-05       0.0305       0.0399         2.37      0.00659\n",
            "     81   410      0.00239      0.00234     4.67e-05       0.0313       0.0416         2.11      0.00587\n",
            "     81   420       0.0018      0.00177     3.02e-05       0.0273       0.0361          1.7      0.00472\n",
            "     81   430      0.00218      0.00217     8.77e-06       0.0306         0.04        0.916      0.00254\n",
            "     81   440      0.00181      0.00179     1.49e-05       0.0277       0.0364         1.19      0.00332\n",
            "     81   450      0.00155      0.00154     6.48e-06       0.0259       0.0337        0.787      0.00219\n",
            "     81   460      0.00178      0.00178     1.29e-06       0.0277       0.0362        0.351     0.000976\n",
            "     81   470      0.00204      0.00202     1.89e-05       0.0295       0.0386         1.34      0.00373\n",
            "     81   480      0.00145      0.00145     5.99e-07       0.0249       0.0327        0.239     0.000665\n",
            "     81   490      0.00251      0.00213     0.000387       0.0298       0.0396         6.09       0.0169\n",
            "     81   500      0.00259      0.00252     7.76e-05       0.0334       0.0431         2.72      0.00756\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     81    10      0.00191       0.0019      4.2e-06       0.0285       0.0374        0.475      0.00132\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              81 10631.641    0.004      0.00203     5.93e-05      0.00209       0.0293       0.0387         1.89      0.00526\n",
            "! Validation         81 10631.641    0.004      0.00181     7.53e-06      0.00182       0.0275       0.0365        0.664      0.00184\n",
            "Wall time: 10631.641625174\n",
            "! Best model       81    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     82    10      0.00181       0.0018     8.93e-06       0.0275       0.0364        0.924      0.00257\n",
            "     82    20      0.00172      0.00171     1.05e-05       0.0275       0.0355            1      0.00278\n",
            "     82    30      0.00196      0.00196        2e-06       0.0288        0.038        0.438      0.00122\n",
            "     82    40      0.00266      0.00255     0.000107       0.0327       0.0434         3.19      0.00886\n",
            "     82    50      0.00274      0.00267     7.01e-05       0.0332       0.0444         2.59      0.00719\n",
            "     82    60      0.00197      0.00196     1.52e-05       0.0286        0.038         1.21      0.00335\n",
            "     82    70      0.00201      0.00181     0.000207       0.0278       0.0365         4.44       0.0123\n",
            "     82    80      0.00204      0.00184     0.000198       0.0287       0.0369         4.35       0.0121\n",
            "     82    90      0.00198      0.00195     3.24e-05       0.0294       0.0379         1.76      0.00489\n",
            "     82   100      0.00205      0.00204     4.89e-06       0.0296       0.0388        0.684       0.0019\n",
            "     82   110      0.00206        0.002     5.29e-05       0.0295       0.0384         2.25      0.00624\n",
            "     82   120      0.00197      0.00194     3.36e-05       0.0288       0.0378         1.79      0.00498\n",
            "     82   130      0.00198      0.00193        5e-05       0.0286       0.0377         2.19      0.00607\n",
            "     82   140      0.00259      0.00258     1.15e-05       0.0331       0.0436         1.05      0.00291\n",
            "     82   150      0.00192      0.00186     5.77e-05       0.0286       0.0371         2.35      0.00652\n",
            "     82   160      0.00149      0.00148     1.01e-05       0.0255        0.033        0.983      0.00273\n",
            "     82   170      0.00153      0.00152     1.14e-05       0.0255       0.0335         1.04       0.0029\n",
            "     82   180      0.00226      0.00224     1.31e-05       0.0307       0.0407         1.12      0.00311\n",
            "     82   190      0.00218      0.00218     2.34e-07       0.0305       0.0401         0.15     0.000415\n",
            "     82   200      0.00161       0.0016     6.03e-06       0.0265       0.0343        0.759      0.00211\n",
            "     82   210      0.00221      0.00219     1.61e-05       0.0313       0.0402         1.24      0.00345\n",
            "     82   220      0.00219      0.00214     5.27e-05       0.0311       0.0397         2.24      0.00623\n",
            "     82   230      0.00239      0.00238     8.29e-06       0.0325       0.0419         0.89      0.00247\n",
            "     82   240      0.00176      0.00155     0.000214       0.0262       0.0338         4.52       0.0125\n",
            "     82   250       0.0019      0.00171     0.000188       0.0276       0.0355         4.24       0.0118\n",
            "     82   260      0.00179      0.00179      6.3e-08       0.0277       0.0364       0.0776     0.000216\n",
            "     82   270      0.00283      0.00282     1.09e-05       0.0337       0.0456         1.02      0.00284\n",
            "     82   280      0.00229      0.00213     0.000165       0.0308       0.0396         3.97        0.011\n",
            "     82   290      0.00202      0.00191     0.000112       0.0288       0.0376         3.27      0.00908\n",
            "     82   300      0.00205      0.00187     0.000176       0.0281       0.0372          4.1       0.0114\n",
            "     82   310      0.00183      0.00183     2.92e-07       0.0279       0.0368        0.167     0.000464\n",
            "     82   320      0.00231      0.00221     9.07e-05       0.0301       0.0404         2.94      0.00818\n",
            "     82   330      0.00216      0.00216     1.67e-09       0.0302         0.04       0.0127     3.51e-05\n",
            "     82   340      0.00219      0.00207     0.000117       0.0306       0.0391         3.34      0.00929\n",
            "     82   350      0.00181      0.00181     2.95e-06       0.0277       0.0365        0.531      0.00148\n",
            "     82   360      0.00221      0.00219     1.91e-05       0.0302       0.0402         1.35      0.00375\n",
            "     82   370      0.00208      0.00206     1.09e-05       0.0293        0.039         1.02      0.00283\n",
            "     82   380      0.00222      0.00219     2.64e-05       0.0313       0.0402         1.59      0.00442\n",
            "     82   390      0.00214      0.00214     2.44e-06       0.0309       0.0397        0.483      0.00134\n",
            "     82   400      0.00187      0.00186     5.78e-06       0.0283       0.0371        0.744      0.00207\n",
            "     82   410      0.00198      0.00194     3.81e-05       0.0295       0.0378         1.91       0.0053\n",
            "     82   420       0.0025      0.00242     8.06e-05       0.0325       0.0422         2.78      0.00771\n",
            "     82   430      0.00289      0.00267     0.000222       0.0346       0.0444         4.61       0.0128\n",
            "     82   440      0.00247      0.00246     1.15e-05       0.0316       0.0426         1.05      0.00292\n",
            "     82   450      0.00234      0.00231     3.44e-05       0.0272       0.0413         1.81      0.00504\n",
            "     82   460      0.00188      0.00188      1.8e-06       0.0285       0.0373        0.414      0.00115\n",
            "     82   470      0.00208      0.00207     1.05e-05       0.0301       0.0391            1      0.00278\n",
            "     82   480      0.00217      0.00216     1.62e-05        0.031       0.0399         1.25      0.00346\n",
            "     82   490      0.00212      0.00207     5.12e-05       0.0294        0.039         2.21      0.00614\n",
            "     82   500      0.00236      0.00215     0.000213       0.0298       0.0398         4.51       0.0125\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     82    10       0.0019      0.00189     4.17e-06       0.0284       0.0374        0.472      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              82 10762.958    0.004      0.00207     4.78e-05      0.00212       0.0296       0.0391          1.7      0.00472\n",
            "! Validation         82 10762.958    0.004      0.00181     7.61e-06      0.00181       0.0274       0.0365        0.672      0.00187\n",
            "Wall time: 10762.958085741\n",
            "! Best model       82    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     83    10      0.00206      0.00201     4.77e-05       0.0294       0.0385         2.14      0.00593\n",
            "     83    20      0.00186      0.00184     1.54e-05       0.0282       0.0369         1.21      0.00337\n",
            "     83    30      0.00193      0.00186     7.02e-05       0.0295        0.037         2.59       0.0072\n",
            "     83    40      0.00222      0.00219      3.3e-05       0.0299       0.0402         1.78      0.00494\n",
            "     83    50      0.00262      0.00236     0.000259       0.0321       0.0417         4.98       0.0138\n",
            "     83    60      0.00179       0.0017     9.27e-05       0.0273       0.0354         2.98      0.00827\n",
            "     83    70      0.00253      0.00243     9.72e-05       0.0316       0.0424         3.05      0.00847\n",
            "     83    80      0.00201      0.00198     3.08e-05       0.0298       0.0382         1.71      0.00476\n",
            "     83    90      0.00231      0.00201     0.000301       0.0285       0.0385         5.37       0.0149\n",
            "     83   100      0.00187      0.00187     1.38e-07       0.0284       0.0371        0.115     0.000319\n",
            "     83   110      0.00186      0.00176     9.92e-05       0.0283        0.036         3.08      0.00856\n",
            "     83   120      0.00198      0.00189     8.69e-05        0.028       0.0374         2.88      0.00801\n",
            "     83   130      0.00182      0.00182     1.09e-06       0.0284       0.0366        0.322     0.000896\n",
            "     83   140      0.00164      0.00164     4.21e-06       0.0264       0.0348        0.634      0.00176\n",
            "     83   150      0.00222      0.00221     7.42e-06       0.0305       0.0404        0.842      0.00234\n",
            "     83   160      0.00187      0.00177     9.91e-05       0.0279       0.0361         3.08      0.00855\n",
            "     83   170      0.00184      0.00183     2.94e-06       0.0284       0.0368         0.53      0.00147\n",
            "     83   180      0.00243       0.0024     2.73e-05       0.0319       0.0421         1.61      0.00448\n",
            "     83   190      0.00154      0.00152      1.3e-05       0.0259       0.0335         1.11       0.0031\n",
            "     83   200      0.00183      0.00159     0.000236       0.0256       0.0343         4.75       0.0132\n",
            "     83   210       0.0031      0.00306     3.74e-05       0.0341       0.0475         1.89      0.00525\n",
            "     83   220      0.00158      0.00155     2.69e-05       0.0264       0.0338          1.6      0.00445\n",
            "     83   230      0.00194      0.00187     6.36e-05       0.0282       0.0372         2.46      0.00685\n",
            "     83   240      0.00193      0.00188     5.15e-05       0.0283       0.0372         2.22      0.00616\n",
            "     83   250      0.00295      0.00291     4.03e-05       0.0338       0.0463         1.96      0.00545\n",
            "     83   260      0.00211      0.00203     8.87e-05       0.0298       0.0386         2.91      0.00809\n",
            "     83   270      0.00213      0.00213      7.1e-06       0.0306       0.0396        0.824      0.00229\n",
            "     83   280      0.00224      0.00223     1.24e-05       0.0302       0.0406         1.09      0.00302\n",
            "     83   290      0.00209      0.00188     0.000204       0.0282       0.0373         4.42       0.0123\n",
            "     83   300       0.0018      0.00176     3.99e-05       0.0278        0.036         1.95      0.00542\n",
            "     83   310      0.00382      0.00375     7.67e-05        0.039       0.0526         2.71      0.00752\n",
            "     83   320      0.00131      0.00127     3.92e-05       0.0237       0.0306         1.93      0.00537\n",
            "     83   330      0.00184      0.00174     9.41e-05       0.0278       0.0359            3      0.00833\n",
            "     83   340      0.00193      0.00191     2.01e-05       0.0293       0.0375         1.39      0.00385\n",
            "     83   350       0.0019      0.00187     3.61e-05        0.028       0.0371         1.86      0.00516\n",
            "     83   360      0.00212      0.00204     8.79e-05       0.0295       0.0387          2.9      0.00805\n",
            "     83   370       0.0019      0.00181     8.93e-05       0.0281       0.0366         2.92      0.00812\n",
            "     83   380      0.00225      0.00222     3.01e-05       0.0309       0.0405          1.7      0.00471\n",
            "     83   390      0.00221      0.00206     0.000151        0.029       0.0389         3.81       0.0106\n",
            "     83   400      0.00181      0.00176     4.63e-05       0.0281        0.036          2.1      0.00584\n",
            "     83   410      0.00239      0.00239     2.73e-09       0.0311        0.042       0.0162     4.49e-05\n",
            "     83   420      0.00214      0.00214     2.46e-06       0.0304       0.0397        0.485      0.00135\n",
            "     83   430      0.00197      0.00196     9.02e-06       0.0293        0.038        0.928      0.00258\n",
            "     83   440      0.00236      0.00234     2.06e-05       0.0314       0.0415          1.4       0.0039\n",
            "     83   450      0.00197      0.00182     0.000144       0.0282       0.0367         3.71       0.0103\n",
            "     83   460        0.002        0.002     1.38e-06        0.029       0.0384        0.363      0.00101\n",
            "     83   470      0.00203      0.00195      7.1e-05        0.029        0.038          2.6      0.00723\n",
            "     83   480      0.00161       0.0016     9.83e-06       0.0266       0.0344         0.97      0.00269\n",
            "     83   490      0.00238      0.00237     6.64e-06       0.0321       0.0418        0.797      0.00221\n",
            "     83   500      0.00234      0.00233     7.28e-06       0.0313       0.0414        0.834      0.00232\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     83    10      0.00188      0.00187     4.51e-06       0.0283       0.0372         0.51      0.00142\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              83 10894.288    0.004      0.00201     6.81e-05      0.00208       0.0292       0.0385          2.1      0.00584\n",
            "! Validation         83 10894.288    0.004       0.0018     7.67e-06       0.0018       0.0274       0.0364        0.686      0.00191\n",
            "Wall time: 10894.288871138\n",
            "! Best model       83    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     84    10      0.00161      0.00157     4.02e-05       0.0267       0.0341         1.96      0.00544\n",
            "     84    20       0.0021      0.00208     2.66e-05       0.0298       0.0391         1.59      0.00443\n",
            "     84    30      0.00181      0.00172     8.52e-05       0.0264       0.0356         2.85      0.00793\n",
            "     84    40      0.00156      0.00153     2.98e-05        0.026       0.0336         1.69      0.00469\n",
            "     84    50      0.00179      0.00161     0.000176        0.026       0.0345          4.1       0.0114\n",
            "     84    60      0.00233      0.00232     1.38e-05       0.0312       0.0413         1.15       0.0032\n",
            "     84    70      0.00215      0.00215     1.13e-07       0.0293       0.0398        0.104     0.000288\n",
            "     84    80      0.00144      0.00143     9.36e-06       0.0251       0.0325        0.946      0.00263\n",
            "     84    90      0.00177      0.00176     1.15e-05       0.0273        0.036         1.05      0.00292\n",
            "     84   100      0.00165      0.00156     8.66e-05       0.0252        0.034         2.88      0.00799\n",
            "     84   110      0.00186      0.00184     1.25e-05       0.0282       0.0369         1.09      0.00303\n",
            "     84   120      0.00228      0.00227     1.47e-05       0.0318       0.0409         1.19      0.00329\n",
            "     84   130      0.00248      0.00239     9.34e-05       0.0313        0.042         2.99       0.0083\n",
            "     84   140      0.00186      0.00182     3.34e-05       0.0275       0.0367         1.79      0.00496\n",
            "     84   150      0.00206      0.00197     8.33e-05       0.0286       0.0382         2.82      0.00784\n",
            "     84   160      0.00208      0.00208     4.35e-09       0.0292       0.0392       0.0204     5.66e-05\n",
            "     84   170       0.0025      0.00238     0.000121       0.0321       0.0419          3.4      0.00944\n",
            "     84   180      0.00242      0.00241     1.52e-05       0.0313       0.0422          1.2      0.00334\n",
            "     84   190      0.00183      0.00183      4.5e-06       0.0276       0.0367        0.656      0.00182\n",
            "     84   200       0.0017      0.00148      0.00022        0.026       0.0331         4.58       0.0127\n",
            "     84   210      0.00264      0.00259      4.6e-05       0.0334       0.0437          2.1      0.00583\n",
            "     84   220      0.00286      0.00285     8.42e-06       0.0345       0.0458        0.897      0.00249\n",
            "     84   230      0.00185      0.00184     6.44e-06       0.0275       0.0369        0.784      0.00218\n",
            "     84   240      0.00235      0.00215     0.000201        0.031       0.0398         4.38       0.0122\n",
            "     84   250      0.00178      0.00167     0.000114       0.0273       0.0351          3.3      0.00916\n",
            "     84   260      0.00205       0.0019     0.000151       0.0288       0.0374         3.79       0.0105\n",
            "     84   270      0.00261      0.00252     8.23e-05       0.0331       0.0431          2.8      0.00779\n",
            "     84   280      0.00163      0.00162     7.09e-06       0.0265       0.0346        0.824      0.00229\n",
            "     84   290      0.00226      0.00226     2.36e-06       0.0294       0.0408        0.475      0.00132\n",
            "     84   300      0.00175      0.00174     5.22e-06       0.0275       0.0358        0.707      0.00196\n",
            "     84   310      0.00203      0.00203     6.88e-07       0.0299       0.0387        0.256     0.000712\n",
            "     84   320      0.00201      0.00182     0.000187       0.0275       0.0366         4.23       0.0118\n",
            "     84   330      0.00175      0.00175     1.07e-06        0.028       0.0359         0.32     0.000889\n",
            "     84   340      0.00141      0.00141     1.46e-07       0.0249       0.0322        0.118     0.000329\n",
            "     84   350       0.0022      0.00217      3.3e-05       0.0305         0.04         1.78      0.00493\n",
            "     84   360      0.00286       0.0023     0.000559       0.0314       0.0412         7.31       0.0203\n",
            "     84   370      0.00225      0.00196     0.000292       0.0298        0.038         5.28       0.0147\n",
            "     84   380      0.00157      0.00152     4.88e-05        0.026       0.0335         2.16        0.006\n",
            "     84   390       0.0018      0.00172     8.63e-05       0.0277       0.0356         2.87      0.00798\n",
            "     84   400      0.00207      0.00206     9.01e-06       0.0303        0.039        0.928      0.00258\n",
            "     84   410      0.00249      0.00231     0.000184       0.0314       0.0413         4.19       0.0116\n",
            "     84   420      0.00238      0.00238     8.37e-08       0.0301       0.0419       0.0894     0.000248\n",
            "     84   430      0.00163      0.00161      2.2e-05       0.0267       0.0344         1.45      0.00403\n",
            "     84   440      0.00298      0.00293     4.53e-05       0.0344       0.0465         2.08      0.00578\n",
            "     84   450      0.00223      0.00216     6.75e-05       0.0295       0.0399         2.54      0.00706\n",
            "     84   460      0.00231      0.00228     3.52e-05       0.0311        0.041         1.83       0.0051\n",
            "     84   470      0.00253      0.00244     9.21e-05        0.032       0.0424         2.97      0.00824\n",
            "     84   480       0.0019      0.00182     7.44e-05       0.0283       0.0367         2.67      0.00741\n",
            "     84   490      0.00221      0.00219     1.26e-05       0.0314       0.0402          1.1      0.00305\n",
            "     84   500      0.00151      0.00148     2.58e-05       0.0248       0.0331         1.57      0.00436\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     84    10      0.00188      0.00188     4.09e-06       0.0283       0.0372        0.467       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              84 11025.480    0.004      0.00198     6.42e-05      0.00204        0.029       0.0382         1.97      0.00548\n",
            "! Validation         84 11025.480    0.004      0.00179     7.49e-06       0.0018       0.0273       0.0363        0.658      0.00183\n",
            "Wall time: 11025.480160292\n",
            "! Best model       84    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     85    10      0.00199      0.00199     2.82e-07       0.0294       0.0383        0.164     0.000456\n",
            "     85    20      0.00265      0.00265     3.52e-06       0.0321       0.0442         0.58      0.00161\n",
            "     85    30        0.002        0.002     7.19e-07       0.0292       0.0384        0.262     0.000728\n",
            "     85    40      0.00217      0.00217     2.94e-06       0.0297         0.04         0.53      0.00147\n",
            "     85    50      0.00198      0.00175     0.000237       0.0273       0.0359         4.76       0.0132\n",
            "     85    60      0.00152      0.00152     1.77e-07       0.0257       0.0335         0.13     0.000361\n",
            "     85    70      0.00185      0.00182     2.54e-05       0.0279       0.0367         1.56      0.00432\n",
            "     85    80      0.00158      0.00156     2.67e-05       0.0261       0.0339          1.6      0.00444\n",
            "     85    90      0.00187      0.00184     2.98e-05       0.0284       0.0369         1.69      0.00469\n",
            "     85   100      0.00229       0.0022     8.52e-05       0.0306       0.0403         2.85      0.00793\n",
            "     85   110      0.00274      0.00274     3.78e-06       0.0334       0.0449        0.601      0.00167\n",
            "     85   120      0.00246      0.00241     4.71e-05       0.0315       0.0422         2.12      0.00589\n",
            "     85   130      0.00291      0.00288     2.72e-05       0.0351       0.0461         1.61      0.00448\n",
            "     85   140      0.00227      0.00224     3.48e-05       0.0312       0.0406         1.82      0.00506\n",
            "     85   150      0.00295      0.00291      3.8e-05        0.034       0.0464         1.91      0.00529\n",
            "     85   160      0.00334      0.00333     1.15e-05       0.0374       0.0496         1.05      0.00291\n",
            "     85   170      0.00249      0.00247     1.91e-05       0.0318       0.0427         1.35      0.00375\n",
            "     85   180      0.00247      0.00246      6.8e-06       0.0306       0.0426        0.806      0.00224\n",
            "     85   190      0.00193      0.00178     0.000144       0.0278       0.0362          3.7       0.0103\n",
            "     85   200      0.00241      0.00228     0.000136       0.0312        0.041         3.61         0.01\n",
            "     85   210      0.00167      0.00167     4.91e-06       0.0268       0.0351        0.685       0.0019\n",
            "     85   220      0.00274      0.00274     1.29e-07       0.0329       0.0449        0.111     0.000308\n",
            "     85   230      0.00225      0.00212     0.000126       0.0288       0.0396         3.47      0.00964\n",
            "     85   240      0.00236      0.00236     9.26e-09       0.0321       0.0418       0.0298     8.27e-05\n",
            "     85   250      0.00301       0.0029      0.00011       0.0346       0.0462         3.25      0.00903\n",
            "     85   260      0.00357      0.00357     4.15e-06       0.0373       0.0513         0.63      0.00175\n",
            "     85   270      0.00292      0.00291     1.44e-05       0.0352       0.0463         1.17      0.00326\n",
            "     85   280      0.00137      0.00137     6.47e-07       0.0247       0.0317        0.249     0.000691\n",
            "     85   290       0.0021      0.00203     7.43e-05       0.0292       0.0387         2.66       0.0074\n",
            "     85   300      0.00253      0.00252     7.77e-06       0.0326       0.0431        0.862      0.00239\n",
            "     85   310      0.00196      0.00196     6.35e-08       0.0293       0.0381       0.0779     0.000216\n",
            "     85   320      0.00192      0.00192        2e-07       0.0283       0.0376        0.138     0.000384\n",
            "     85   330      0.00172      0.00165     6.75e-05       0.0266       0.0349         2.54      0.00706\n",
            "     85   340      0.00192      0.00184     7.79e-05       0.0287       0.0369         2.73      0.00758\n",
            "     85   350      0.00213      0.00211     2.56e-05       0.0305       0.0394         1.56      0.00434\n",
            "     85   360      0.00183      0.00183     4.44e-06       0.0278       0.0367        0.652      0.00181\n",
            "     85   370      0.00201      0.00201     2.07e-06       0.0292       0.0385        0.445      0.00124\n",
            "     85   380      0.00195      0.00195     1.19e-07       0.0288       0.0379        0.107     0.000296\n",
            "     85   390      0.00175      0.00175     1.16e-07       0.0272        0.036        0.105     0.000293\n",
            "     85   400      0.00158      0.00155     3.27e-05       0.0261       0.0338         1.77      0.00491\n",
            "     85   410       0.0018       0.0018     5.74e-09       0.0279       0.0365       0.0234     6.51e-05\n",
            "     85   420      0.00211       0.0021     1.09e-05       0.0301       0.0393         1.02      0.00283\n",
            "     85   430      0.00181      0.00172     9.06e-05       0.0272       0.0356         2.94      0.00817\n",
            "     85   440      0.00199      0.00199     1.92e-07       0.0297       0.0383        0.135     0.000376\n",
            "     85   450      0.00169      0.00165     4.48e-05       0.0265       0.0348         2.07      0.00575\n",
            "     85   460      0.00165      0.00161     4.23e-05       0.0265       0.0344         2.01      0.00558\n",
            "     85   470      0.00248      0.00246     2.49e-05       0.0321       0.0426         1.54      0.00429\n",
            "     85   480      0.00203      0.00202     9.55e-06       0.0296       0.0386        0.956      0.00265\n",
            "     85   490      0.00193      0.00192     7.07e-06       0.0289       0.0377        0.822      0.00228\n",
            "     85   500      0.00184      0.00184     1.86e-06       0.0281       0.0368        0.421      0.00117\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     85    10      0.00187      0.00186     4.18e-06       0.0283       0.0371         0.47      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              85 11156.860    0.004      0.00201     4.79e-05      0.00206       0.0292       0.0385         1.74      0.00484\n",
            "! Validation         85 11156.860    0.004      0.00178     7.56e-06      0.00179       0.0272       0.0362        0.664      0.00184\n",
            "Wall time: 11156.860753979\n",
            "! Best model       85    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     86    10      0.00248      0.00225     0.000229       0.0303       0.0407         4.68        0.013\n",
            "     86    20      0.00176      0.00167     8.94e-05       0.0266       0.0351         2.92      0.00812\n",
            "     86    30      0.00175      0.00171     4.06e-05       0.0273       0.0355         1.97      0.00547\n",
            "     86    40      0.00252      0.00245     7.68e-05       0.0319       0.0425         2.71      0.00752\n",
            "     86    50      0.00181      0.00162     0.000189       0.0266       0.0345         4.25       0.0118\n",
            "     86    60      0.00174      0.00166     7.57e-05       0.0268        0.035         2.69      0.00747\n",
            "     86    70      0.00218      0.00217      2.2e-06       0.0299         0.04        0.459      0.00127\n",
            "     86    80      0.00239      0.00233     5.51e-05       0.0318       0.0415         2.29      0.00637\n",
            "     86    90      0.00183      0.00183     6.65e-07       0.0282       0.0367        0.252       0.0007\n",
            "     86   100      0.00219      0.00203     0.000165       0.0299       0.0387         3.98        0.011\n",
            "     86   110      0.00269      0.00245     0.000244       0.0305       0.0425         4.83       0.0134\n",
            "     86   120      0.00179      0.00176     2.55e-05       0.0277       0.0361         1.56      0.00434\n",
            "     86   130      0.00173      0.00173     1.38e-07       0.0275       0.0357        0.115     0.000319\n",
            "     86   140      0.00212       0.0021     2.39e-05        0.028       0.0393         1.51       0.0042\n",
            "     86   150      0.00229      0.00229     6.36e-06       0.0316       0.0411         0.78      0.00217\n",
            "     86   160       0.0031      0.00309     3.98e-06       0.0364       0.0478        0.617      0.00171\n",
            "     86   170      0.00213       0.0021     2.84e-05       0.0298       0.0394         1.65      0.00457\n",
            "     86   180       0.0017      0.00165     5.08e-05        0.027       0.0349          2.2      0.00612\n",
            "     86   190      0.00234      0.00233     5.35e-06       0.0314       0.0415        0.715      0.00199\n",
            "     86   200      0.00248      0.00247     1.08e-05       0.0325       0.0426         1.02      0.00283\n",
            "     86   210      0.00277      0.00276     6.42e-06       0.0345       0.0451        0.783      0.00218\n",
            "     86   220      0.00231       0.0023     1.82e-05       0.0313       0.0412         1.32      0.00366\n",
            "     86   230      0.00204      0.00202     2.03e-05       0.0287       0.0386         1.39      0.00387\n",
            "     86   240      0.00196      0.00178     0.000182        0.028       0.0362         4.18       0.0116\n",
            "     86   250      0.00193      0.00192     1.48e-05       0.0281       0.0376         1.19       0.0033\n",
            "     86   260      0.00181      0.00178      3.3e-05       0.0275       0.0362         1.78      0.00493\n",
            "     86   270      0.00182      0.00172     9.98e-05       0.0273       0.0356         3.09      0.00858\n",
            "     86   280      0.00176      0.00174     2.72e-05       0.0277       0.0358         1.61      0.00448\n",
            "     86   290      0.00224      0.00223     2.48e-06       0.0299       0.0406        0.487      0.00135\n",
            "     86   300      0.00217      0.00216     1.01e-05       0.0298       0.0399        0.981      0.00273\n",
            "     86   310      0.00239      0.00239     7.44e-07       0.0325        0.042        0.267     0.000741\n",
            "     86   320      0.00188      0.00184     3.85e-05       0.0279       0.0369         1.92      0.00533\n",
            "     86   330      0.00226      0.00226     8.97e-06       0.0309       0.0408        0.926      0.00257\n",
            "     86   340      0.00191       0.0019     6.31e-06       0.0286       0.0374        0.776      0.00216\n",
            "     86   350       0.0029      0.00288     2.52e-05       0.0342       0.0461         1.55      0.00431\n",
            "     86   360      0.00178      0.00173     4.07e-05       0.0268       0.0358         1.97      0.00548\n",
            "     86   370      0.00217      0.00213     4.25e-05       0.0301       0.0396         2.02       0.0056\n",
            "     86   380      0.00186       0.0018     5.48e-05       0.0282       0.0364         2.29      0.00636\n",
            "     86   390      0.00204      0.00203     5.56e-06        0.029       0.0387        0.729      0.00202\n",
            "     86   400       0.0018      0.00172      7.9e-05       0.0276       0.0356         2.75      0.00764\n",
            "     86   410      0.00156      0.00155     6.53e-06       0.0255       0.0338         0.79      0.00219\n",
            "     86   420      0.00167       0.0016     6.85e-05       0.0269       0.0344         2.56      0.00711\n",
            "     86   430      0.00174      0.00171     3.23e-05       0.0275       0.0355         1.76      0.00488\n",
            "     86   440      0.00184      0.00178      5.8e-05       0.0276       0.0362         2.36      0.00654\n",
            "     86   450      0.00224      0.00222     1.78e-05       0.0309       0.0405         1.31      0.00363\n",
            "     86   460       0.0021      0.00205     4.54e-05       0.0295       0.0389         2.08      0.00579\n",
            "     86   470      0.00349      0.00348     2.49e-06       0.0367       0.0507        0.487      0.00135\n",
            "     86   480       0.0021      0.00208     2.03e-05       0.0301       0.0392         1.39      0.00387\n",
            "     86   490      0.00185      0.00178      6.7e-05       0.0274       0.0363         2.53      0.00703\n",
            "     86   500       0.0017       0.0017     3.04e-06       0.0274       0.0354        0.539       0.0015\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     86    10      0.00187      0.00186     4.07e-06       0.0282       0.0371        0.462      0.00128\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              86 11288.489    0.004      0.00202     5.01e-05      0.00207       0.0292       0.0386          1.8      0.00501\n",
            "! Validation         86 11288.489    0.004      0.00178     7.54e-06      0.00178       0.0272       0.0362        0.657      0.00182\n",
            "Wall time: 11288.489327182\n",
            "! Best model       86    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     87    10      0.00204      0.00179     0.000247       0.0274       0.0363         4.86       0.0135\n",
            "     87    20      0.00165      0.00165     7.24e-06       0.0262       0.0349        0.832      0.00231\n",
            "     87    30      0.00193      0.00185     7.96e-05       0.0281       0.0369         2.76      0.00766\n",
            "     87    40      0.00166      0.00158     8.24e-05       0.0259       0.0341         2.81       0.0078\n",
            "     87    50      0.00169      0.00168     9.15e-06       0.0275       0.0352        0.935       0.0026\n",
            "     87    60      0.00236      0.00217     0.000191       0.0304         0.04         4.27       0.0119\n",
            "     87    70      0.00188      0.00184     4.57e-05       0.0282       0.0368         2.09       0.0058\n",
            "     87    80      0.00236      0.00213     0.000223       0.0303       0.0397         4.62       0.0128\n",
            "     87    90      0.00216      0.00193     0.000231       0.0292       0.0377          4.7       0.0131\n",
            "     87   100       0.0025      0.00237     0.000126       0.0315       0.0418         3.47      0.00964\n",
            "     87   110      0.00208      0.00193     0.000143       0.0294       0.0378          3.7       0.0103\n",
            "     87   120      0.00173      0.00173     4.03e-07       0.0263       0.0357        0.196     0.000545\n",
            "     87   130      0.00207      0.00204     2.76e-05       0.0297       0.0388         1.63      0.00451\n",
            "     87   140      0.00162      0.00161      4.4e-07       0.0263       0.0345        0.205      0.00057\n",
            "     87   150      0.00253      0.00235     0.000185       0.0297       0.0416          4.2       0.0117\n",
            "     87   160      0.00217      0.00208     8.08e-05       0.0291       0.0392         2.78      0.00772\n",
            "     87   170      0.00187      0.00187     8.32e-07       0.0285       0.0371        0.282     0.000783\n",
            "     87   180       0.0016      0.00145     0.000149       0.0256       0.0327         3.78       0.0105\n",
            "     87   190      0.00248      0.00232     0.000157       0.0309       0.0414         3.87       0.0108\n",
            "     87   200      0.00165      0.00164     7.44e-06       0.0264       0.0348        0.843      0.00234\n",
            "     87   210       0.0017      0.00159     0.000102       0.0263       0.0343         3.12      0.00866\n",
            "     87   220      0.00245      0.00244     1.18e-05       0.0314       0.0424         1.06      0.00295\n",
            "     87   230      0.00229      0.00225     4.55e-05       0.0309       0.0407         2.09      0.00579\n",
            "     87   240      0.00212      0.00196     0.000167       0.0295        0.038            4       0.0111\n",
            "     87   250      0.00227       0.0022     6.95e-05       0.0303       0.0403         2.58      0.00716\n",
            "     87   260      0.00182      0.00169     0.000136        0.027       0.0353          3.6         0.01\n",
            "     87   270      0.00164      0.00149      0.00015       0.0256       0.0332         3.79       0.0105\n",
            "     87   280      0.00178      0.00165     0.000131       0.0268       0.0348         3.54      0.00982\n",
            "     87   290      0.00222      0.00221     1.57e-05       0.0301       0.0403         1.23      0.00341\n",
            "     87   300      0.00189      0.00185     3.66e-05       0.0278       0.0369         1.87       0.0052\n",
            "     87   310        0.002        0.002     6.41e-07       0.0292       0.0384        0.248     0.000688\n",
            "     87   320      0.00216      0.00205     0.000108       0.0295       0.0389         3.22      0.00893\n",
            "     87   330      0.00182      0.00169     0.000129       0.0277       0.0353         3.52      0.00977\n",
            "     87   340      0.00198      0.00182     0.000158       0.0281       0.0367         3.89       0.0108\n",
            "     87   350      0.00155      0.00155     8.26e-07       0.0255       0.0338        0.281     0.000781\n",
            "     87   360      0.00203      0.00201      1.9e-05        0.029       0.0385         1.35      0.00374\n",
            "     87   370      0.00252      0.00242       0.0001       0.0314       0.0422         3.09      0.00859\n",
            "     87   380      0.00195      0.00195     1.87e-06       0.0292       0.0379        0.423      0.00117\n",
            "     87   390      0.00244      0.00242     1.37e-05       0.0315       0.0423         1.15      0.00318\n",
            "     87   400      0.00245      0.00242     2.18e-05       0.0329       0.0423         1.44      0.00401\n",
            "     87   410      0.00194      0.00194     2.11e-06       0.0285       0.0378        0.449      0.00125\n",
            "     87   420      0.00194      0.00194     2.02e-06       0.0296       0.0378        0.439      0.00122\n",
            "     87   430      0.00152      0.00152     4.05e-06       0.0262       0.0334        0.622      0.00173\n",
            "     87   440      0.00155      0.00153     1.57e-05       0.0255       0.0336         1.23      0.00341\n",
            "     87   450      0.00278      0.00267      0.00011        0.033       0.0444         3.24      0.00899\n",
            "     87   460      0.00175      0.00175     1.06e-07       0.0274       0.0359          0.1     0.000279\n",
            "     87   470       0.0018       0.0018     1.67e-08       0.0282       0.0365       0.0399     0.000111\n",
            "     87   480      0.00355      0.00339     0.000151       0.0373         0.05          3.8       0.0106\n",
            "     87   490      0.00197      0.00187     0.000104       0.0286       0.0371         3.16      0.00876\n",
            "     87   500      0.00226      0.00224     2.39e-05       0.0306       0.0406         1.51       0.0042\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     87    10      0.00187      0.00187      4.4e-06       0.0282       0.0371        0.495      0.00138\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              87 11420.214    0.004      0.00201     7.54e-05      0.00208       0.0292       0.0385         2.16      0.00601\n",
            "! Validation         87 11420.214    0.004      0.00177     7.59e-06      0.00178       0.0272       0.0361        0.677      0.00188\n",
            "Wall time: 11420.214133084\n",
            "! Best model       87    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     88    10      0.00188      0.00188     3.66e-08       0.0287       0.0372       0.0591     0.000164\n",
            "     88    20      0.00169      0.00166     2.81e-05       0.0269        0.035         1.64      0.00455\n",
            "     88    30      0.00179      0.00176     3.06e-05       0.0274        0.036         1.71      0.00475\n",
            "     88    40      0.00163      0.00155     7.98e-05       0.0257       0.0338         2.76      0.00767\n",
            "     88    50      0.00187      0.00178     9.12e-05       0.0278       0.0362         2.95       0.0082\n",
            "     88    60      0.00203      0.00203     4.02e-08       0.0295       0.0387        0.062     0.000172\n",
            "     88    70      0.00165      0.00164     8.23e-06       0.0272       0.0348        0.887      0.00246\n",
            "     88    80      0.00182      0.00181     2.55e-06       0.0278       0.0366        0.494      0.00137\n",
            "     88    90      0.00183      0.00166     0.000174       0.0267        0.035         4.08       0.0113\n",
            "     88   100       0.0019      0.00188      1.5e-05       0.0285       0.0372          1.2      0.00333\n",
            "     88   110       0.0019      0.00189     2.21e-06       0.0288       0.0374        0.459      0.00128\n",
            "     88   120       0.0028       0.0027     9.48e-05       0.0331       0.0446         3.01      0.00836\n",
            "     88   130      0.00181      0.00175     6.34e-05       0.0276       0.0359         2.46      0.00684\n",
            "     88   140      0.00137      0.00137     3.55e-06        0.024       0.0318        0.583      0.00162\n",
            "     88   150      0.00175      0.00173     2.55e-05       0.0268       0.0357         1.56      0.00434\n",
            "     88   160      0.00223      0.00214     8.57e-05       0.0304       0.0398         2.86      0.00795\n",
            "     88   170      0.00225      0.00223     2.22e-05       0.0308       0.0405         1.46      0.00404\n",
            "     88   180      0.00297      0.00291     5.76e-05       0.0339       0.0463         2.35      0.00652\n",
            "     88   190      0.00276      0.00264     0.000119       0.0339       0.0441         3.38      0.00938\n",
            "     88   200        0.002      0.00199      6.1e-06       0.0294       0.0383        0.764      0.00212\n",
            "     88   210      0.00233      0.00233     3.46e-06       0.0315       0.0414        0.575       0.0016\n",
            "     88   220       0.0021      0.00204     5.95e-05       0.0293       0.0388         2.38      0.00662\n",
            "     88   230      0.00149      0.00148     6.42e-06       0.0256        0.033        0.784      0.00218\n",
            "     88   240      0.00171       0.0017     1.06e-05       0.0269       0.0354         1.01       0.0028\n",
            "     88   250      0.00186      0.00183     2.79e-05       0.0284       0.0368         1.63      0.00454\n",
            "     88   260       0.0019      0.00189     1.28e-05       0.0287       0.0373          1.1      0.00307\n",
            "     88   270      0.00361      0.00357      4.6e-05       0.0376       0.0513          2.1      0.00583\n",
            "     88   280      0.00167      0.00161      5.5e-05       0.0262       0.0345         2.29      0.00637\n",
            "     88   290      0.00154       0.0015     3.31e-05        0.026       0.0333         1.78      0.00494\n",
            "     88   300      0.00183      0.00183     3.13e-06       0.0281       0.0367        0.547      0.00152\n",
            "     88   310      0.00208      0.00207     1.22e-05       0.0297       0.0391         1.08      0.00299\n",
            "     88   320      0.00163      0.00162     4.27e-06        0.027       0.0346        0.639      0.00177\n",
            "     88   330      0.00214      0.00206     8.42e-05       0.0296        0.039         2.84      0.00788\n",
            "     88   340       0.0031       0.0031     6.66e-06       0.0361       0.0478        0.798      0.00222\n",
            "     88   350      0.00242      0.00231     0.000117       0.0305       0.0412         3.34      0.00929\n",
            "     88   360      0.00197      0.00191      6.6e-05       0.0288       0.0375         2.51      0.00698\n",
            "     88   370      0.00178      0.00178     3.74e-06       0.0279       0.0362        0.598      0.00166\n",
            "     88   380      0.00142      0.00142     7.44e-07       0.0251       0.0324        0.267     0.000741\n",
            "     88   390      0.00198      0.00195     3.39e-05       0.0288       0.0379          1.8        0.005\n",
            "     88   400      0.00145      0.00145      8.7e-07       0.0247       0.0327        0.288     0.000801\n",
            "     88   410      0.00168      0.00158     9.33e-05       0.0269       0.0342         2.99       0.0083\n",
            "     88   420      0.00177      0.00176     1.67e-05       0.0277        0.036         1.26      0.00351\n",
            "     88   430      0.00161      0.00159     1.93e-05       0.0261       0.0342         1.36      0.00377\n",
            "     88   440      0.00161      0.00161     2.98e-06       0.0265       0.0344        0.534      0.00148\n",
            "     88   450      0.00168      0.00168     1.65e-06       0.0269       0.0352        0.397       0.0011\n",
            "     88   460      0.00205      0.00204     1.22e-05       0.0299       0.0388         1.08        0.003\n",
            "     88   470      0.00224      0.00219     4.95e-05       0.0303       0.0402         2.17      0.00604\n",
            "     88   480      0.00228      0.00218     0.000103       0.0291       0.0401         3.15      0.00874\n",
            "     88   490       0.0021      0.00209     7.56e-06       0.0295       0.0393         0.85      0.00236\n",
            "     88   500      0.00156      0.00154     2.59e-05       0.0258       0.0337         1.57      0.00437\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     88    10      0.00185      0.00185     4.08e-06       0.0281       0.0369        0.468       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              88 11551.603    0.004      0.00196     4.38e-05      0.00201       0.0289       0.0381         1.66      0.00461\n",
            "! Validation         88 11551.603    0.004      0.00176     7.54e-06      0.00177       0.0271        0.036        0.661      0.00184\n",
            "Wall time: 11551.603934282\n",
            "! Best model       88    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     89    10      0.00273      0.00273     7.98e-06       0.0341       0.0448        0.873      0.00243\n",
            "     89    20      0.00196      0.00196     1.14e-07       0.0291        0.038        0.104      0.00029\n",
            "     89    30      0.00252      0.00252     4.43e-07       0.0312       0.0431        0.206     0.000571\n",
            "     89    40      0.00181      0.00179     1.57e-05       0.0266       0.0364         1.22       0.0034\n",
            "     89    50      0.00184      0.00175     8.43e-05        0.027        0.036         2.84      0.00788\n",
            "     89    60      0.00338      0.00338     4.88e-06        0.037       0.0499        0.683       0.0019\n",
            "     89    70       0.0015       0.0015     2.21e-07       0.0255       0.0332        0.145     0.000404\n",
            "     89    80      0.00193      0.00176     0.000172        0.028        0.036         4.06       0.0113\n",
            "     89    90      0.00283      0.00282     1.12e-05       0.0344       0.0456         1.04      0.00288\n",
            "     89   100       0.0026       0.0026      1.8e-07        0.033       0.0438        0.131     0.000364\n",
            "     89   110      0.00205      0.00203     2.25e-05       0.0294       0.0387         1.47      0.00407\n",
            "     89   120      0.00212       0.0021     1.93e-05       0.0289       0.0394         1.36      0.00377\n",
            "     89   130      0.00155      0.00154     9.27e-06       0.0258       0.0337        0.941      0.00262\n",
            "     89   140      0.00191       0.0019     9.07e-06       0.0289       0.0374        0.931      0.00259\n",
            "     89   150      0.00168      0.00156     0.000111       0.0264        0.034         3.26      0.00905\n",
            "     89   160       0.0019      0.00185     5.04e-05       0.0285       0.0369          2.2       0.0061\n",
            "     89   170      0.00191      0.00181     9.72e-05       0.0279       0.0366         3.05      0.00847\n",
            "     89   180      0.00197      0.00193     4.26e-05       0.0285       0.0377         2.02       0.0056\n",
            "     89   190       0.0023      0.00221     9.26e-05       0.0298       0.0404         2.98      0.00827\n",
            "     89   200      0.00174       0.0016     0.000139       0.0267       0.0344         3.65       0.0101\n",
            "     89   210       0.0016      0.00159     7.54e-06       0.0262       0.0343        0.849      0.00236\n",
            "     89   220      0.00207      0.00181     0.000264        0.028       0.0365         5.02        0.014\n",
            "     89   230      0.00216      0.00215     7.35e-06       0.0297       0.0398        0.838      0.00233\n",
            "     89   240       0.0018      0.00162     0.000182        0.027       0.0346         4.17       0.0116\n",
            "     89   250      0.00229      0.00203     0.000261       0.0288       0.0387         4.99       0.0139\n",
            "     89   260      0.00165      0.00165     8.53e-08       0.0269       0.0349       0.0903     0.000251\n",
            "     89   270      0.00162      0.00154     8.37e-05       0.0258       0.0337         2.83      0.00786\n",
            "     89   280      0.00182      0.00181      7.1e-06       0.0286       0.0366        0.824      0.00229\n",
            "     89   290      0.00152      0.00152     1.97e-08        0.026       0.0335       0.0434     0.000121\n",
            "     89   300      0.00178      0.00168     9.33e-05       0.0271       0.0352         2.99       0.0083\n",
            "     89   310      0.00191      0.00191     4.97e-07       0.0287       0.0376        0.218     0.000606\n",
            "     89   320      0.00195      0.00195     6.08e-07       0.0287       0.0379        0.241     0.000669\n",
            "     89   330      0.00172      0.00166     5.66e-05       0.0265        0.035         2.33      0.00646\n",
            "     89   340      0.00142       0.0014     2.26e-05       0.0249       0.0322         1.47      0.00408\n",
            "     89   350       0.0037       0.0037     2.69e-06       0.0381       0.0522        0.507      0.00141\n",
            "     89   360      0.00177      0.00173     4.28e-05       0.0276       0.0357         2.02      0.00562\n",
            "     89   370       0.0019      0.00189      6.3e-06       0.0283       0.0374        0.776      0.00216\n",
            "     89   380      0.00212      0.00212     1.05e-06       0.0285       0.0395        0.317     0.000881\n",
            "     89   390      0.00163      0.00155     8.26e-05       0.0264       0.0338         2.81       0.0078\n",
            "     89   400      0.00214      0.00194     0.000194       0.0292       0.0379         4.31        0.012\n",
            "     89   410      0.00195      0.00194     1.14e-05       0.0286       0.0378         1.04       0.0029\n",
            "     89   420      0.00182      0.00158     0.000242       0.0256       0.0341         4.81       0.0134\n",
            "     89   430       0.0018      0.00164     0.000154       0.0268       0.0348         3.84       0.0107\n",
            "     89   440      0.00169      0.00165     4.14e-05        0.027       0.0349         1.99      0.00552\n",
            "     89   450      0.00191      0.00185     5.12e-05       0.0277        0.037         2.21      0.00614\n",
            "     89   460      0.00237      0.00211     0.000261       0.0298       0.0395         4.99       0.0139\n",
            "     89   470      0.00208      0.00196     0.000125        0.029        0.038         3.46      0.00962\n",
            "     89   480      0.00301      0.00261     0.000403       0.0326       0.0439          6.2       0.0172\n",
            "     89   490      0.00199      0.00173     0.000262        0.027       0.0357         5.01       0.0139\n",
            "     89   500      0.00212      0.00208     4.01e-05       0.0302       0.0392         1.96      0.00544\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     89    10      0.00184      0.00184     4.02e-06        0.028       0.0368        0.465      0.00129\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              89 11683.067    0.004      0.00194     6.85e-05      0.00201       0.0287       0.0378         2.03      0.00565\n",
            "! Validation         89 11683.067    0.004      0.00175     7.58e-06      0.00175        0.027       0.0359         0.66      0.00183\n",
            "Wall time: 11683.067656381\n",
            "! Best model       89    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     90    10      0.00173      0.00172     1.09e-05       0.0272       0.0356         1.02      0.00283\n",
            "     90    20       0.0019      0.00189        4e-06       0.0286       0.0373        0.618      0.00172\n",
            "     90    30       0.0023      0.00219     0.000106         0.03       0.0402         3.18      0.00883\n",
            "     90    40      0.00195      0.00177     0.000175        0.028       0.0362         4.09       0.0114\n",
            "     90    50      0.00164      0.00164     1.62e-06       0.0267       0.0348        0.393      0.00109\n",
            "     90    60      0.00218      0.00216     2.15e-05       0.0301       0.0399         1.43      0.00398\n",
            "     90    70       0.0019      0.00186     3.95e-05       0.0281        0.037         1.94       0.0054\n",
            "     90    80      0.00241       0.0024     7.19e-06       0.0313       0.0421        0.829       0.0023\n",
            "     90    90      0.00171      0.00171     4.87e-08       0.0276       0.0355       0.0682      0.00019\n",
            "     90   100      0.00208      0.00199     9.25e-05       0.0285       0.0383         2.97      0.00826\n",
            "     90   110      0.00171      0.00171     4.07e-07       0.0276       0.0355        0.197     0.000548\n",
            "     90   120       0.0029      0.00281     9.39e-05       0.0347       0.0455            3      0.00832\n",
            "     90   130      0.00237      0.00203     0.000348       0.0293       0.0387         5.77        0.016\n",
            "     90   140      0.00202      0.00171     0.000309       0.0271       0.0355         5.44       0.0151\n",
            "     90   150       0.0017       0.0017     5.96e-06       0.0272       0.0354        0.755       0.0021\n",
            "     90   160      0.00211      0.00208     2.18e-05       0.0301       0.0392         1.44      0.00401\n",
            "     90   170      0.00197      0.00179     0.000186       0.0275       0.0363         4.21       0.0117\n",
            "     90   180      0.00213      0.00212     4.87e-06       0.0312       0.0396        0.682      0.00189\n",
            "     90   190      0.00155      0.00155     3.41e-07        0.026       0.0338        0.181     0.000502\n",
            "     90   200      0.00232      0.00232     3.52e-06       0.0292       0.0414         0.58      0.00161\n",
            "     90   210      0.00183       0.0018     2.97e-05       0.0282       0.0365         1.68      0.00468\n",
            "     90   220      0.00216      0.00195     0.000213       0.0286       0.0379         4.51       0.0125\n",
            "     90   230      0.00168      0.00166     1.47e-05       0.0271        0.035         1.19      0.00329\n",
            "     90   240       0.0017       0.0017     4.72e-06       0.0274       0.0354        0.672      0.00187\n",
            "     90   250      0.00153      0.00152     1.73e-05       0.0255       0.0334         1.29      0.00358\n",
            "     90   260      0.00212      0.00189     0.000234       0.0288       0.0373         4.73       0.0131\n",
            "     90   270      0.00169      0.00159       0.0001       0.0264       0.0343         3.09      0.00859\n",
            "     90   280      0.00193      0.00193      5.2e-06       0.0284       0.0377        0.705      0.00196\n",
            "     90   290      0.00184      0.00184     5.07e-07       0.0279       0.0368         0.22     0.000612\n",
            "     90   300      0.00195      0.00181     0.000141       0.0276       0.0365         3.67       0.0102\n",
            "     90   310      0.00185      0.00182     2.96e-05       0.0281       0.0367         1.68      0.00468\n",
            "     90   320      0.00212      0.00212      2.3e-06       0.0296       0.0395        0.468       0.0013\n",
            "     90   330      0.00162      0.00162     4.53e-06       0.0269       0.0345        0.658      0.00183\n",
            "     90   340      0.00221      0.00219     1.75e-05       0.0296       0.0402          1.3       0.0036\n",
            "     90   350      0.00211      0.00207     4.11e-05         0.03       0.0391         1.98      0.00551\n",
            "     90   360      0.00305      0.00304     8.45e-06       0.0355       0.0474        0.899       0.0025\n",
            "     90   370      0.00268      0.00267     1.78e-06       0.0339       0.0444        0.412      0.00114\n",
            "     90   380       0.0014       0.0014     1.09e-07       0.0251       0.0322        0.102     0.000283\n",
            "     90   390      0.00157      0.00157     1.63e-10       0.0262       0.0341      0.00395      1.1e-05\n",
            "     90   400      0.00258      0.00242     0.000159       0.0313       0.0423          3.9       0.0108\n",
            "     90   410      0.00251       0.0023     0.000212       0.0316       0.0412         4.51       0.0125\n",
            "     90   420      0.00214      0.00214     2.44e-07       0.0306       0.0397        0.153     0.000424\n",
            "     90   430      0.00193      0.00175     0.000175       0.0274       0.0359         4.09       0.0113\n",
            "     90   440      0.00323      0.00313     9.83e-05       0.0366       0.0481         3.07      0.00852\n",
            "     90   450       0.0021      0.00204     5.28e-05       0.0296       0.0388         2.25      0.00624\n",
            "     90   460       0.0018      0.00174     5.88e-05       0.0276       0.0359         2.37      0.00658\n",
            "     90   470      0.00213      0.00196     0.000173       0.0287        0.038         4.07       0.0113\n",
            "     90   480      0.00206      0.00202     3.84e-05       0.0302       0.0386         1.92      0.00532\n",
            "     90   490      0.00182      0.00182     7.01e-08       0.0275       0.0367       0.0819     0.000227\n",
            "     90   500      0.00176      0.00175     5.65e-06       0.0269        0.036        0.735      0.00204\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     90    10      0.00185      0.00185     4.26e-06        0.028       0.0369        0.482      0.00134\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              90 11814.609    0.004      0.00198      5.9e-05      0.00204        0.029       0.0382         1.89      0.00526\n",
            "! Validation         90 11814.609    0.004      0.00175     7.54e-06      0.00176        0.027       0.0359        0.672      0.00187\n",
            "Wall time: 11814.609218762\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     91    10      0.00208      0.00207     5.47e-06         0.03       0.0391        0.723      0.00201\n",
            "     91    20      0.00144      0.00143     9.95e-06        0.025       0.0325        0.975      0.00271\n",
            "     91    30      0.00178      0.00167      0.00011       0.0273       0.0351         3.24        0.009\n",
            "     91    40      0.00223      0.00207     0.000165       0.0298       0.0391         3.98        0.011\n",
            "     91    50      0.00193      0.00193     6.51e-08       0.0289       0.0377       0.0789     0.000219\n",
            "     91    60      0.00164       0.0016     4.16e-05        0.026       0.0343         1.99      0.00554\n",
            "     91    70      0.00222      0.00222     1.18e-06       0.0298       0.0404        0.335     0.000931\n",
            "     91    80      0.00174      0.00172     2.43e-05       0.0262       0.0356         1.52      0.00423\n",
            "     91    90      0.00205      0.00205      2.6e-06       0.0285       0.0389        0.498      0.00138\n",
            "     91   100      0.00188       0.0018      7.8e-05       0.0277       0.0365         2.73      0.00758\n",
            "     91   110      0.00173      0.00158     0.000157       0.0263       0.0341         3.87       0.0107\n",
            "     91   120      0.00245      0.00245     4.49e-06       0.0314       0.0425        0.655      0.00182\n",
            "     91   130      0.00185      0.00172      0.00013       0.0271       0.0356         3.53       0.0098\n",
            "     91   140      0.00166      0.00166     1.19e-07       0.0271        0.035        0.106     0.000296\n",
            "     91   150       0.0021      0.00199     0.000105       0.0289       0.0383         3.17       0.0088\n",
            "     91   160      0.00179      0.00177     2.15e-05       0.0274       0.0361         1.43      0.00398\n",
            "     91   170      0.00201        0.002      7.8e-06       0.0299       0.0384        0.863       0.0024\n",
            "     91   180      0.00207      0.00196       0.0001       0.0295       0.0381          3.1       0.0086\n",
            "     91   190      0.00216      0.00215     1.46e-05       0.0302       0.0398         1.18      0.00328\n",
            "     91   200      0.00207      0.00207     4.02e-06       0.0298        0.039         0.62      0.00172\n",
            "     91   210      0.00158      0.00158     9.57e-07       0.0266       0.0341        0.302      0.00084\n",
            "     91   220      0.00279      0.00279     1.66e-09       0.0343       0.0453       0.0126      3.5e-05\n",
            "     91   230      0.00179      0.00175     4.16e-05        0.028       0.0359         1.99      0.00554\n",
            "     91   240      0.00234      0.00234     1.86e-09       0.0315       0.0416       0.0133     3.71e-05\n",
            "     91   250      0.00185      0.00185     6.32e-07       0.0284       0.0369        0.246     0.000683\n",
            "     91   260      0.00186      0.00186     4.45e-07       0.0281        0.037        0.206     0.000573\n",
            "     91   270      0.00174      0.00171     2.69e-05       0.0266       0.0355         1.61      0.00446\n",
            "     91   280      0.00191      0.00186     5.75e-05       0.0279        0.037         2.34      0.00651\n",
            "     91   290      0.00354      0.00336     0.000178       0.0368       0.0498         4.13       0.0115\n",
            "     91   300       0.0016      0.00159     6.01e-06       0.0265       0.0343        0.758       0.0021\n",
            "     91   310      0.00164      0.00161     3.11e-05       0.0264       0.0345         1.72      0.00479\n",
            "     91   320      0.00195       0.0019     4.57e-05       0.0284       0.0375         2.09      0.00581\n",
            "     91   330      0.00176      0.00172     3.12e-05        0.027       0.0357         1.73      0.00479\n",
            "     91   340      0.00154      0.00152     1.36e-05       0.0255       0.0335         1.14      0.00317\n",
            "     91   350      0.00169      0.00168        1e-05       0.0265       0.0352         0.98      0.00272\n",
            "     91   360      0.00183      0.00174     8.73e-05       0.0281       0.0358         2.89      0.00803\n",
            "     91   370      0.00204      0.00204     5.48e-06       0.0293       0.0388        0.724      0.00201\n",
            "     91   380      0.00207      0.00206     5.97e-06       0.0297        0.039        0.755       0.0021\n",
            "     91   390      0.00158       0.0015     8.27e-05       0.0261       0.0333         2.81      0.00781\n",
            "     91   400      0.00216      0.00206     9.63e-05       0.0304        0.039         3.03      0.00843\n",
            "     91   410      0.00161      0.00159     2.43e-05       0.0265       0.0342         1.53      0.00424\n",
            "     91   420      0.00203      0.00203     2.54e-06       0.0296       0.0387        0.493      0.00137\n",
            "     91   430      0.00235      0.00234      7.8e-06       0.0317       0.0416        0.864       0.0024\n",
            "     91   440      0.00214       0.0021     4.46e-05         0.03       0.0393         2.06      0.00573\n",
            "     91   450      0.00162      0.00159      2.7e-05       0.0262       0.0343         1.61      0.00446\n",
            "     91   460      0.00222      0.00217     4.72e-05         0.03         0.04         2.12       0.0059\n",
            "     91   470      0.00174      0.00173     5.73e-06       0.0278       0.0357         0.74      0.00206\n",
            "     91   480      0.00182      0.00179     2.28e-05       0.0275       0.0364         1.48       0.0041\n",
            "     91   490      0.00257      0.00242     0.000147       0.0317       0.0422         3.75       0.0104\n",
            "     91   500      0.00214      0.00214     5.66e-09       0.0298       0.0397       0.0233     6.46e-05\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     91    10      0.00184      0.00183     4.09e-06       0.0279       0.0368        0.471      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              91 11945.885    0.004      0.00194     3.98e-05      0.00198       0.0287       0.0378         1.56      0.00432\n",
            "! Validation         91 11945.885    0.004      0.00174     7.53e-06      0.00174       0.0269       0.0358        0.659      0.00183\n",
            "Wall time: 11945.885558541\n",
            "! Best model       91    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     92    10      0.00169      0.00162     7.42e-05       0.0266       0.0346         2.66       0.0074\n",
            "     92    20        0.002      0.00198     1.59e-05        0.029       0.0382         1.23      0.00343\n",
            "     92    30      0.00188      0.00188     1.14e-06       0.0278       0.0372         0.33     0.000918\n",
            "     92    40      0.00373       0.0037     2.74e-05       0.0378       0.0523         1.62       0.0045\n",
            "     92    50      0.00182      0.00173     9.69e-05       0.0273       0.0357         3.04      0.00845\n",
            "     92    60      0.00185      0.00176     9.57e-05       0.0274        0.036         3.02       0.0084\n",
            "     92    70      0.00196      0.00192     4.72e-05        0.029       0.0376         2.13       0.0059\n",
            "     92    80      0.00211      0.00206     4.92e-05       0.0298        0.039         2.17      0.00603\n",
            "     92    90      0.00181       0.0018     5.91e-06        0.028       0.0365        0.751      0.00209\n",
            "     92   100      0.00169      0.00166     3.23e-05       0.0272        0.035         1.76      0.00488\n",
            "     92   110      0.00181      0.00181     7.95e-11       0.0278       0.0365      0.00276     7.66e-06\n",
            "     92   120      0.00209      0.00209     8.24e-09       0.0297       0.0393       0.0281      7.8e-05\n",
            "     92   130      0.00198      0.00195     3.52e-05       0.0291       0.0379         1.83      0.00509\n",
            "     92   140      0.00202        0.002     2.14e-05       0.0296       0.0384         1.43      0.00397\n",
            "     92   150      0.00138      0.00136     1.61e-05       0.0244       0.0317         1.24      0.00344\n",
            "     92   160      0.00203      0.00195     7.81e-05       0.0286       0.0379         2.73      0.00759\n",
            "     92   170       0.0018       0.0018     7.76e-09       0.0274       0.0365       0.0272     7.57e-05\n",
            "     92   180       0.0021       0.0021     5.53e-07       0.0295       0.0393         0.23     0.000639\n",
            "     92   190      0.00228      0.00226     1.93e-05       0.0309       0.0408         1.36      0.00377\n",
            "     92   200      0.00257       0.0025     6.64e-05       0.0323        0.043         2.52        0.007\n",
            "     92   210      0.00195      0.00192     2.75e-05       0.0287       0.0376         1.62       0.0045\n",
            "     92   220      0.00215      0.00215     2.58e-06       0.0306       0.0398        0.496      0.00138\n",
            "     92   230      0.00184      0.00184     5.42e-08       0.0285       0.0369        0.072       0.0002\n",
            "     92   240      0.00281      0.00276     5.43e-05       0.0336       0.0451         2.28      0.00633\n",
            "     92   250      0.00177      0.00176     7.42e-06       0.0276        0.036        0.842      0.00234\n",
            "     92   260        0.002        0.002     1.84e-06       0.0295       0.0384         0.42      0.00117\n",
            "     92   270      0.00215      0.00215     3.56e-09       0.0286       0.0398       0.0184     5.12e-05\n",
            "     92   280       0.0019       0.0019     5.49e-08       0.0283       0.0374       0.0725     0.000201\n",
            "     92   290      0.00214      0.00206     7.99e-05         0.03        0.039         2.76      0.00768\n",
            "     92   300       0.0022      0.00218     2.14e-05       0.0309       0.0401         1.43      0.00397\n",
            "     92   310      0.00247      0.00243     4.13e-05       0.0327       0.0423         1.99      0.00552\n",
            "     92   320      0.00163      0.00162     9.94e-06       0.0265       0.0346        0.975      0.00271\n",
            "     92   330      0.00222      0.00215     6.78e-05       0.0294       0.0398         2.55      0.00707\n",
            "     92   340      0.00197      0.00189     8.31e-05       0.0286       0.0373         2.82      0.00783\n",
            "     92   350      0.00169      0.00168     1.59e-05       0.0267       0.0352         1.23      0.00342\n",
            "     92   360      0.00268      0.00264     4.75e-05       0.0336       0.0441         2.13      0.00592\n",
            "     92   370      0.00221      0.00212     9.61e-05       0.0298       0.0395         3.03      0.00842\n",
            "     92   380      0.00163      0.00162     1.02e-05       0.0261       0.0345        0.986      0.00274\n",
            "     92   390      0.00184      0.00182     1.53e-05       0.0284       0.0367         1.21      0.00336\n",
            "     92   400      0.00241      0.00239     2.23e-05       0.0295       0.0419         1.46      0.00405\n",
            "     92   410      0.00239      0.00235     3.49e-05       0.0317       0.0417         1.83      0.00507\n",
            "     92   420      0.00198      0.00196     2.23e-05       0.0296        0.038         1.46      0.00405\n",
            "     92   430      0.00202      0.00202     1.15e-06       0.0288       0.0386        0.331     0.000921\n",
            "     92   440      0.00204      0.00204        3e-06       0.0268       0.0388        0.536      0.00149\n",
            "     92   450      0.00164      0.00161      3.4e-05        0.027       0.0344          1.8      0.00501\n",
            "     92   460      0.00164      0.00163     1.23e-05       0.0268       0.0347         1.08      0.00301\n",
            "     92   470      0.00186      0.00184     1.26e-05       0.0289       0.0369          1.1      0.00305\n",
            "     92   480      0.00163      0.00162     1.07e-05       0.0259       0.0345         1.01      0.00281\n",
            "     92   490      0.00196      0.00187     8.95e-05       0.0279       0.0371         2.92      0.00812\n",
            "     92   500      0.00167       0.0016     7.39e-05       0.0261       0.0344         2.66      0.00738\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     92    10      0.00183      0.00182     4.23e-06       0.0278       0.0367         0.48      0.00133\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              92 12077.128    0.004      0.00194     3.31e-05      0.00198       0.0287       0.0379         1.41      0.00391\n",
            "! Validation         92 12077.128    0.004      0.00174     7.53e-06      0.00174       0.0269       0.0358        0.667      0.00185\n",
            "Wall time: 12077.129062372\n",
            "! Best model       92    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     93    10      0.00275      0.00265     0.000105       0.0338       0.0442         3.16      0.00878\n",
            "     93    20      0.00199      0.00198     4.07e-06       0.0293       0.0382        0.624      0.00173\n",
            "     93    30      0.00203      0.00194     8.62e-05       0.0291       0.0378         2.87      0.00797\n",
            "     93    40      0.00349      0.00348     4.29e-06       0.0368       0.0507        0.641      0.00178\n",
            "     93    50      0.00198      0.00198      4.9e-06       0.0298       0.0382        0.684       0.0019\n",
            "     93    60      0.00184      0.00183     1.78e-05       0.0289       0.0367          1.3      0.00362\n",
            "     93    70      0.00162       0.0016     1.51e-05       0.0264       0.0344          1.2      0.00334\n",
            "     93    80      0.00177      0.00172     5.05e-05       0.0276       0.0356          2.2      0.00611\n",
            "     93    90      0.00185      0.00179     5.29e-05        0.028       0.0364         2.25      0.00625\n",
            "     93   100      0.00296      0.00296     8.36e-06       0.0348       0.0467        0.894      0.00248\n",
            "     93   110      0.00161       0.0016     8.53e-06       0.0264       0.0343        0.903      0.00251\n",
            "     93   120      0.00154      0.00149     5.29e-05       0.0252       0.0332         2.25      0.00625\n",
            "     93   130      0.00226       0.0022     6.08e-05       0.0315       0.0403         2.41       0.0067\n",
            "     93   140      0.00172      0.00172     1.62e-06        0.027       0.0356        0.393      0.00109\n",
            "     93   150      0.00179      0.00179        6e-07       0.0271       0.0363         0.24     0.000665\n",
            "     93   160      0.00303      0.00301     2.11e-05       0.0353       0.0471         1.42      0.00395\n",
            "     93   170       0.0019      0.00188     2.64e-05       0.0283       0.0372         1.59      0.00441\n",
            "     93   180      0.00232      0.00229     2.51e-05       0.0307       0.0411         1.55      0.00431\n",
            "     93   190       0.0019      0.00184     6.41e-05       0.0282       0.0368         2.48      0.00688\n",
            "     93   200      0.00194      0.00193     1.18e-05       0.0288       0.0377         1.06      0.00296\n",
            "     93   210      0.00171       0.0017     1.08e-05       0.0265       0.0354         1.02      0.00282\n",
            "     93   220      0.00135      0.00135     1.58e-07       0.0244       0.0315        0.123     0.000342\n",
            "     93   230      0.00156      0.00156     2.94e-07       0.0258       0.0339        0.168     0.000466\n",
            "     93   240      0.00203      0.00193     0.000104       0.0288       0.0377         3.16      0.00877\n",
            "     93   250       0.0016       0.0016     5.81e-08       0.0265       0.0344       0.0745     0.000207\n",
            "     93   260      0.00207      0.00206     1.37e-05       0.0293        0.039         1.15      0.00318\n",
            "     93   270      0.00149      0.00146     3.17e-05       0.0249       0.0328         1.74      0.00484\n",
            "     93   280      0.00258      0.00246      0.00013        0.032       0.0426         3.52      0.00978\n",
            "     93   290      0.00143      0.00139     4.31e-05       0.0247        0.032         2.03      0.00564\n",
            "     93   300      0.00232      0.00232     4.19e-06       0.0316       0.0413        0.633      0.00176\n",
            "     93   310      0.00261       0.0026     5.02e-06       0.0323       0.0438        0.693      0.00193\n",
            "     93   320      0.00147      0.00146     9.03e-06       0.0253       0.0328        0.929      0.00258\n",
            "     93   330      0.00174      0.00164     9.81e-05       0.0269       0.0348         3.06      0.00851\n",
            "     93   340      0.00221      0.00221     4.45e-07       0.0308       0.0404        0.206     0.000573\n",
            "     93   350      0.00177      0.00176     5.98e-06       0.0278        0.036        0.756       0.0021\n",
            "     93   360       0.0018      0.00178     2.03e-05       0.0273       0.0363         1.39      0.00387\n",
            "     93   370      0.00191      0.00191     1.03e-06       0.0282       0.0376        0.314     0.000873\n",
            "     93   380      0.00191      0.00189     2.49e-05       0.0291       0.0373         1.54      0.00428\n",
            "     93   390      0.00239      0.00229     0.000109       0.0312       0.0411         3.22      0.00896\n",
            "     93   400      0.00176      0.00171     4.79e-05       0.0276       0.0355         2.14      0.00595\n",
            "     93   410      0.00188      0.00182     6.43e-05       0.0278       0.0366         2.48      0.00689\n",
            "     93   420      0.00278      0.00258     0.000193       0.0326       0.0436          4.3       0.0119\n",
            "     93   430      0.00192      0.00186     6.03e-05       0.0277        0.037          2.4      0.00667\n",
            "     93   440      0.00165      0.00162     2.76e-05       0.0269       0.0346         1.62      0.00451\n",
            "     93   450      0.00207      0.00207      1.1e-07       0.0299       0.0391        0.103     0.000285\n",
            "     93   460      0.00216      0.00198     0.000175       0.0293       0.0383         4.09       0.0114\n",
            "     93   470       0.0021      0.00204     5.99e-05       0.0298       0.0388         2.39      0.00665\n",
            "     93   480      0.00188      0.00185     3.04e-05       0.0277       0.0369         1.71      0.00474\n",
            "     93   490      0.00217      0.00206     0.000109       0.0294        0.039         3.23      0.00897\n",
            "     93   500      0.00211      0.00211     1.93e-07       0.0294       0.0395        0.136     0.000378\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     93    10      0.00182      0.00181     4.05e-06       0.0278       0.0366        0.467       0.0013\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              93 12208.537    0.004      0.00193     4.55e-05      0.00198       0.0286       0.0378         1.65       0.0046\n",
            "! Validation         93 12208.537    0.004      0.00173     7.56e-06      0.00173       0.0268       0.0357        0.661      0.00183\n",
            "Wall time: 12208.537718673\n",
            "! Best model       93    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     94    10      0.00273      0.00263     9.96e-05       0.0328        0.044         3.09      0.00857\n",
            "     94    20      0.00198      0.00197      4.3e-06       0.0296       0.0382        0.641      0.00178\n",
            "     94    30       0.0015      0.00145     5.21e-05       0.0246       0.0327         2.23       0.0062\n",
            "     94    40      0.00273      0.00256     0.000166       0.0322       0.0435         3.98       0.0111\n",
            "     94    50      0.00197      0.00188     8.57e-05       0.0283       0.0373         2.86      0.00795\n",
            "     94    60      0.00242      0.00223     0.000183       0.0308       0.0406         4.18       0.0116\n",
            "     94    70      0.00195      0.00194     7.53e-06       0.0291       0.0379        0.848      0.00236\n",
            "     94    80      0.00249      0.00234     0.000143        0.032       0.0416          3.7       0.0103\n",
            "     94    90      0.00186      0.00186      5.7e-06       0.0287        0.037        0.738      0.00205\n",
            "     94   100      0.00246      0.00241     4.71e-05       0.0322       0.0421         2.12      0.00589\n",
            "     94   110      0.00194      0.00189     4.93e-05       0.0288       0.0373         2.17      0.00603\n",
            "     94   120      0.00177       0.0017     6.87e-05       0.0273       0.0354         2.56      0.00712\n",
            "     94   130      0.00195      0.00188      6.7e-05       0.0278       0.0372         2.53      0.00703\n",
            "     94   140      0.00204      0.00202     2.26e-05       0.0297       0.0386         1.47      0.00408\n",
            "     94   150      0.00247      0.00247        3e-06        0.032       0.0427        0.536      0.00149\n",
            "     94   160      0.00193      0.00191      2.3e-05       0.0285       0.0375         1.48      0.00411\n",
            "     94   170      0.00162       0.0016      2.7e-05       0.0264       0.0343         1.61      0.00446\n",
            "     94   180      0.00202      0.00202     4.77e-06       0.0295       0.0386        0.675      0.00188\n",
            "     94   190      0.00176      0.00174     2.55e-05       0.0269       0.0358         1.56      0.00433\n",
            "     94   200      0.00191      0.00191     2.31e-06       0.0281       0.0376         0.47      0.00131\n",
            "     94   210      0.00184      0.00169     0.000155       0.0264       0.0353         3.85       0.0107\n",
            "     94   220      0.00203      0.00199     3.36e-05       0.0298       0.0383         1.79      0.00498\n",
            "     94   230      0.00233      0.00227      5.5e-05       0.0316        0.041         2.29      0.00637\n",
            "     94   240      0.00169      0.00166      3.1e-05        0.027        0.035         1.72      0.00479\n",
            "     94   250      0.00295      0.00295     2.31e-06       0.0349       0.0466        0.469       0.0013\n",
            "     94   260      0.00184      0.00184     1.41e-06       0.0283       0.0368        0.367      0.00102\n",
            "     94   270      0.00173      0.00169     3.78e-05       0.0256       0.0353          1.9      0.00528\n",
            "     94   280      0.00198      0.00194      4.5e-05       0.0282       0.0378         2.07      0.00576\n",
            "     94   290      0.00141      0.00141     2.65e-07       0.0249       0.0323        0.159     0.000442\n",
            "     94   300      0.00149      0.00149     2.67e-06       0.0257       0.0332        0.506       0.0014\n",
            "     94   310      0.00207      0.00207     2.88e-06       0.0297        0.039        0.525      0.00146\n",
            "     94   320      0.00242      0.00207     0.000346       0.0303       0.0391         5.75        0.016\n",
            "     94   330      0.00229      0.00201     0.000276       0.0298       0.0385         5.13       0.0143\n",
            "     94   340      0.00168      0.00163     5.61e-05       0.0264       0.0346         2.32      0.00643\n",
            "     94   350      0.00268      0.00267     1.98e-06        0.033       0.0444        0.435      0.00121\n",
            "     94   360      0.00254      0.00253     5.56e-06       0.0325       0.0432        0.729      0.00202\n",
            "     94   370      0.00149      0.00145     3.96e-05       0.0253       0.0327         1.95      0.00541\n",
            "     94   380      0.00156      0.00154     1.57e-05       0.0257       0.0337         1.22       0.0034\n",
            "     94   390      0.00231       0.0023     8.43e-06       0.0314       0.0412        0.898      0.00249\n",
            "     94   400      0.00155      0.00146     9.36e-05       0.0257       0.0328         2.99      0.00831\n",
            "     94   410      0.00155      0.00154     8.49e-06       0.0261       0.0337        0.901       0.0025\n",
            "     94   420      0.00164      0.00164     2.52e-07       0.0267       0.0348        0.155     0.000431\n",
            "     94   430      0.00185      0.00185     5.28e-06       0.0285       0.0369         0.71      0.00197\n",
            "     94   440      0.00162      0.00161     1.53e-05       0.0262       0.0344         1.21      0.00335\n",
            "     94   450      0.00198      0.00198     1.51e-06       0.0289       0.0382         0.38      0.00106\n",
            "     94   460        0.002      0.00198      2.5e-05       0.0286       0.0382         1.54      0.00429\n",
            "     94   470      0.00269      0.00269     1.71e-06       0.0335       0.0445        0.405      0.00112\n",
            "     94   480      0.00178      0.00177     9.25e-06       0.0278       0.0362         0.94      0.00261\n",
            "     94   490      0.00191      0.00188     3.16e-05       0.0291       0.0372         1.74      0.00483\n",
            "     94   500      0.00231      0.00231     6.31e-07       0.0301       0.0412        0.246     0.000682\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     94    10      0.00181      0.00181     4.64e-06       0.0278       0.0365        0.526      0.00146\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              94 12339.975    0.004       0.0019     5.24e-05      0.00196       0.0284       0.0375          1.8        0.005\n",
            "! Validation         94 12339.975    0.004      0.00172     7.71e-06      0.00173       0.0268       0.0356        0.692      0.00192\n",
            "Wall time: 12339.9757171\n",
            "! Best model       94    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     95    10      0.00189      0.00188     1.06e-05       0.0291       0.0372         1.01      0.00279\n",
            "     95    20      0.00199      0.00198     1.01e-05       0.0294       0.0382        0.985      0.00273\n",
            "     95    30      0.00154      0.00154     5.82e-07       0.0259       0.0337        0.236     0.000655\n",
            "     95    40      0.00193      0.00184     9.07e-05       0.0283       0.0369         2.95      0.00818\n",
            "     95    50      0.00153      0.00151     2.02e-05       0.0253       0.0334         1.39      0.00386\n",
            "     95    60      0.00234      0.00222      0.00012       0.0306       0.0405         3.39      0.00942\n",
            "     95    70      0.00198      0.00184      0.00014       0.0284       0.0369         3.66       0.0102\n",
            "     95    80      0.00181      0.00181     5.82e-06       0.0283       0.0365        0.746      0.00207\n",
            "     95    90      0.00194      0.00194     2.04e-06       0.0293       0.0378        0.441      0.00123\n",
            "     95   100      0.00172       0.0015     0.000222       0.0252       0.0332         4.61       0.0128\n",
            "     95   110      0.00148      0.00148      4.3e-07       0.0249       0.0331        0.203     0.000563\n",
            "     95   120      0.00174      0.00173     6.13e-06       0.0279       0.0357        0.765      0.00213\n",
            "     95   130      0.00144      0.00143     9.35e-07       0.0247       0.0325        0.299      0.00083\n",
            "     95   140      0.00224      0.00222     1.79e-05       0.0302       0.0404         1.31      0.00364\n",
            "     95   150      0.00153      0.00153      3.4e-06       0.0259       0.0335         0.57      0.00158\n",
            "     95   160      0.00173      0.00171     1.28e-05       0.0272       0.0355          1.1      0.00307\n",
            "     95   170      0.00162      0.00162     2.09e-06       0.0268       0.0345        0.447      0.00124\n",
            "     95   180      0.00174      0.00174     5.86e-07       0.0278       0.0358        0.237     0.000657\n",
            "     95   190      0.00186      0.00185     8.11e-06       0.0292        0.037        0.881      0.00245\n",
            "     95   200       0.0019      0.00176     0.000133       0.0275       0.0361         3.56      0.00989\n",
            "     95   210      0.00259      0.00258     7.55e-06       0.0332       0.0436         0.85      0.00236\n",
            "     95   220      0.00196      0.00194     2.38e-05       0.0294       0.0378         1.51      0.00419\n",
            "     95   230      0.00133      0.00132     1.46e-05        0.024       0.0312         1.18      0.00328\n",
            "     95   240      0.00168      0.00168     4.56e-06       0.0267       0.0352         0.66      0.00183\n",
            "     95   250      0.00158      0.00158     4.56e-07       0.0265       0.0342        0.209      0.00058\n",
            "     95   260      0.00176      0.00172     4.68e-05       0.0274       0.0356         2.11      0.00587\n",
            "     95   270      0.00178      0.00173     4.95e-05       0.0273       0.0357         2.18      0.00604\n",
            "     95   280      0.00205      0.00198     6.61e-05       0.0294       0.0382         2.51      0.00698\n",
            "     95   290      0.00155      0.00153     1.97e-05       0.0254       0.0336         1.37      0.00381\n",
            "     95   300        0.002        0.002     6.68e-06       0.0293       0.0384        0.799      0.00222\n",
            "     95   310      0.00171      0.00171     7.18e-06       0.0275       0.0355        0.829       0.0023\n",
            "     95   320      0.00206      0.00206     4.28e-07       0.0297        0.039        0.202     0.000562\n",
            "     95   330      0.00228      0.00222     5.46e-05       0.0305       0.0405         2.29      0.00635\n",
            "     95   340       0.0031       0.0031     5.01e-07        0.036       0.0478        0.219     0.000608\n",
            "     95   350      0.00193      0.00189     4.11e-05        0.029       0.0374         1.98       0.0055\n",
            "     95   360      0.00214      0.00213     1.16e-05         0.03       0.0397         1.05      0.00293\n",
            "     95   370      0.00157      0.00157     5.77e-06       0.0264        0.034        0.743      0.00206\n",
            "     95   380      0.00231      0.00221     9.78e-05       0.0302       0.0404         3.06      0.00849\n",
            "     95   390      0.00207      0.00202     5.46e-05       0.0295       0.0386         2.28      0.00635\n",
            "     95   400      0.00173      0.00173      1.9e-06       0.0274       0.0357        0.426      0.00118\n",
            "     95   410       0.0014      0.00138     1.57e-05       0.0246       0.0319         1.23      0.00341\n",
            "     95   420      0.00205      0.00187     0.000176       0.0284       0.0371          4.1       0.0114\n",
            "     95   430      0.00218      0.00216     1.81e-05       0.0294       0.0399         1.32      0.00366\n",
            "     95   440        0.002      0.00196     3.64e-05       0.0297       0.0381         1.87      0.00518\n",
            "     95   450      0.00164      0.00164      8.4e-06       0.0267       0.0347        0.896      0.00249\n",
            "     95   460      0.00176       0.0015     0.000253       0.0256       0.0333         4.92       0.0137\n",
            "     95   470      0.00178      0.00178     1.98e-06       0.0271       0.0363        0.435      0.00121\n",
            "     95   480      0.00191      0.00191      5.2e-07       0.0287       0.0376        0.223     0.000619\n",
            "     95   490      0.00168      0.00161     7.15e-05       0.0265       0.0345         2.61      0.00726\n",
            "     95   500      0.00167      0.00165     2.33e-05       0.0275       0.0349         1.49      0.00415\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     95    10       0.0018       0.0018     4.87e-06       0.0276       0.0364        0.549      0.00153\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              95 12471.202    0.004       0.0019     3.76e-05      0.00194       0.0284       0.0375         1.53      0.00426\n",
            "! Validation         95 12471.202    0.004      0.00171     7.81e-06      0.00172       0.0267       0.0355        0.703      0.00195\n",
            "Wall time: 12471.202800062\n",
            "! Best model       95    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     96    10      0.00173      0.00173     5.45e-07       0.0274       0.0358        0.228     0.000634\n",
            "     96    20      0.00171       0.0016     0.000105       0.0267       0.0344         3.17      0.00882\n",
            "     96    30      0.00149      0.00144     5.41e-05       0.0251       0.0326         2.27      0.00632\n",
            "     96    40       0.0014      0.00138     1.89e-05        0.025       0.0319         1.34      0.00374\n",
            "     96    50      0.00202      0.00181     0.000218       0.0277       0.0365         4.57       0.0127\n",
            "     96    60      0.00161       0.0016     2.87e-06       0.0264       0.0344        0.524      0.00146\n",
            "     96    70       0.0016      0.00158     2.34e-05       0.0261       0.0341         1.49      0.00415\n",
            "     96    80      0.00152      0.00152     1.72e-06       0.0253       0.0335        0.405      0.00113\n",
            "     96    90      0.00239      0.00229      9.3e-05       0.0308       0.0411         2.98      0.00828\n",
            "     96   100      0.00161      0.00161     1.49e-08       0.0267       0.0345       0.0377     0.000105\n",
            "     96   110      0.00207      0.00204     2.94e-05         0.03       0.0388         1.68      0.00466\n",
            "     96   120      0.00179      0.00178     1.17e-05       0.0279       0.0363         1.06      0.00294\n",
            "     96   130      0.00149      0.00149     3.99e-06       0.0252       0.0331        0.617      0.00172\n",
            "     96   140      0.00215      0.00215     5.99e-08       0.0305       0.0399       0.0757      0.00021\n",
            "     96   150      0.00185      0.00183     1.44e-05       0.0279       0.0368         1.17      0.00326\n",
            "     96   160      0.00211       0.0021     4.54e-06       0.0305       0.0394        0.659      0.00183\n",
            "     96   170      0.00224       0.0022     4.34e-05       0.0304       0.0403         2.04      0.00566\n",
            "     96   180      0.00221      0.00217     3.63e-05       0.0305         0.04         1.86      0.00518\n",
            "     96   190      0.00239      0.00232     7.07e-05       0.0313       0.0414          2.6      0.00722\n",
            "     96   200      0.00194      0.00194     3.11e-06       0.0287       0.0378        0.545      0.00151\n",
            "     96   210      0.00208      0.00208     8.29e-08       0.0295       0.0392        0.089     0.000247\n",
            "     96   220      0.00181      0.00175     5.91e-05       0.0269       0.0359         2.38       0.0066\n",
            "     96   230      0.00155      0.00155     1.06e-06       0.0257       0.0338        0.318     0.000883\n",
            "     96   240      0.00288      0.00286     1.74e-05        0.035        0.046         1.29      0.00358\n",
            "     96   250      0.00232      0.00231     4.42e-06       0.0311       0.0413         0.65      0.00181\n",
            "     96   260      0.00228      0.00226     1.46e-05       0.0307       0.0409         1.18      0.00328\n",
            "     96   270      0.00162      0.00161     9.32e-06        0.026       0.0345        0.944      0.00262\n",
            "     96   280      0.00182      0.00152     0.000302        0.026       0.0335         5.37       0.0149\n",
            "     96   290      0.00183      0.00169     0.000145       0.0274       0.0353         3.72       0.0103\n",
            "     96   300      0.00171      0.00155     0.000159       0.0258       0.0338         3.89       0.0108\n",
            "     96   310      0.00159      0.00159      1.3e-06       0.0262       0.0343        0.353      0.00098\n",
            "     96   320      0.00176      0.00175     1.04e-05       0.0277       0.0359        0.995      0.00276\n",
            "     96   330      0.00176      0.00175     1.12e-05        0.027       0.0359         1.04      0.00288\n",
            "     96   340      0.00179      0.00173     5.53e-05       0.0275       0.0358          2.3      0.00639\n",
            "     96   350      0.00245      0.00219     0.000256       0.0298       0.0402         4.95       0.0138\n",
            "     96   360      0.00181      0.00167     0.000136       0.0262       0.0351          3.6         0.01\n",
            "     96   370      0.00201      0.00185     0.000156       0.0285        0.037         3.86       0.0107\n",
            "     96   380      0.00207      0.00204     2.51e-05       0.0303       0.0388         1.55      0.00431\n",
            "     96   390      0.00208      0.00205     2.62e-05         0.03       0.0389         1.58       0.0044\n",
            "     96   400       0.0021      0.00207     3.21e-05       0.0291       0.0391         1.75      0.00487\n",
            "     96   410      0.00196      0.00196        5e-06       0.0283        0.038        0.691      0.00192\n",
            "     96   420      0.00236      0.00235     5.24e-06       0.0315       0.0416        0.708      0.00197\n",
            "     96   430      0.00157      0.00154     3.22e-05       0.0259       0.0337         1.75      0.00487\n",
            "     96   440      0.00175      0.00173     2.48e-05        0.028       0.0357         1.54      0.00427\n",
            "     96   450      0.00177      0.00176     1.23e-05       0.0277        0.036         1.09      0.00302\n",
            "     96   460      0.00223       0.0021     0.000132         0.03       0.0393         3.55      0.00985\n",
            "     96   470      0.00195      0.00195     1.77e-06       0.0273       0.0379        0.411      0.00114\n",
            "     96   480      0.00238      0.00228     9.41e-05       0.0317        0.041            3      0.00833\n",
            "     96   490      0.00199      0.00198     7.28e-06       0.0288       0.0382        0.834      0.00232\n",
            "     96   500      0.00241      0.00241     3.46e-07       0.0315       0.0422        0.182     0.000505\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     96    10       0.0018       0.0018     4.07e-06       0.0276       0.0364        0.472      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              96 12602.163    0.004      0.00192     4.34e-05      0.00197       0.0285       0.0377         1.63      0.00452\n",
            "! Validation         96 12602.163    0.004      0.00171     7.63e-06      0.00172       0.0267       0.0355        0.666      0.00185\n",
            "Wall time: 12602.163454477999\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     97    10      0.00189      0.00189     1.83e-06       0.0287       0.0373        0.418      0.00116\n",
            "     97    20      0.00191      0.00191     2.82e-06       0.0285       0.0375        0.519      0.00144\n",
            "     97    30      0.00169      0.00169     5.26e-08       0.0266       0.0353       0.0709     0.000197\n",
            "     97    40      0.00172      0.00172     7.96e-06       0.0272       0.0356        0.872      0.00242\n",
            "     97    50      0.00265      0.00245     0.000195       0.0322       0.0425         4.31        0.012\n",
            "     97    60      0.00191      0.00182     8.97e-05       0.0275       0.0367         2.93      0.00813\n",
            "     97    70      0.00205      0.00195     0.000103        0.028       0.0379         3.13       0.0087\n",
            "     97    80      0.00156      0.00147     9.69e-05       0.0253       0.0329         3.04      0.00845\n",
            "     97    90      0.00169      0.00168     8.27e-06       0.0268       0.0352        0.889      0.00247\n",
            "     97   100      0.00145      0.00144     1.06e-05       0.0252       0.0326         1.01       0.0028\n",
            "     97   110      0.00236      0.00231     4.38e-05       0.0311       0.0413         2.05      0.00568\n",
            "     97   120      0.00169      0.00155     0.000136       0.0257       0.0339         3.61         0.01\n",
            "     97   130      0.00177      0.00174     3.48e-05        0.028       0.0358         1.82      0.00507\n",
            "     97   140      0.00255      0.00246     8.36e-05       0.0311       0.0426         2.83      0.00785\n",
            "     97   150       0.0029      0.00286     4.11e-05       0.0344       0.0459         1.98      0.00551\n",
            "     97   160      0.00165      0.00165     1.61e-06       0.0275       0.0348        0.393      0.00109\n",
            "     97   170      0.00169      0.00166     3.11e-05       0.0265        0.035         1.72      0.00479\n",
            "     97   180      0.00233       0.0023     2.47e-05       0.0317       0.0412         1.54      0.00427\n",
            "     97   190      0.00192      0.00174     0.000181       0.0274       0.0358         4.15       0.0115\n",
            "     97   200      0.00221      0.00221     1.22e-06       0.0303       0.0404        0.341     0.000947\n",
            "     97   210      0.00221      0.00221     6.52e-06       0.0307       0.0403        0.789      0.00219\n",
            "     97   220      0.00226      0.00226     6.82e-10       0.0314       0.0408      0.00808     2.24e-05\n",
            "     97   230      0.00171      0.00169     1.67e-05       0.0268       0.0353         1.26      0.00351\n",
            "     97   240        0.002      0.00196     3.34e-05       0.0288        0.038         1.79      0.00497\n",
            "     97   250      0.00209      0.00206     3.21e-05       0.0295       0.0389         1.75      0.00486\n",
            "     97   260       0.0021      0.00209     6.03e-06       0.0296       0.0393        0.759      0.00211\n",
            "     97   270      0.00145      0.00142     2.71e-05        0.025       0.0324         1.61      0.00447\n",
            "     97   280      0.00253      0.00248     5.45e-05       0.0312       0.0428         2.28      0.00634\n",
            "     97   290      0.00194      0.00194     1.95e-07       0.0288       0.0378        0.137     0.000379\n",
            "     97   300      0.00178      0.00163      0.00015        0.027       0.0347         3.79       0.0105\n",
            "     97   310      0.00163      0.00163      1.2e-07       0.0266       0.0347        0.107     0.000298\n",
            "     97   320      0.00296       0.0027     0.000267       0.0327       0.0446         5.05        0.014\n",
            "     97   330      0.00198      0.00195     3.47e-05       0.0285       0.0379         1.82      0.00506\n",
            "     97   340      0.00162      0.00162     1.36e-07       0.0266       0.0345        0.114     0.000316\n",
            "     97   350      0.00199      0.00196     2.68e-05       0.0293        0.038          1.6      0.00445\n",
            "     97   360      0.00244      0.00233     0.000108       0.0314       0.0414         3.21      0.00892\n",
            "     97   370      0.00172      0.00171     8.38e-06       0.0271       0.0355        0.895      0.00249\n",
            "     97   380      0.00255      0.00252     2.42e-05        0.033       0.0431         1.52      0.00422\n",
            "     97   390      0.00213      0.00191      0.00022       0.0285       0.0376         4.59       0.0127\n",
            "     97   400      0.00273      0.00259     0.000138       0.0332       0.0437         3.63       0.0101\n",
            "     97   410      0.00202      0.00202     2.15e-06       0.0297       0.0386        0.453      0.00126\n",
            "     97   420      0.00192      0.00192     9.61e-06       0.0292       0.0376        0.959      0.00266\n",
            "     97   430      0.00188      0.00188      1.1e-06       0.0289       0.0372        0.325     0.000902\n",
            "     97   440      0.00197      0.00176     0.000207       0.0276        0.036         4.45       0.0124\n",
            "     97   450      0.00227      0.00202     0.000248       0.0296       0.0386         4.87       0.0135\n",
            "     97   460      0.00209      0.00202     7.68e-05       0.0297       0.0386         2.71      0.00753\n",
            "     97   470      0.00185      0.00178     6.66e-05       0.0281       0.0363         2.52      0.00701\n",
            "     97   480      0.00169      0.00163     5.16e-05       0.0263       0.0347         2.22      0.00617\n",
            "     97   490      0.00209      0.00209     7.33e-06       0.0301       0.0392        0.837      0.00233\n",
            "     97   500      0.00168      0.00166     1.98e-05       0.0265        0.035         1.38      0.00382\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     97    10       0.0018       0.0018     4.11e-06       0.0276       0.0364        0.471      0.00131\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              97 12733.169    0.004      0.00194     5.39e-05      0.00199       0.0286       0.0378         1.83      0.00509\n",
            "! Validation         97 12733.169    0.004      0.00171     7.53e-06      0.00171       0.0266       0.0355         0.66      0.00183\n",
            "Wall time: 12733.169202275\n",
            "! Best model       97    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     98    10      0.00178      0.00177     1.66e-06       0.0272       0.0362        0.398      0.00111\n",
            "     98    20      0.00172      0.00168     3.98e-05       0.0273       0.0352         1.95      0.00542\n",
            "     98    30      0.00184      0.00183     1.02e-05        0.028       0.0367        0.987      0.00274\n",
            "     98    40      0.00131      0.00128     3.12e-05       0.0239       0.0308         1.73       0.0048\n",
            "     98    50      0.00189      0.00183     5.31e-05       0.0278       0.0368         2.25      0.00626\n",
            "     98    60      0.00184      0.00184     9.26e-08       0.0281       0.0369       0.0941     0.000261\n",
            "     98    70      0.00186      0.00174     0.000123       0.0277       0.0358         3.43      0.00953\n",
            "     98    80      0.00138      0.00136     1.36e-05       0.0244       0.0317         1.14      0.00316\n",
            "     98    90      0.00197      0.00196     8.63e-06       0.0291        0.038        0.908      0.00252\n",
            "     98   100      0.00209      0.00206     2.68e-05       0.0284        0.039          1.6      0.00445\n",
            "     98   110      0.00303      0.00292     0.000108       0.0346       0.0464         3.22      0.00895\n",
            "     98   120      0.00204      0.00193     0.000108       0.0294       0.0377         3.21      0.00893\n",
            "     98   130      0.00184      0.00167     0.000174       0.0266       0.0351         4.08       0.0113\n",
            "     98   140      0.00174      0.00174     2.07e-06       0.0273       0.0358        0.445      0.00124\n",
            "     98   150      0.00167      0.00165     1.84e-05       0.0268       0.0349         1.33      0.00369\n",
            "     98   160      0.00147      0.00147     7.47e-07       0.0251       0.0329        0.267     0.000742\n",
            "     98   170      0.00138      0.00135     3.83e-05       0.0242       0.0315         1.91      0.00532\n",
            "     98   180      0.00191      0.00182     8.48e-05       0.0273       0.0366         2.85      0.00791\n",
            "     98   190      0.00184       0.0018     3.37e-05        0.028       0.0365         1.79      0.00499\n",
            "     98   200      0.00157      0.00157     8.16e-06       0.0258        0.034        0.883      0.00245\n",
            "     98   210      0.00162       0.0014     0.000219       0.0248       0.0321         4.57       0.0127\n",
            "     98   220      0.00157      0.00154     2.85e-05       0.0257       0.0337         1.65      0.00459\n",
            "     98   230      0.00176      0.00175      1.2e-05       0.0269       0.0359         1.07      0.00298\n",
            "     98   240       0.0022      0.00218     2.08e-05       0.0309       0.0401         1.41      0.00392\n",
            "     98   250      0.00243      0.00239     3.93e-05       0.0323        0.042         1.94      0.00538\n",
            "     98   260       0.0015       0.0015     2.46e-06       0.0256       0.0332        0.485      0.00135\n",
            "     98   270      0.00215      0.00214      1.3e-05       0.0297       0.0397         1.11      0.00309\n",
            "     98   280      0.00206      0.00192     0.000143       0.0271       0.0376          3.7       0.0103\n",
            "     98   290      0.00156      0.00156     2.08e-06       0.0257       0.0339        0.446      0.00124\n",
            "     98   300       0.0017      0.00164     6.31e-05       0.0264       0.0348         2.46      0.00682\n",
            "     98   310      0.00202       0.0019     0.000122       0.0285       0.0374         3.41      0.00948\n",
            "     98   320      0.00185      0.00161     0.000239       0.0267       0.0345         4.78       0.0133\n",
            "     98   330      0.00203      0.00193     0.000101       0.0289       0.0378          3.1      0.00862\n",
            "     98   340      0.00201        0.002      9.1e-06       0.0293       0.0384        0.933      0.00259\n",
            "     98   350      0.00186      0.00174      0.00012        0.028       0.0358         3.39      0.00941\n",
            "     98   360      0.00231      0.00226     4.75e-05       0.0305       0.0408         2.13      0.00592\n",
            "     98   370      0.00152      0.00138     0.000144       0.0245       0.0319         3.71       0.0103\n",
            "     98   380      0.00173      0.00173      2.7e-07       0.0268       0.0357        0.161     0.000446\n",
            "     98   390      0.00177      0.00165     0.000113       0.0267       0.0349         3.29      0.00915\n",
            "     98   400      0.00201      0.00183     0.000177       0.0285       0.0368         4.12       0.0114\n",
            "     98   410      0.00132      0.00132     1.39e-06       0.0242       0.0312        0.364      0.00101\n",
            "     98   420      0.00193      0.00176     0.000171       0.0278        0.036         4.04       0.0112\n",
            "     98   430      0.00181      0.00171     0.000101       0.0266       0.0355          3.1      0.00862\n",
            "     98   440      0.00208      0.00206     1.81e-05       0.0294        0.039         1.32      0.00366\n",
            "     98   450      0.00161      0.00158     3.32e-05       0.0264       0.0341         1.78      0.00495\n",
            "     98   460      0.00137      0.00137     1.37e-06       0.0247       0.0318        0.362      0.00101\n",
            "     98   470      0.00221      0.00216     4.39e-05       0.0295       0.0399         2.05      0.00569\n",
            "     98   480      0.00194      0.00193     1.16e-05       0.0274       0.0377         1.05      0.00293\n",
            "     98   490      0.00206      0.00206     2.43e-06       0.0294        0.039        0.482      0.00134\n",
            "     98   500      0.00136      0.00135     6.19e-06       0.0242       0.0316        0.769      0.00214\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     98    10       0.0018      0.00179     4.02e-06       0.0276       0.0364        0.461      0.00128\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              98 12864.415    0.004      0.00184     5.32e-05      0.00189       0.0279       0.0368          1.8        0.005\n",
            "! Validation         98 12864.415    0.004       0.0017      7.6e-06      0.00171       0.0266       0.0354        0.657      0.00183\n",
            "Wall time: 12864.415774885\n",
            "! Best model       98    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     99    10      0.00224      0.00222     1.55e-05       0.0314       0.0405         1.22      0.00338\n",
            "     99    20      0.00159      0.00152      6.2e-05       0.0258       0.0335         2.43      0.00676\n",
            "     99    30      0.00183      0.00163     0.000199       0.0269       0.0347         4.36       0.0121\n",
            "     99    40      0.00191      0.00186      4.8e-05       0.0283        0.037         2.14      0.00595\n",
            "     99    50      0.00175      0.00175     3.32e-06       0.0277       0.0359        0.564      0.00157\n",
            "     99    60      0.00207      0.00205     1.88e-05       0.0298       0.0389         1.34      0.00372\n",
            "     99    70      0.00165      0.00165     4.76e-06       0.0267       0.0349        0.675      0.00187\n",
            "     99    80      0.00184      0.00183     1.24e-05       0.0286       0.0368         1.09      0.00302\n",
            "     99    90      0.00157      0.00157     1.41e-06       0.0258        0.034        0.367      0.00102\n",
            "     99   100      0.00205      0.00204     7.95e-06         0.03       0.0388        0.872      0.00242\n",
            "     99   110      0.00246      0.00222     0.000235       0.0306       0.0405         4.74       0.0132\n",
            "     99   120      0.00228      0.00226     1.69e-05       0.0312       0.0408         1.27      0.00353\n",
            "     99   130       0.0018       0.0018     9.75e-08       0.0286       0.0365       0.0966     0.000268\n",
            "     99   140      0.00204      0.00204     4.17e-06         0.03       0.0388        0.632      0.00175\n",
            "     99   150      0.00189      0.00183     6.02e-05       0.0278       0.0368          2.4      0.00666\n",
            "     99   160      0.00171      0.00161     9.48e-05        0.027       0.0345         3.01      0.00836\n",
            "     99   170       0.0014      0.00139     1.27e-05       0.0251        0.032          1.1      0.00306\n",
            "     99   180      0.00251      0.00249     1.55e-05        0.032       0.0429         1.22      0.00338\n",
            "     99   190      0.00197      0.00194      2.9e-05       0.0286       0.0378         1.66      0.00462\n",
            "     99   200      0.00192      0.00191     2.65e-06       0.0289       0.0376        0.504       0.0014\n",
            "     99   210      0.00158      0.00157     1.75e-05       0.0265        0.034         1.29      0.00359\n",
            "     99   220      0.00174      0.00161     0.000126       0.0267       0.0345         3.46      0.00962\n",
            "     99   230      0.00146      0.00144      1.8e-05       0.0252       0.0326         1.31      0.00364\n",
            "     99   240      0.00218      0.00218     3.34e-08       0.0308       0.0401       0.0565     0.000157\n",
            "     99   250      0.00168      0.00167     9.04e-06       0.0272       0.0351        0.929      0.00258\n",
            "     99   260       0.0018      0.00175     5.05e-05       0.0279       0.0359          2.2       0.0061\n",
            "     99   270      0.00238      0.00237     8.82e-06       0.0316       0.0418        0.918      0.00255\n",
            "     99   280      0.00223      0.00219     4.44e-05       0.0303       0.0401         2.06      0.00572\n",
            "     99   290      0.00199      0.00198      7.7e-06       0.0288       0.0382        0.858      0.00238\n",
            "     99   300      0.00172       0.0017     1.92e-05       0.0273       0.0354         1.35      0.00376\n",
            "     99   310      0.00274      0.00273     1.02e-05       0.0338       0.0448        0.986      0.00274\n",
            "     99   320       0.0018      0.00179     1.18e-05       0.0275       0.0364         1.06      0.00295\n",
            "     99   330      0.00183      0.00179        4e-05       0.0274       0.0364         1.95      0.00543\n",
            "     99   340      0.00135      0.00133     1.77e-05       0.0245       0.0313          1.3      0.00362\n",
            "     99   350      0.00213      0.00211     1.93e-05       0.0293       0.0395         1.36      0.00378\n",
            "     99   360      0.00134      0.00128     5.81e-05       0.0239       0.0307         2.36      0.00655\n",
            "     99   370      0.00176      0.00176     2.51e-06       0.0275        0.036         0.49      0.00136\n",
            "     99   380      0.00223      0.00204     0.000197       0.0296       0.0388         4.34       0.0121\n",
            "     99   390      0.00236      0.00234     1.81e-05       0.0313       0.0416         1.31      0.00365\n",
            "     99   400      0.00192      0.00191     1.04e-05       0.0283       0.0376        0.997      0.00277\n",
            "     99   410      0.00221       0.0022     1.15e-05       0.0302       0.0403         1.05      0.00291\n",
            "     99   420       0.0018      0.00179     7.83e-06        0.028       0.0363        0.865       0.0024\n",
            "     99   430      0.00163       0.0016      3.2e-05       0.0259       0.0343         1.75      0.00486\n",
            "     99   440       0.0021      0.00202     8.05e-05       0.0292       0.0386         2.77       0.0077\n",
            "     99   450      0.00153      0.00153     2.87e-08       0.0252       0.0335       0.0524     0.000145\n",
            "     99   460       0.0018      0.00179     1.37e-05       0.0273       0.0363         1.14      0.00318\n",
            "     99   470      0.00164       0.0014     0.000234       0.0248       0.0322         4.73       0.0131\n",
            "     99   480      0.00233      0.00233     2.88e-06       0.0314       0.0414        0.525      0.00146\n",
            "     99   490      0.00174      0.00168     6.16e-05       0.0274       0.0352         2.43      0.00674\n",
            "     99   500      0.00203      0.00178     0.000256       0.0278       0.0362         4.95       0.0138\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "     99    10      0.00179      0.00178     4.14e-06       0.0275       0.0363        0.477      0.00132\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train              99 12995.434    0.004      0.00187     3.99e-05      0.00191       0.0282       0.0372         1.55      0.00432\n",
            "! Validation         99 12995.434    0.004      0.00169     7.58e-06       0.0017       0.0265       0.0353        0.666      0.00185\n",
            "Wall time: 12995.434086321\n",
            "! Best model       99    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "    100    10      0.00164      0.00162     1.58e-05       0.0264       0.0346         1.23      0.00342\n",
            "    100    20      0.00187      0.00187      3.7e-06       0.0282       0.0371        0.595      0.00165\n",
            "    100    30      0.00286      0.00283     2.13e-05       0.0334       0.0457         1.43      0.00396\n",
            "    100    40      0.00153      0.00151     2.49e-05       0.0254       0.0333         1.54      0.00429\n",
            "    100    50      0.00176      0.00166     0.000101       0.0271        0.035          3.1      0.00861\n",
            "    100    60      0.00293      0.00292      1.4e-05       0.0345       0.0464         1.16      0.00322\n",
            "    100    70      0.00175      0.00175     6.13e-06       0.0268       0.0359        0.765      0.00213\n",
            "    100    80      0.00181      0.00179     1.58e-05       0.0272       0.0364         1.23      0.00341\n",
            "    100    90      0.00151      0.00146     5.59e-05        0.026       0.0328         2.31      0.00642\n",
            "    100   100      0.00224      0.00224     1.71e-06       0.0315       0.0406        0.405      0.00112\n",
            "    100   110       0.0019       0.0019     9.72e-07       0.0288       0.0374        0.305     0.000847\n",
            "    100   120      0.00222       0.0022     2.42e-05       0.0305       0.0403         1.52      0.00423\n",
            "    100   130      0.00138      0.00138     1.16e-06       0.0244       0.0319        0.332     0.000923\n",
            "    100   140      0.00168      0.00151      0.00017       0.0254       0.0334         4.04       0.0112\n",
            "    100   150      0.00154       0.0015     3.81e-05       0.0255       0.0333         1.91       0.0053\n",
            "    100   160      0.00177      0.00167     0.000105       0.0268       0.0351         3.16      0.00879\n",
            "    100   170       0.0017      0.00157     0.000132       0.0255       0.0341         3.56      0.00988\n",
            "    100   180      0.00182      0.00182     4.25e-06       0.0281       0.0366        0.638      0.00177\n",
            "    100   190      0.00227      0.00227     1.65e-06       0.0314       0.0409        0.397       0.0011\n",
            "    100   200      0.00205      0.00185     0.000199       0.0277       0.0369         4.36       0.0121\n",
            "    100   210      0.00146      0.00144     1.31e-05       0.0251       0.0326         1.12      0.00311\n",
            "    100   220      0.00141      0.00135      5.9e-05       0.0246       0.0316         2.37      0.00659\n",
            "    100   230      0.00193      0.00185     8.08e-05       0.0279       0.0369         2.78      0.00772\n",
            "    100   240      0.00231      0.00231     9.52e-09       0.0312       0.0413       0.0302     8.38e-05\n",
            "    100   250      0.00181      0.00181     1.33e-07       0.0278       0.0366        0.113     0.000313\n",
            "    100   260      0.00206      0.00205      9.1e-06       0.0295       0.0389        0.933      0.00259\n",
            "    100   270      0.00154      0.00145     9.02e-05       0.0251       0.0327         2.94      0.00816\n",
            "    100   280      0.00197      0.00185     0.000119       0.0285        0.037         3.38      0.00939\n",
            "    100   290      0.00217       0.0021     6.71e-05         0.03       0.0394         2.53      0.00704\n",
            "    100   300       0.0018      0.00178     1.89e-05       0.0282       0.0362         1.34      0.00373\n",
            "    100   310      0.00171      0.00165     5.88e-05       0.0266       0.0349         2.37      0.00659\n",
            "    100   320       0.0019      0.00188      1.7e-05       0.0291       0.0373         1.28      0.00354\n",
            "    100   330      0.00227      0.00221        6e-05       0.0305       0.0404         2.39      0.00665\n",
            "    100   340      0.00233      0.00232     1.18e-05       0.0311       0.0414         1.06      0.00295\n",
            "    100   350      0.00251      0.00247     4.21e-05       0.0323       0.0426         2.01      0.00557\n",
            "    100   360      0.00236      0.00234     1.54e-05       0.0314       0.0416         1.21      0.00337\n",
            "    100   370      0.00247      0.00244     2.92e-05       0.0319       0.0424         1.67      0.00464\n",
            "    100   380      0.00221      0.00195     0.000258       0.0297       0.0379         4.97       0.0138\n",
            "    100   390      0.00198      0.00192     6.62e-05       0.0286       0.0376         2.52      0.00699\n",
            "    100   400       0.0017      0.00164     5.83e-05       0.0266       0.0348         2.36      0.00656\n",
            "    100   410      0.00191      0.00165     0.000267       0.0264       0.0348         5.05        0.014\n",
            "    100   420      0.00196      0.00195     1.06e-05       0.0292       0.0379            1      0.00279\n",
            "    100   430      0.00267      0.00267     2.57e-06       0.0336       0.0443        0.496      0.00138\n",
            "    100   440      0.00214      0.00208     5.42e-05       0.0299       0.0392         2.28      0.00632\n",
            "    100   450      0.00178      0.00176     2.49e-05       0.0273        0.036         1.54      0.00429\n",
            "    100   460      0.00156       0.0014     0.000155        0.025       0.0322         3.85       0.0107\n",
            "    100   470      0.00179       0.0017     9.43e-05       0.0272       0.0354            3      0.00834\n",
            "    100   480      0.00197      0.00182      0.00015       0.0273       0.0367         3.78       0.0105\n",
            "    100   490      0.00167      0.00167     1.34e-06        0.027       0.0351        0.357     0.000993\n",
            "    100   500      0.00174      0.00174     2.79e-06       0.0276       0.0358        0.516      0.00143\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse        e_mae      e/N_mae\n",
            "    100    10      0.00179      0.00179     4.77e-06       0.0275       0.0363        0.539       0.0015\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse        e_mae      e/N_mae\n",
            "! Train             100 13126.665    0.004      0.00188     5.38e-05      0.00194       0.0282       0.0373         1.84      0.00511\n",
            "! Validation        100 13126.665    0.004      0.00169     7.72e-06       0.0017       0.0265       0.0353        0.696      0.00193\n",
            "Wall time: 13126.664948483\n",
            "! Best model      100    0.002\n",
            "! Stop training: max epochs\n",
            "Wall time: 13126.682649339\n",
            "Cumulative wall time: 13126.682649339\n"
          ]
        }
      ],
      "source": [
        "!rm -rf ./results\n",
        "\n",
        "Model='Allegro'\n",
        "\n",
        "if Model=='Allegro':\n",
        "  !nequip-train allegro/configs/allegro-water-gra.yaml  --equivariance-test\n",
        "elif Model=='NequIP':\n",
        "  !nequip-train nequip_train/water-gra.yaml --equivariance-test\n",
        "else:\n",
        "  print(\"Model has to be either Allegro or NequIP\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nequip-train --help"
      ],
      "metadata": {
        "id": "RnqHooUBoIjg",
        "outputId": "b521cd1f-9f11-4373-9674-12842b196993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: nequip-train\n",
            "       [-h]\n",
            "       [--equivariance-test [EQUIVARIANCE_TEST]]\n",
            "       [--model-debug-mode]\n",
            "       [--grad-anomaly-mode]\n",
            "       [--log LOG]\n",
            "       config\n",
            "\n",
            "Train (or\n",
            "restart\n",
            "training\n",
            "of) a\n",
            "NequIP\n",
            "model.\n",
            "\n",
            "positional arguments:\n",
            "  config\n",
            "    YAML file\n",
            "    configuring\n",
            "    the model,\n",
            "    dataset,\n",
            "    and other\n",
            "    options\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --equivariance-test [EQUIVARIANCE_TEST]\n",
            "    test the\n",
            "    model's equ\n",
            "    ivariance\n",
            "    before\n",
            "    training on\n",
            "    n (default\n",
            "    1) random\n",
            "    frames from\n",
            "    the dataset\n",
            "  --model-debug-mode\n",
            "    enable\n",
            "    model debug\n",
            "    mode, which\n",
            "    can\n",
            "    sometimes\n",
            "    give much\n",
            "    more useful\n",
            "    error\n",
            "    messages at\n",
            "    the cost of\n",
            "    some speed.\n",
            "    Do not use\n",
            "    for\n",
            "    production\n",
            "    training!\n",
            "  --grad-anomaly-mode\n",
            "    enable\n",
            "    PyTorch\n",
            "    autograd\n",
            "    anomaly\n",
            "    mode to\n",
            "    debug NaN\n",
            "    gradients.\n",
            "    Do not use\n",
            "    for\n",
            "    production\n",
            "    training!\n",
            "  --log LOG\n",
            "    log file to\n",
            "    store all\n",
            "    the screen\n",
            "    logging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the test error\n",
        "##### We get rather small errors in the forces of ~50 meV/A"
      ],
      "metadata": {
        "id": "Wev2u1UyrVCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nequip-evaluate --train-dir results/water-gra-film/water-gra-film --batch-size 10"
      ],
      "metadata": {
        "id": "KlEaWYSgrXtr",
        "outputId": "fd17adb5-ee03-4228-df8d-d0e1fe2dac5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`\n",
            "Loading model... \n",
            "loaded model from training session\n",
            "Loading original dataset...\n",
            "Loaded dataset specified in config.yaml.\n",
            "Using origial training dataset (5793 frames) minus training (500 frames) and validation frames (50 frames), yielding a test set size of 5243 frames.\n",
            "Starting...\n",
            "  0% 0/5243 [00:00<?, ?it/s]\n",
            "\u001b[A\n",
            "  0% 10/5243 [00:01<12:44,  6.84it/s]\n",
            "  0% 20/5243 [00:02<12:08,  7.17it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:276: UserWarning: operator() profile_node %884 : int[] = prim::profile_ivalue(%882)\n",
            " does not have profile information (Triggered internally at  ../torch/csrc/jit/codegen/cuda/graph_fuser.cpp:108.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "\n",
            "  1% 30/5243 [00:09<33:30,  2.59it/s]\n",
            "  1% 40/5243 [00:10<23:52,  3.63it/s]\n",
            "  1% 50/5243 [00:11<18:08,  4.77it/s]\n",
            "  1% 60/5243 [00:12<14:40,  5.88it/s]\n",
            "  1% 70/5243 [00:13<12:30,  6.89it/s]\n",
            "  2% 80/5243 [00:14<11:07,  7.74it/s]\n",
            "  2% 90/5243 [00:15<10:13,  8.39it/s]\n",
            "  2% 100/5243 [00:16<09:34,  8.95it/s]\n",
            "  2% 110/5243 [00:17<09:06,  9.40it/s]\n",
            "  2% 120/5243 [00:18<08:45,  9.74it/s]\n",
            "  2% 130/5243 [00:19<08:32,  9.98it/s]\n",
            "  3% 140/5243 [00:20<08:23, 10.13it/s]\n",
            "  3% 150/5243 [00:21<08:19, 10.20it/s]\n",
            "  3% 160/5243 [00:22<08:15, 10.27it/s]\n",
            "  3% 170/5243 [00:23<08:12, 10.30it/s]\n",
            "  3% 180/5243 [00:24<08:31,  9.90it/s]\n",
            "  4% 190/5243 [00:25<08:26,  9.98it/s]\n",
            "  4% 200/5243 [00:26<08:22, 10.04it/s]\n",
            "  4% 210/5243 [00:27<08:18, 10.10it/s]\n",
            "  4% 220/5243 [00:28<08:15, 10.13it/s]\n",
            "  4% 230/5243 [00:28<08:12, 10.19it/s]\n",
            "  5% 240/5243 [00:29<08:09, 10.22it/s]\n",
            "  5% 250/5243 [00:30<08:07, 10.24it/s]\n",
            "  5% 260/5243 [00:31<08:05, 10.26it/s]\n",
            "  5% 270/5243 [00:32<08:04, 10.27it/s]\n",
            "  5% 280/5243 [00:33<08:01, 10.30it/s]\n",
            "  6% 290/5243 [00:34<08:00, 10.31it/s]\n",
            "  6% 300/5243 [00:35<07:59, 10.30it/s]\n",
            "  6% 310/5243 [00:36<07:59, 10.29it/s]\n",
            "  6% 320/5243 [00:37<08:00, 10.25it/s]\n",
            "  6% 330/5243 [00:38<07:59, 10.24it/s]\n",
            "  6% 340/5243 [00:39<07:57, 10.26it/s]\n",
            "  7% 350/5243 [00:40<07:54, 10.31it/s]\n",
            "  7% 360/5243 [00:41<07:50, 10.38it/s]\n",
            "  7% 370/5243 [00:42<07:49, 10.38it/s]\n",
            "  7% 380/5243 [00:43<07:50, 10.33it/s]\n",
            "  7% 390/5243 [00:44<07:52, 10.27it/s]\n",
            "  8% 400/5243 [00:45<07:51, 10.28it/s]\n",
            "  8% 410/5243 [00:46<07:48, 10.32it/s]\n",
            "  8% 420/5243 [00:47<07:43, 10.40it/s]\n",
            "  8% 430/5243 [00:48<07:40, 10.45it/s]\n",
            "  8% 440/5243 [00:49<07:39, 10.46it/s]\n",
            "  9% 450/5243 [00:50<07:37, 10.47it/s]\n",
            "  9% 460/5243 [00:51<07:36, 10.48it/s]\n",
            "  9% 470/5243 [00:52<07:35, 10.48it/s]\n",
            "  9% 480/5243 [00:53<07:35, 10.46it/s]\n",
            "  9% 490/5243 [00:54<07:35, 10.43it/s]\n",
            " 10% 500/5243 [00:55<07:36, 10.40it/s]\n",
            " 10% 510/5243 [00:56<07:37, 10.35it/s]\n",
            " 10% 520/5243 [00:57<07:37, 10.32it/s]\n",
            " 10% 530/5243 [00:57<07:36, 10.33it/s]\n",
            " 10% 540/5243 [00:58<07:34, 10.35it/s]\n",
            " 10% 550/5243 [00:59<07:34, 10.33it/s]\n",
            " 11% 560/5243 [01:00<07:34, 10.30it/s]\n",
            " 11% 570/5243 [01:01<07:34, 10.28it/s]\n",
            " 11% 580/5243 [01:02<07:33, 10.27it/s]\n",
            " 11% 590/5243 [01:03<07:33, 10.26it/s]\n",
            " 11% 600/5243 [01:04<07:32, 10.26it/s]\n",
            " 12% 610/5243 [01:05<07:30, 10.28it/s]\n",
            " 12% 620/5243 [01:06<07:28, 10.30it/s]\n",
            " 12% 630/5243 [01:07<07:26, 10.33it/s]\n",
            " 12% 640/5243 [01:08<07:23, 10.38it/s]\n",
            " 12% 650/5243 [01:09<07:19, 10.44it/s]\n",
            " 13% 660/5243 [01:10<07:18, 10.46it/s]\n",
            " 13% 670/5243 [01:11<07:18, 10.42it/s]\n",
            " 13% 680/5243 [01:12<07:18, 10.39it/s]\n",
            " 13% 690/5243 [01:13<07:18, 10.39it/s]\n",
            " 13% 700/5243 [01:14<07:16, 10.41it/s]\n",
            " 14% 710/5243 [01:15<07:14, 10.43it/s]\n",
            " 14% 720/5243 [01:16<07:13, 10.44it/s]\n",
            " 14% 730/5243 [01:17<07:11, 10.45it/s]\n",
            " 14% 740/5243 [01:18<07:11, 10.44it/s]\n",
            " 14% 750/5243 [01:19<07:11, 10.42it/s]\n",
            " 14% 760/5243 [01:20<07:09, 10.43it/s]\n",
            " 15% 770/5243 [01:21<07:10, 10.39it/s]\n",
            " 15% 780/5243 [01:22<07:27,  9.97it/s]\n",
            " 15% 790/5243 [01:23<07:22, 10.06it/s]\n",
            " 15% 800/5243 [01:24<07:16, 10.18it/s]\n",
            " 15% 810/5243 [01:25<07:11, 10.28it/s]\n",
            " 16% 820/5243 [01:26<07:07, 10.34it/s]\n",
            " 16% 830/5243 [01:27<07:06, 10.34it/s]\n",
            " 16% 840/5243 [01:27<07:07, 10.31it/s]\n",
            " 16% 850/5243 [01:28<07:07, 10.29it/s]\n",
            " 16% 860/5243 [01:29<07:06, 10.28it/s]\n",
            " 17% 870/5243 [01:30<07:03, 10.34it/s]\n",
            " 17% 880/5243 [01:31<07:00, 10.37it/s]\n",
            " 17% 890/5243 [01:32<06:59, 10.37it/s]\n",
            " 17% 900/5243 [01:33<07:00, 10.33it/s]\n",
            " 17% 910/5243 [01:34<07:00, 10.31it/s]\n",
            " 18% 920/5243 [01:35<06:57, 10.35it/s]\n",
            " 18% 930/5243 [01:36<06:54, 10.40it/s]\n",
            " 18% 940/5243 [01:37<06:52, 10.44it/s]\n",
            " 18% 950/5243 [01:38<06:51, 10.42it/s]\n",
            " 18% 960/5243 [01:39<06:52, 10.39it/s]\n",
            " 19% 970/5243 [01:40<06:52, 10.36it/s]\n",
            " 19% 980/5243 [01:41<06:51, 10.37it/s]\n",
            " 19% 990/5243 [01:42<06:49, 10.38it/s]\n",
            " 19% 1000/5243 [01:43<06:49, 10.36it/s]\n",
            " 19% 1010/5243 [01:44<06:49, 10.33it/s]\n",
            " 19% 1020/5243 [01:45<06:49, 10.32it/s]\n",
            " 20% 1030/5243 [01:46<06:46, 10.36it/s]\n",
            " 20% 1040/5243 [01:47<06:43, 10.42it/s]\n",
            " 20% 1050/5243 [01:48<06:41, 10.44it/s]\n",
            " 20% 1060/5243 [01:49<06:39, 10.46it/s]\n",
            " 20% 1070/5243 [01:50<06:40, 10.41it/s]\n",
            " 21% 1080/5243 [01:51<06:41, 10.37it/s]\n",
            " 21% 1090/5243 [01:52<06:39, 10.40it/s]\n",
            " 21% 1100/5243 [01:53<06:35, 10.46it/s]\n",
            " 21% 1110/5243 [01:53<06:33, 10.51it/s]\n",
            " 21% 1120/5243 [01:54<06:32, 10.50it/s]\n",
            " 22% 1130/5243 [01:55<06:33, 10.45it/s]\n",
            " 22% 1140/5243 [01:56<06:33, 10.42it/s]\n",
            " 22% 1150/5243 [01:57<06:31, 10.44it/s]\n",
            " 22% 1160/5243 [01:58<06:30, 10.45it/s]\n",
            " 22% 1170/5243 [01:59<06:28, 10.48it/s]\n",
            " 23% 1180/5243 [02:00<06:26, 10.50it/s]\n",
            " 23% 1190/5243 [02:01<06:26, 10.49it/s]\n",
            " 23% 1200/5243 [02:02<06:26, 10.47it/s]\n",
            " 23% 1210/5243 [02:03<06:26, 10.43it/s]\n",
            " 23% 1220/5243 [02:04<06:26, 10.40it/s]\n",
            " 23% 1230/5243 [02:05<06:26, 10.39it/s]\n",
            " 24% 1240/5243 [02:06<06:24, 10.42it/s]\n",
            " 24% 1250/5243 [02:07<06:20, 10.48it/s]\n",
            " 24% 1260/5243 [02:08<06:18, 10.52it/s]\n",
            " 24% 1270/5243 [02:09<06:16, 10.55it/s]\n",
            " 24% 1280/5243 [02:10<06:15, 10.55it/s]\n",
            " 25% 1290/5243 [02:11<06:16, 10.51it/s]\n",
            " 25% 1300/5243 [02:12<06:16, 10.48it/s]\n",
            " 25% 1310/5243 [02:13<06:17, 10.43it/s]\n",
            " 25% 1320/5243 [02:14<06:17, 10.38it/s]\n",
            " 25% 1330/5243 [02:15<06:18, 10.34it/s]\n",
            " 26% 1340/5243 [02:15<06:17, 10.33it/s]\n",
            " 26% 1350/5243 [02:16<06:14, 10.39it/s]\n",
            " 26% 1360/5243 [02:17<06:11, 10.45it/s]\n",
            " 26% 1370/5243 [02:18<06:10, 10.46it/s]\n",
            " 26% 1380/5243 [02:19<06:09, 10.46it/s]\n",
            " 27% 1390/5243 [02:20<06:09, 10.42it/s]\n",
            " 27% 1400/5243 [02:21<06:10, 10.38it/s]\n",
            " 27% 1410/5243 [02:22<06:09, 10.37it/s]\n",
            " 27% 1420/5243 [02:23<06:06, 10.42it/s]\n",
            " 27% 1430/5243 [02:24<06:04, 10.47it/s]\n",
            " 27% 1440/5243 [02:25<06:02, 10.48it/s]\n",
            " 28% 1450/5243 [02:26<06:03, 10.43it/s]\n",
            " 28% 1460/5243 [02:27<06:03, 10.41it/s]\n",
            " 28% 1470/5243 [02:28<06:02, 10.41it/s]\n",
            " 28% 1480/5243 [02:29<06:00, 10.45it/s]\n",
            " 28% 1490/5243 [02:30<05:58, 10.47it/s]\n",
            " 29% 1500/5243 [02:31<05:57, 10.48it/s]\n",
            " 29% 1510/5243 [02:32<05:54, 10.52it/s]\n",
            " 29% 1520/5243 [02:33<05:51, 10.60it/s]\n",
            " 29% 1530/5243 [02:34<05:47, 10.68it/s]\n",
            " 29% 1540/5243 [02:34<05:44, 10.74it/s]\n",
            " 30% 1550/5243 [02:35<05:44, 10.73it/s]\n",
            " 30% 1560/5243 [02:36<05:44, 10.68it/s]\n",
            " 30% 1570/5243 [02:37<05:46, 10.61it/s]\n",
            " 30% 1580/5243 [02:38<05:47, 10.54it/s]\n",
            " 30% 1590/5243 [02:39<05:45, 10.58it/s]\n",
            " 31% 1600/5243 [02:40<05:41, 10.67it/s]\n",
            " 31% 1610/5243 [02:41<05:37, 10.75it/s]\n",
            " 31% 1620/5243 [02:42<05:35, 10.81it/s]\n",
            " 31% 1630/5243 [02:43<05:35, 10.77it/s]\n",
            " 31% 1640/5243 [02:44<05:37, 10.68it/s]\n",
            " 31% 1650/5243 [02:45<05:38, 10.61it/s]\n",
            " 32% 1660/5243 [02:46<05:37, 10.62it/s]\n",
            " 32% 1670/5243 [02:47<05:35, 10.65it/s]\n",
            " 32% 1680/5243 [02:48<05:36, 10.60it/s]\n",
            " 32% 1690/5243 [02:49<05:37, 10.52it/s]\n",
            " 32% 1700/5243 [02:50<05:38, 10.46it/s]\n",
            " 33% 1710/5243 [02:51<05:37, 10.46it/s]\n",
            " 33% 1720/5243 [02:51<05:34, 10.52it/s]\n",
            " 33% 1730/5243 [02:52<05:31, 10.60it/s]\n",
            " 33% 1740/5243 [02:53<05:29, 10.64it/s]\n",
            " 33% 1750/5243 [02:54<05:28, 10.62it/s]\n",
            " 34% 1760/5243 [02:55<05:30, 10.54it/s]\n",
            " 34% 1770/5243 [02:56<05:31, 10.49it/s]\n",
            " 34% 1780/5243 [02:57<05:30, 10.49it/s]\n",
            " 34% 1790/5243 [02:58<05:28, 10.52it/s]\n",
            " 34% 1800/5243 [02:59<05:25, 10.57it/s]\n",
            " 35% 1810/5243 [03:00<05:23, 10.61it/s]\n",
            " 35% 1820/5243 [03:01<05:22, 10.60it/s]\n",
            " 35% 1830/5243 [03:02<05:23, 10.55it/s]\n",
            " 35% 1840/5243 [03:03<05:23, 10.53it/s]\n",
            " 35% 1850/5243 [03:04<05:21, 10.55it/s]\n",
            " 35% 1860/5243 [03:05<05:20, 10.55it/s]\n",
            " 36% 1870/5243 [03:06<05:20, 10.51it/s]\n",
            " 36% 1880/5243 [03:07<05:21, 10.48it/s]\n",
            " 36% 1890/5243 [03:08<05:21, 10.42it/s]\n",
            " 36% 1900/5243 [03:09<05:21, 10.39it/s]\n",
            " 36% 1910/5243 [03:10<05:20, 10.39it/s]\n",
            " 37% 1920/5243 [03:11<05:19, 10.42it/s]\n",
            " 37% 1930/5243 [03:11<05:16, 10.46it/s]\n",
            " 37% 1940/5243 [03:12<05:14, 10.51it/s]\n",
            " 37% 1950/5243 [03:13<05:12, 10.55it/s]\n",
            " 37% 1960/5243 [03:14<05:11, 10.54it/s]\n",
            " 38% 1970/5243 [03:15<05:11, 10.50it/s]\n",
            " 38% 1980/5243 [03:16<05:11, 10.47it/s]\n",
            " 38% 1990/5243 [03:17<05:10, 10.49it/s]\n",
            " 38% 2000/5243 [03:18<05:07, 10.54it/s]\n",
            " 38% 2010/5243 [03:19<05:06, 10.55it/s]\n",
            " 39% 2020/5243 [03:20<05:06, 10.52it/s]\n",
            " 39% 2030/5243 [03:21<05:06, 10.48it/s]\n",
            " 39% 2040/5243 [03:22<05:06, 10.46it/s]\n",
            " 39% 2050/5243 [03:23<05:07, 10.39it/s]\n",
            " 39% 2060/5243 [03:24<05:07, 10.35it/s]\n",
            " 39% 2070/5243 [03:25<05:06, 10.35it/s]\n",
            " 40% 2080/5243 [03:26<05:04, 10.38it/s]\n",
            " 40% 2090/5243 [03:27<05:01, 10.45it/s]\n",
            " 40% 2100/5243 [03:28<05:00, 10.47it/s]\n",
            " 40% 2110/5243 [03:29<04:59, 10.46it/s]\n",
            " 40% 2120/5243 [03:30<04:58, 10.45it/s]\n",
            " 41% 2130/5243 [03:31<04:57, 10.46it/s]\n",
            " 41% 2140/5243 [03:32<04:56, 10.46it/s]\n",
            " 41% 2150/5243 [03:32<04:55, 10.48it/s]\n",
            " 41% 2160/5243 [03:33<04:53, 10.51it/s]\n",
            " 41% 2170/5243 [03:34<04:52, 10.52it/s]\n",
            " 42% 2180/5243 [03:35<04:52, 10.47it/s]\n",
            " 42% 2190/5243 [03:36<04:53, 10.41it/s]\n",
            " 42% 2200/5243 [03:37<04:54, 10.34it/s]\n",
            " 42% 2210/5243 [03:38<04:54, 10.31it/s]\n",
            " 42% 2220/5243 [03:39<04:53, 10.31it/s]\n",
            " 43% 2230/5243 [03:40<04:52, 10.30it/s]\n",
            " 43% 2240/5243 [03:41<04:51, 10.31it/s]\n",
            " 43% 2250/5243 [03:42<04:50, 10.32it/s]\n",
            " 43% 2260/5243 [03:43<04:48, 10.34it/s]\n",
            " 43% 2270/5243 [03:44<04:45, 10.41it/s]\n",
            " 43% 2280/5243 [03:45<04:43, 10.45it/s]\n",
            " 44% 2290/5243 [03:46<04:41, 10.48it/s]\n",
            " 44% 2300/5243 [03:47<04:40, 10.50it/s]\n",
            " 44% 2310/5243 [03:48<04:40, 10.47it/s]\n",
            " 44% 2320/5243 [03:49<04:40, 10.41it/s]\n",
            " 44% 2330/5243 [03:50<04:40, 10.37it/s]\n",
            " 45% 2340/5243 [03:51<04:38, 10.42it/s]\n",
            " 45% 2350/5243 [03:52<04:34, 10.53it/s]\n",
            " 45% 2360/5243 [03:53<04:30, 10.64it/s]\n",
            " 45% 2370/5243 [03:54<04:28, 10.68it/s]\n",
            " 45% 2380/5243 [03:54<04:28, 10.67it/s]\n",
            " 46% 2390/5243 [03:55<04:29, 10.58it/s]\n",
            " 46% 2400/5243 [03:56<04:30, 10.52it/s]\n",
            " 46% 2410/5243 [03:57<04:29, 10.49it/s]\n",
            " 46% 2420/5243 [03:58<04:29, 10.49it/s]\n",
            " 46% 2430/5243 [03:59<04:27, 10.50it/s]\n",
            " 47% 2440/5243 [04:00<04:26, 10.50it/s]\n",
            " 47% 2450/5243 [04:01<04:26, 10.50it/s]\n",
            " 47% 2460/5243 [04:02<04:24, 10.50it/s]\n",
            " 47% 2470/5243 [04:03<04:24, 10.49it/s]\n",
            " 47% 2480/5243 [04:04<04:23, 10.48it/s]\n",
            " 47% 2490/5243 [04:05<04:23, 10.45it/s]\n",
            " 48% 2500/5243 [04:06<04:22, 10.45it/s]\n",
            " 48% 2510/5243 [04:07<04:21, 10.47it/s]\n",
            " 48% 2520/5243 [04:08<04:20, 10.46it/s]\n",
            " 48% 2530/5243 [04:09<04:20, 10.43it/s]\n",
            " 48% 2540/5243 [04:10<04:19, 10.41it/s]\n",
            " 49% 2550/5243 [04:11<04:19, 10.39it/s]\n",
            " 49% 2560/5243 [04:12<04:17, 10.42it/s]\n",
            " 49% 2570/5243 [04:13<04:15, 10.46it/s]\n",
            " 49% 2580/5243 [04:14<04:14, 10.48it/s]\n",
            " 49% 2590/5243 [04:15<04:12, 10.49it/s]\n",
            " 50% 2600/5243 [04:16<04:12, 10.45it/s]\n",
            " 50% 2610/5243 [04:16<04:12, 10.42it/s]\n",
            " 50% 2620/5243 [04:17<04:10, 10.46it/s]\n",
            " 50% 2630/5243 [04:18<04:08, 10.50it/s]\n",
            " 50% 2640/5243 [04:19<04:07, 10.51it/s]\n",
            " 51% 2650/5243 [04:20<04:07, 10.49it/s]\n",
            " 51% 2660/5243 [04:21<04:07, 10.44it/s]\n",
            " 51% 2670/5243 [04:22<04:07, 10.40it/s]\n",
            " 51% 2680/5243 [04:23<04:06, 10.38it/s]\n",
            " 51% 2690/5243 [04:24<04:04, 10.42it/s]\n",
            " 51% 2700/5243 [04:25<04:02, 10.48it/s]\n",
            " 52% 2710/5243 [04:26<04:01, 10.51it/s]\n",
            " 52% 2720/5243 [04:27<04:00, 10.51it/s]\n",
            " 52% 2730/5243 [04:28<03:58, 10.52it/s]\n",
            " 52% 2740/5243 [04:29<03:58, 10.50it/s]\n",
            " 52% 2750/5243 [04:30<03:57, 10.49it/s]\n",
            " 53% 2760/5243 [04:31<03:57, 10.44it/s]\n",
            " 53% 2770/5243 [04:32<03:56, 10.44it/s]\n",
            " 53% 2780/5243 [04:33<03:56, 10.43it/s]\n",
            " 53% 2790/5243 [04:34<03:53, 10.49it/s]\n",
            " 53% 2800/5243 [04:35<03:51, 10.56it/s]\n",
            " 54% 2810/5243 [04:36<03:50, 10.56it/s]\n",
            " 54% 2820/5243 [04:37<03:50, 10.50it/s]\n",
            " 54% 2830/5243 [04:37<03:51, 10.42it/s]\n",
            " 54% 2840/5243 [04:38<03:51, 10.38it/s]\n",
            " 54% 2850/5243 [04:39<03:50, 10.38it/s]\n",
            " 55% 2860/5243 [04:40<03:48, 10.43it/s]\n",
            " 55% 2870/5243 [04:41<03:47, 10.44it/s]\n",
            " 55% 2880/5243 [04:42<03:45, 10.47it/s]\n",
            " 55% 2890/5243 [04:43<03:44, 10.46it/s]\n",
            " 55% 2900/5243 [04:44<03:44, 10.45it/s]\n",
            " 56% 2910/5243 [04:45<03:42, 10.47it/s]\n",
            " 56% 2920/5243 [04:46<03:42, 10.46it/s]\n",
            " 56% 2930/5243 [04:47<03:40, 10.47it/s]\n",
            " 56% 2940/5243 [04:48<03:39, 10.50it/s]\n",
            " 56% 2950/5243 [04:49<03:38, 10.49it/s]\n",
            " 56% 2960/5243 [04:50<03:37, 10.49it/s]\n",
            " 57% 2970/5243 [04:51<03:36, 10.51it/s]\n",
            " 57% 2980/5243 [04:52<03:35, 10.51it/s]\n",
            " 57% 2990/5243 [04:53<03:34, 10.50it/s]\n",
            " 57% 3000/5243 [04:54<03:34, 10.48it/s]\n",
            " 57% 3010/5243 [04:55<03:34, 10.41it/s]\n",
            " 58% 3020/5243 [04:56<03:34, 10.38it/s]\n",
            " 58% 3030/5243 [04:57<03:33, 10.38it/s]\n",
            " 58% 3040/5243 [04:58<03:32, 10.39it/s]\n",
            " 58% 3050/5243 [04:59<03:30, 10.40it/s]\n",
            " 58% 3060/5243 [05:00<03:30, 10.39it/s]\n",
            " 59% 3070/5243 [05:00<03:28, 10.42it/s]\n",
            " 59% 3080/5243 [05:01<03:27, 10.43it/s]\n",
            " 59% 3090/5243 [05:02<03:25, 10.46it/s]\n",
            " 59% 3100/5243 [05:03<03:24, 10.48it/s]\n",
            " 59% 3110/5243 [05:04<03:24, 10.45it/s]\n",
            " 60% 3120/5243 [05:05<03:24, 10.37it/s]\n",
            " 60% 3130/5243 [05:06<03:24, 10.32it/s]\n",
            " 60% 3140/5243 [05:07<03:24, 10.29it/s]\n",
            " 60% 3150/5243 [05:08<03:23, 10.31it/s]\n",
            " 60% 3160/5243 [05:09<03:20, 10.40it/s]\n",
            " 60% 3170/5243 [05:10<03:17, 10.50it/s]\n",
            " 61% 3180/5243 [05:11<03:15, 10.56it/s]\n",
            " 61% 3190/5243 [05:12<03:14, 10.56it/s]\n",
            " 61% 3200/5243 [05:13<03:14, 10.53it/s]\n",
            " 61% 3210/5243 [05:14<03:14, 10.47it/s]\n",
            " 61% 3220/5243 [05:15<03:14, 10.41it/s]\n",
            " 62% 3230/5243 [05:16<03:14, 10.37it/s]\n",
            " 62% 3240/5243 [05:17<03:13, 10.36it/s]\n",
            " 62% 3250/5243 [05:18<03:12, 10.36it/s]\n",
            " 62% 3260/5243 [05:19<03:11, 10.37it/s]\n",
            " 62% 3270/5243 [05:20<03:10, 10.37it/s]\n",
            " 63% 3280/5243 [05:21<03:08, 10.41it/s]\n",
            " 63% 3290/5243 [05:22<03:07, 10.41it/s]\n",
            " 63% 3300/5243 [05:23<03:06, 10.40it/s]\n",
            " 63% 3310/5243 [05:24<03:05, 10.41it/s]\n",
            " 63% 3320/5243 [05:24<03:04, 10.42it/s]\n",
            " 64% 3330/5243 [05:25<03:03, 10.44it/s]\n",
            " 64% 3340/5243 [05:26<03:02, 10.44it/s]\n",
            " 64% 3350/5243 [05:27<03:01, 10.41it/s]\n",
            " 64% 3360/5243 [05:28<03:01, 10.37it/s]\n",
            " 64% 3370/5243 [05:29<03:01, 10.33it/s]\n",
            " 64% 3380/5243 [05:30<03:00, 10.32it/s]\n",
            " 65% 3390/5243 [05:31<02:59, 10.33it/s]\n",
            " 65% 3400/5243 [05:32<02:58, 10.34it/s]\n",
            " 65% 3410/5243 [05:33<02:57, 10.31it/s]\n",
            " 65% 3420/5243 [05:34<02:57, 10.30it/s]\n",
            " 65% 3430/5243 [05:35<02:55, 10.31it/s]\n",
            " 66% 3440/5243 [05:36<02:53, 10.37it/s]\n",
            " 66% 3450/5243 [05:37<02:51, 10.44it/s]\n",
            " 66% 3460/5243 [05:38<02:50, 10.48it/s]\n",
            " 66% 3470/5243 [05:39<02:48, 10.51it/s]\n",
            " 66% 3480/5243 [05:40<02:47, 10.51it/s]\n",
            " 67% 3490/5243 [05:41<02:46, 10.51it/s]\n",
            " 67% 3500/5243 [05:42<02:46, 10.50it/s]\n",
            " 67% 3510/5243 [05:43<02:45, 10.50it/s]\n",
            " 67% 3520/5243 [05:44<02:43, 10.51it/s]\n",
            " 67% 3530/5243 [05:45<02:43, 10.50it/s]\n",
            " 68% 3540/5243 [05:46<02:42, 10.45it/s]\n",
            " 68% 3550/5243 [05:47<02:42, 10.43it/s]\n",
            " 68% 3560/5243 [05:48<02:41, 10.42it/s]\n",
            " 68% 3570/5243 [05:48<02:40, 10.43it/s]\n",
            " 68% 3580/5243 [05:49<02:39, 10.44it/s]\n",
            " 68% 3590/5243 [05:50<02:38, 10.45it/s]\n",
            " 69% 3600/5243 [05:51<02:37, 10.46it/s]\n",
            " 69% 3610/5243 [05:52<02:35, 10.48it/s]\n",
            " 69% 3620/5243 [05:53<02:34, 10.47it/s]\n",
            " 69% 3630/5243 [05:54<02:34, 10.44it/s]\n",
            " 69% 3640/5243 [05:55<02:34, 10.41it/s]\n",
            " 70% 3650/5243 [05:56<02:33, 10.39it/s]\n",
            " 70% 3660/5243 [05:57<02:32, 10.40it/s]\n",
            " 70% 3670/5243 [05:58<02:31, 10.41it/s]\n",
            " 70% 3680/5243 [05:59<02:30, 10.41it/s]\n",
            " 70% 3690/5243 [06:00<02:29, 10.42it/s]\n",
            " 71% 3700/5243 [06:01<02:28, 10.39it/s]\n",
            " 71% 3710/5243 [06:02<02:27, 10.38it/s]\n",
            " 71% 3720/5243 [06:03<02:26, 10.40it/s]\n",
            " 71% 3730/5243 [06:04<02:24, 10.44it/s]\n",
            " 71% 3740/5243 [06:05<02:23, 10.44it/s]\n",
            " 72% 3750/5243 [06:06<02:23, 10.42it/s]\n",
            " 72% 3760/5243 [06:07<02:22, 10.39it/s]\n",
            " 72% 3770/5243 [06:08<02:22, 10.36it/s]\n",
            " 72% 3780/5243 [06:09<02:21, 10.35it/s]\n",
            " 72% 3790/5243 [06:10<02:20, 10.37it/s]\n",
            " 72% 3800/5243 [06:11<02:19, 10.38it/s]\n",
            " 73% 3810/5243 [06:12<02:18, 10.36it/s]\n",
            " 73% 3820/5243 [06:12<02:17, 10.36it/s]\n",
            " 73% 3830/5243 [06:13<02:16, 10.36it/s]\n",
            " 73% 3840/5243 [06:14<02:15, 10.38it/s]\n",
            " 73% 3850/5243 [06:15<02:14, 10.39it/s]\n",
            " 74% 3860/5243 [06:16<02:12, 10.42it/s]\n",
            " 74% 3870/5243 [06:17<02:11, 10.47it/s]\n",
            " 74% 3880/5243 [06:18<02:09, 10.50it/s]\n",
            " 74% 3890/5243 [06:19<02:08, 10.54it/s]\n",
            " 74% 3900/5243 [06:20<02:07, 10.53it/s]\n",
            " 75% 3910/5243 [06:21<02:06, 10.50it/s]\n",
            " 75% 3920/5243 [06:22<02:05, 10.52it/s]\n",
            " 75% 3930/5243 [06:23<02:04, 10.54it/s]\n",
            " 75% 3940/5243 [06:24<02:03, 10.57it/s]\n",
            " 75% 3950/5243 [06:25<02:02, 10.57it/s]\n",
            " 76% 3960/5243 [06:26<02:01, 10.57it/s]\n",
            " 76% 3970/5243 [06:27<02:00, 10.58it/s]\n",
            " 76% 3980/5243 [06:28<01:59, 10.56it/s]\n",
            " 76% 3990/5243 [06:29<01:59, 10.51it/s]\n",
            " 76% 4000/5243 [06:30<01:59, 10.42it/s]\n",
            " 76% 4010/5243 [06:31<01:58, 10.36it/s]\n",
            " 77% 4020/5243 [06:32<01:58, 10.34it/s]\n",
            " 77% 4030/5243 [06:33<01:57, 10.33it/s]\n",
            " 77% 4040/5243 [06:34<01:56, 10.33it/s]\n",
            " 77% 4050/5243 [06:34<01:55, 10.30it/s]\n",
            " 77% 4060/5243 [06:35<01:54, 10.30it/s]\n",
            " 78% 4070/5243 [06:36<01:53, 10.32it/s]\n",
            " 78% 4080/5243 [06:37<01:51, 10.39it/s]\n",
            " 78% 4090/5243 [06:38<01:49, 10.49it/s]\n",
            " 78% 4100/5243 [06:39<01:48, 10.58it/s]\n",
            " 78% 4110/5243 [06:40<01:46, 10.63it/s]\n",
            " 79% 4120/5243 [06:41<01:45, 10.64it/s]\n",
            " 79% 4130/5243 [06:42<01:44, 10.61it/s]\n",
            " 79% 4140/5243 [06:43<01:44, 10.53it/s]\n",
            " 79% 4150/5243 [06:44<01:44, 10.46it/s]\n",
            " 79% 4160/5243 [06:45<01:43, 10.45it/s]\n",
            " 80% 4170/5243 [06:46<01:43, 10.42it/s]\n",
            " 80% 4180/5243 [06:47<01:41, 10.44it/s]\n",
            " 80% 4190/5243 [06:48<01:40, 10.49it/s]\n",
            " 80% 4200/5243 [06:49<01:39, 10.48it/s]\n",
            " 80% 4210/5243 [06:50<01:38, 10.44it/s]\n",
            " 80% 4220/5243 [06:51<01:38, 10.41it/s]\n",
            " 81% 4230/5243 [06:52<01:37, 10.40it/s]\n",
            " 81% 4240/5243 [06:53<01:36, 10.42it/s]\n",
            " 81% 4250/5243 [06:54<01:35, 10.45it/s]\n",
            " 81% 4260/5243 [06:55<01:34, 10.45it/s]\n",
            " 81% 4270/5243 [06:55<01:33, 10.44it/s]\n",
            " 82% 4280/5243 [06:56<01:32, 10.46it/s]\n",
            " 82% 4290/5243 [06:57<01:30, 10.49it/s]\n",
            " 82% 4300/5243 [06:58<01:29, 10.52it/s]\n",
            " 82% 4310/5243 [06:59<01:28, 10.51it/s]\n",
            " 82% 4320/5243 [07:00<01:28, 10.46it/s]\n",
            " 83% 4330/5243 [07:01<01:27, 10.45it/s]\n",
            " 83% 4340/5243 [07:02<01:26, 10.47it/s]\n",
            " 83% 4350/5243 [07:03<01:25, 10.47it/s]\n",
            " 83% 4360/5243 [07:04<01:24, 10.46it/s]\n",
            " 83% 4370/5243 [07:05<01:23, 10.45it/s]\n",
            " 84% 4380/5243 [07:06<01:22, 10.44it/s]\n",
            " 84% 4390/5243 [07:07<01:21, 10.44it/s]\n",
            " 84% 4400/5243 [07:08<01:20, 10.44it/s]\n",
            " 84% 4410/5243 [07:09<01:19, 10.43it/s]\n",
            " 84% 4420/5243 [07:10<01:19, 10.42it/s]\n",
            " 84% 4430/5243 [07:11<01:18, 10.37it/s]\n",
            " 85% 4440/5243 [07:12<01:17, 10.33it/s]\n",
            " 85% 4450/5243 [07:13<01:16, 10.32it/s]\n",
            " 85% 4460/5243 [07:14<01:16, 10.27it/s]\n",
            " 85% 4470/5243 [07:15<01:15, 10.26it/s]\n",
            " 85% 4480/5243 [07:16<01:14, 10.28it/s]\n",
            " 86% 4490/5243 [07:17<01:13, 10.30it/s]\n",
            " 86% 4500/5243 [07:18<01:11, 10.34it/s]\n",
            " 86% 4510/5243 [07:19<01:10, 10.36it/s]\n",
            " 86% 4520/5243 [07:20<01:09, 10.37it/s]\n",
            " 86% 4530/5243 [07:20<01:08, 10.39it/s]\n",
            " 87% 4540/5243 [07:21<01:07, 10.42it/s]\n",
            " 87% 4550/5243 [07:22<01:05, 10.51it/s]\n",
            " 87% 4560/5243 [07:23<01:04, 10.51it/s]\n",
            " 87% 4570/5243 [07:24<01:04, 10.47it/s]\n",
            " 87% 4580/5243 [07:25<01:03, 10.39it/s]\n",
            " 88% 4590/5243 [07:26<01:03, 10.34it/s]\n",
            " 88% 4600/5243 [07:27<01:02, 10.34it/s]\n",
            " 88% 4610/5243 [07:28<01:01, 10.34it/s]\n",
            " 88% 4620/5243 [07:29<01:00, 10.36it/s]\n",
            " 88% 4630/5243 [07:30<00:59, 10.37it/s]\n",
            " 88% 4640/5243 [07:31<00:58, 10.38it/s]\n",
            " 89% 4650/5243 [07:32<00:57, 10.34it/s]\n",
            " 89% 4660/5243 [07:33<00:56, 10.35it/s]\n",
            " 89% 4670/5243 [07:34<00:55, 10.37it/s]\n",
            " 89% 4680/5243 [07:35<00:54, 10.36it/s]\n",
            " 89% 4690/5243 [07:36<00:53, 10.36it/s]\n",
            " 90% 4700/5243 [07:37<00:52, 10.39it/s]\n",
            " 90% 4710/5243 [07:38<00:51, 10.44it/s]\n",
            " 90% 4720/5243 [07:39<00:49, 10.47it/s]\n",
            " 90% 4730/5243 [07:40<00:48, 10.48it/s]\n",
            " 90% 4740/5243 [07:41<00:47, 10.49it/s]\n",
            " 91% 4750/5243 [07:42<00:46, 10.49it/s]\n",
            " 91% 4760/5243 [07:43<00:46, 10.45it/s]\n",
            " 91% 4770/5243 [07:44<00:45, 10.43it/s]\n",
            " 91% 4780/5243 [07:44<00:44, 10.45it/s]\n",
            " 91% 4790/5243 [07:45<00:43, 10.47it/s]\n",
            " 92% 4800/5243 [07:46<00:42, 10.46it/s]\n",
            " 92% 4810/5243 [07:47<00:41, 10.48it/s]\n",
            " 92% 4820/5243 [07:48<00:40, 10.51it/s]\n",
            " 92% 4830/5243 [07:49<00:39, 10.53it/s]\n",
            " 92% 4840/5243 [07:50<00:38, 10.58it/s]\n",
            " 93% 4850/5243 [07:51<00:37, 10.58it/s]\n",
            " 93% 4860/5243 [07:52<00:36, 10.59it/s]\n",
            " 93% 4870/5243 [07:53<00:35, 10.58it/s]\n",
            " 93% 4880/5243 [07:54<00:34, 10.51it/s]\n",
            " 93% 4890/5243 [07:55<00:33, 10.44it/s]\n",
            " 93% 4900/5243 [07:56<00:32, 10.40it/s]\n",
            " 94% 4910/5243 [07:57<00:32, 10.38it/s]\n",
            " 94% 4920/5243 [07:58<00:31, 10.39it/s]\n",
            " 94% 4930/5243 [07:59<00:29, 10.43it/s]\n",
            " 94% 4940/5243 [08:00<00:29, 10.44it/s]\n",
            " 94% 4950/5243 [08:01<00:28, 10.44it/s]\n",
            " 95% 4960/5243 [08:02<00:27, 10.40it/s]\n",
            " 95% 4970/5243 [08:03<00:26, 10.39it/s]\n",
            " 95% 4980/5243 [08:04<00:25, 10.38it/s]\n",
            " 95% 4990/5243 [08:05<00:24, 10.41it/s]\n",
            " 95% 5000/5243 [08:06<00:23, 10.43it/s]\n",
            " 96% 5010/5243 [08:06<00:22, 10.48it/s]\n",
            " 96% 5020/5243 [08:07<00:21, 10.51it/s]\n",
            " 96% 5030/5243 [08:08<00:20, 10.53it/s]\n",
            " 96% 5040/5243 [08:09<00:19, 10.49it/s]\n",
            " 96% 5050/5243 [08:10<00:18, 10.41it/s]\n",
            " 97% 5060/5243 [08:11<00:17, 10.35it/s]\n",
            " 97% 5070/5243 [08:12<00:16, 10.34it/s]\n",
            " 97% 5080/5243 [08:13<00:15, 10.41it/s]\n",
            " 97% 5090/5243 [08:14<00:14, 10.46it/s]\n",
            " 97% 5100/5243 [08:15<00:13, 10.51it/s]\n",
            " 97% 5110/5243 [08:16<00:12, 10.55it/s]\n",
            " 98% 5120/5243 [08:17<00:11, 10.57it/s]\n",
            " 98% 5130/5243 [08:18<00:10, 10.51it/s]\n",
            " 98% 5140/5243 [08:19<00:09, 10.45it/s]\n",
            " 98% 5150/5243 [08:20<00:08, 10.39it/s]\n",
            " 98% 5160/5243 [08:21<00:08, 10.35it/s]\n",
            " 99% 5170/5243 [08:22<00:07, 10.37it/s]\n",
            " 99% 5180/5243 [08:23<00:06, 10.41it/s]\n",
            " 99% 5190/5243 [08:24<00:05, 10.47it/s]\n",
            " 99% 5200/5243 [08:25<00:04, 10.53it/s]\n",
            " 99% 5210/5243 [08:26<00:03, 10.55it/s]\n",
            "100% 5220/5243 [08:27<00:02, 10.51it/s]\n",
            "100% 5230/5243 [08:27<00:01, 10.48it/s]\n",
            "100% 5240/5243 [08:28<00:00, 10.43it/s]\n",
            "100% 5243/5243 [08:29<00:00, 10.30it/s]\n",
            "\n",
            "\n",
            "--- Final result: ---\n",
            "               f_mae =  0.026003           \n",
            "              f_rmse =  0.034455           \n",
            "               e_mae =  0.746099           \n",
            "             e/N_mae =  0.002072           \n",
            "               f_mae =  0.026003           \n",
            "              f_rmse =  0.034455           \n",
            "               e_mae =  0.746099           \n",
            "             e/N_mae =  0.002072           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJitSZgLYNNF"
      },
      "source": [
        "### Deploy the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VoeGtlA02KQ"
      },
      "source": [
        "We now convert the model to a potential file. This makes it independent of NequIP and we can load it in CP2K to run MD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y3NJJgtDIDNc",
        "outputId": "9eb5a069-aaf4-4ccd-e278-12ac981d7b4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:root:Loading best_model from training session...\n",
            "INFO:root:Compiled & optimized model.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['cp', 'water-gra-film-deploy-alle.pth', 'wat...>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import subprocess\n",
        "\n",
        "# datetime object containing current date and time\n",
        "depl_time = datetime.now().strftime(\"%d%m%Y-%H%M\")\n",
        "\n",
        "if Model == \"Allegro\":\n",
        "  !nequip-deploy build --train-dir results/water-gra-film/water-gra-film water-gra-film-deploy-alle.pth\n",
        "  cmd = [\"cp\", \"water-gra-film-deploy-alle.pth\", \"water-gra-film-deploy-alle-\"+depl_time+\".pth\"] \n",
        "elif Model == \"NequIP\":\n",
        "   !nequip-deploy build --train-dir results/water-gra-film/water-gra-film water-gra-film-deploy-neq.pth \n",
        "   cmd = [\"cp\", \"water-gra-film-deploy-neq.pth\", \"water-gra-film-deploy-neq-\"+depl_time+\".pth\"] \n",
        "\n",
        "subprocess.Popen(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_is_pretrained = False\n",
        "\n",
        "if model_is_pretrained == False:\n",
        "  ! cp *2023*.pth /content/drive/MyDrive/models_and_datasets/models/.\n",
        "else:\n",
        "  ! cp /content/drive/MyDrive/models_and_datasets/models/*.pth ."
      ],
      "metadata": {
        "id": "9uFoAb6AHD8X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTzdm_qeAU2r"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "interpreter": {
      "hash": "c9be9acec9edbd902b751bf46a8fbd7b71bbc5f0438c72d3ebaee4bffeb5e5e4"
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}